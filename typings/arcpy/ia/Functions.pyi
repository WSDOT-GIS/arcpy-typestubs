"""
This type stub file was generated by pyright.
"""

__all__ = [
    "Abs",
    "ACos",
    "ACosH",
    "AggregateMultidimensionalRaster",
    "AnalyzeChangesUsingCCDC",
    "AnalyzeChangesUsingLandTrendr",
    "ApplyGeometricTerrainCorrection",
    "ApplyOrbitCorrection",
    "ApplyRadiometricCalibration",
    "ApplyRadiometricTerrainFlattening",
    "ASin",
    "ASinH",
    "ATan",
    "ATan2",
    "ATanH",
    "BitwiseAnd",
    "BitwiseLeftShift",
    "BitwiseNot",
    "BitwiseOr",
    "BitwiseRightShift",
    "BitwiseXOr",
    "BooleanAnd",
    "BooleanNot",
    "BooleanOr",
    "BooleanXOr",
    "CellStatistics",
    "ClassifyObjectsUsingDeepLearning",
    "ClassifyPixelsUsingDeepLearning",
    "ClassifyRaster",
    "ClassifyRasterUsingSpectra",
    "CombinatorialAnd",
    "CombinatorialOr",
    "CombinatorialXOr",
    "ComputeAccuracyForObjectDetection",
    "ComputeChangeRaster",
    "ComputeConfusionMatrix",
    "ComputeSegmentAttributes",
    "Con",
    "ConvertSARUnits",
    "Cos",
    "CosH",
    "CreateAccuracyAssessmentPoints",
    "CreateColorComposite",
    "DeepLearningModelToEcd",
    "Despeckle",
    "DetectChangeUsingChangeAnalysisRaster",
    "DetectChangeUsingDeepLearning",
    "DetectObjectsUsingDeepLearning",
    "Diff",
    "DimensionalMovingStatistics",
    "Divide",
    "DownloadOrbitFile",
    "EqualTo",
    "Exp",
    "Exp10",
    "Exp2",
    "ExportTrainingDataForDeepLearning",
    "ExtractFeaturesUsingAIModels",
    "ExtractVideoFramesToImages",
    "FindArgumentStatistics",
    "Float",
    "FocalStatistics",
    "GenerateMultidimensionalAnomaly",
    "GenerateTrainingSamplesFromSeedPoints",
    "GenerateTrendRaster",
    "GreaterThan",
    "GreaterThanEqual",
    "InList",
    "InspectTrainingSamples",
    "Int",
    "InterpolateFromSpatiotemporalPoints",
    "IsNull",
    "LessThan",
    "LessThanEqual",
    "LinearSpectralUnmixing",
    "Ln",
    "Log10",
    "Log2",
    "Minus",
    "Mod",
    "MultidimensionalPrincipalComponents",
    "Negate",
    "NonMaximumSuppression",
    "NotEqual",
    "Over",
    "Pick",
    "Plus",
    "Power",
    "PredictUsingRegressionModel",
    "PredictUsingTrendRaster",
    "RemoveRasterSegmentTilingArtifacts",
    "RemoveThermalNoise",
    "RoundDown",
    "RoundUp",
    "Sample",
    "SegmentMeanShift",
    "SetNull",
    "Sin",
    "SinH",
    "Square",
    "SquareRoot",
    "SummarizeCategoricalRaster",
    "Tan",
    "TanH",
    "Test",
    "Times",
    "TrainDeepLearningModel",
    "TrainIsoClusterClassifier",
    "TrainKNearestNeighborClassifier",
    "TrainMaximumLikelihoodClassifier",
    "TrainRandomTreesClassifier",
    "TrainRandomTreesRegressionModel",
    "TrainSupportVectorMachineClassifier",
    "TrainUsingAutoDL",
    "UpdateAccuracyAssessmentPoints",
    "VideoMetadataToFeatureClass",
    "VideoMultiplexer",
    "WeightedSum",
    "ZonalStatistics",
    "ZonalStatisticsAsTable",
    "ApplyEnvironment",
    "FloatDivide",
    "FloorDivide",
]

def Abs(in_raster_or_constant):
    """Abs_ia(in_raster_or_constant)

    Calculates the absolute value of the cells in a raster.

    Arguments:
    in_raster_or_constant -- The input raster for which to calculate the absolute values.

    Results:
    out_raster -- Output raster"""
    ...

def ACos(in_raster_or_constant):
    """ACos_ia(in_raster_or_constant)

    Calculates the inverse cosine of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the inverse cosine values.

    Results:
    out_raster -- Output raster"""
    ...

def ACosH(in_raster_or_constant):
    """ACosH_ia(in_raster_or_constant)

    Calculates the inverse hyperbolic cosine of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the inverse hyperbolic cosine values.

    Results:
    out_raster -- Output raster"""
    ...

def AggregateMultidimensionalRaster(
    in_multidimensional_raster,
    dimension,
    aggregation_method=...,
    variables=...,
    aggregation_def=...,
    interval_keyword=...,
    interval_value=...,
    interval_unit=...,
    interval_ranges=...,
    aggregation_function=...,
    ignore_nodata=...,
    dimensionless=...,
    percentile_value=...,
    percentile_interpolation_type=...,
):
    """AggregateMultidimensionalRaster_ia(in_multidimensional_raster, dimension, {aggregation_method}, {[variable,...]}, {aggregation_def}, {interval_keyword}, {interval_value}, {interval_unit}, {interval_ranges}, {aggregation_function}, {ignore_nodata}, {dimensionless}, {percentile_value}, {percentile_interpolation_type})

    Generates a multidimensional raster dataset by combining existing multidimensional raster variables along a dimension.

    Arguments:
    in_multidimensional_raster -- The input multidimensional raster dataset.
    dimension -- The aggregation dimension. This is the dimension along which the variables will be aggregated.
    aggregation_method -- Specifies the mathematical method that will be used to combine the aggregated slices in an interval.
    variable -- The variable or variables that will be aggregated along the given dimension. If no variable is specified, all variables with the selected dimension will be aggregated.
    aggregation_def -- Specifies the dimension interval for which the data will be aggregated.
    interval_keyword -- Specifies the keyword interval that will be used when aggregating along the dimension. This parameter is required when the Aggregation Definition parameter is set to Interval Keyword and the aggregation must be across time.
    interval_value -- The size of the interval that will be used for the aggregation. This parameter is required when the Aggregation Definition parameter is set to Interval Value.
    interval_unit -- The unit that will be used for the Value Interval parameter. This parameter is required when the Dimension parameter is a time field and the Aggregation Definition parameter is set to Interval Value.
    interval_ranges -- Interval ranges specified in a value table will be used to aggregate groups of values. The value table consists of pairs of minimum and maximum range values, with data type Double or Date.
    aggregation_function -- A custom raster function that will be used to compute the pixel values of the aggregated rasters. The input is a raster function JSON object or an .rft.xml file created from a function chain or a custom Python raster function.
    ignore_nodata -- Specifies whether NoData values will be ignored in the analysis.
    dimensionless -- Specifies whether the layer will have dimension values. This parameter is only active if a single slice is selected to create a layer.
    percentile_value -- The percentile to calculate. The default is 90, indicating the 90th percentile.
    percentile_interpolation_type -- Specifies the method of percentile interpolation that will be used when there is an even number of values from the input raster to be calculated.

    Results:
    out_multidimensional_raster -- Output Multidimensional Raster"""
    ...

def AnalyzeChangesUsingCCDC(
    in_multidimensional_raster,
    bands=...,
    tmask_bands=...,
    chi_squared_threshold=...,
    min_anomaly_observations=...,
    update_frequency=...,
):
    """AnalyzeChangesUsingCCDC_ia(in_multidimensional_raster, {[band,...]}, {[tmask_band,...]}, {chi_squared_threshold}, {min_anomaly_observations}, {update_frequency})

    Evaluates changes in pixel values over time using the Continuous Change Detection and Classification (CCDC) method and generates a change analysis raster containing the model results.

    Arguments:
    in_multidimensional_raster -- The input multidimensional raster dataset.
    band -- The band IDs to use for change detection. If no band IDs are provided, all the bands from the input raster dataset will be used.
    tmask_band -- The band IDs to be used in the temporal mask (Tmask). It is recommended that you use the green band and the SWIR band. If no band IDs are provided, no masking will occur.
    chi_squared_threshold -- The chi-square statistic change probability threshold. If an observation has a calculated change probability that is above this threshold, it is flagged as an anomaly, which is a potential change event. The default value is 0.99.
    min_anomaly_observations -- The minimum number of consecutive anomaly observations that must occur before an event is considered a change. A pixel must be flagged as an anomaly for the specified number of consecutive time slices before it is considered a true change. The default value is 6.
    update_frequency -- The frequency, in years, at which to update the time series model with new observations. The default value is 1.

    Results:
    out_ccdc_result -- Output CCDC Analysis Raster"""
    ...

def AnalyzeChangesUsingLandTrendr(
    in_multidimensional_raster,
    processing_band=...,
    snapping_date=...,
    max_num_segments=...,
    vertex_count_overshoot=...,
    spike_threshold=...,
    recovery_threshold=...,
    prevent_one_year_recovery=...,
    recovery_trend=...,
    min_num_observations=...,
    best_model_proportion=...,
    pvalue_threshold=...,
    output_other_bands=...,
):
    """AnalyzeChangesUsingLandTrendr_ia(in_multidimensional_raster, {processing_band}, {snapping_date}, {max_num_segments}, {vertex_count_overshoot}, {spike_threshold}, {recovery_threshold}, {prevent_one_year_recovery}, {recovery_trend}, {min_num_observations}, {best_model_proportion}, {pvalue_threshold}, {output_other_bands})

    Evaluates changes in pixel values over time using the Landsat-based detection of trends in disturbance and recovery (LandTrendr) method and generates a change analysis raster containing the model results.

    Arguments:
    in_multidimensional_raster -- The input multidimensional raster dataset.
    processing_band -- The image band name to use for segmenting the pixel value trajectories over time. Choose the band name that will best capture the changes in the feature you want to observe.
    snapping_date -- The date used to identify a slice for each year in the input multidimensional dataset. The slice with the date closest to the snapping date will be used. This parameter is required if the input dataset contains sub-yearly data.
    max_num_segments -- The maximum number of segments to be fitted to the time series for each pixel. The default is 5.
    vertex_count_overshoot -- The number of additional vertices beyond max_num_segments + 1 that can be used to fit the model during the initial stage of identifying vertices. Later in the modeling process, the number of additional vertices will be reduced to max_num_segments + 1. The default is 2.
    spike_threshold -- The threshold to use for dampening spikes or anomalies in the pixel value trajectory. The value must range between 0 and 1 in which 1 means no dampening. The default is 0.9.
    recovery_threshold -- The recovery threshold value in years. If a segment has a recovery rate that is faster than 1/recovery threshold, the segment is discarded and not included in the time series model. The value must range between 0 and 1. The default is 0.25.
    prevent_one_year_recovery -- Specifies whether segments that exhibit a one year recovery will be excluded.
    recovery_trend -- Specifies whether the recovery has an increasing (positive) trend.
    min_num_observations -- The minimum number of valid observations required to perform fitting. The number of years in the input multidimensional dataset must be equal to or greater than this value. The default is 6.
    best_model_proportion -- The best model proportion value. During the model selection process, the tool will calculate the p-value for each model and identify a model that has the most vertices while maintaining the smallest (most significant) p-value based on this proportion value. A value of 1 means the model has the lowest p-value but may not have a high number of vertices. The default is 1.25.
    pvalue_threshold -- The p-value threshold for a model to be selected. After the vertices are detected in the initial stage of the model fitting, the tool will fit each segment and calculate the p-value to determine the significance of the model. On the next iteration, the model will decrease the number of segments by one and recalculate the p-value. This will continue and, if the p-value is smaller than the value specified in this parameter, the model will be selected and the tool will stop searching for a better model. If no such model is selected, the tool will select a model with a p-value smaller than the lowest p-value  best model proportion value. The default is 0.01.
    output_other_bands -- Specifies whether other bands will be included in the results.

    Results:
    out_multidimensional_raster -- Output Multidimensional Raster"""
    ...

def ApplyGeometricTerrainCorrection(
    in_radar_data, polarization_bands=..., in_dem_raster=..., geoid=...
):
    """ApplyGeometricTerrainCorrection_ia(in_radar_data, {[polarization_band,...]}, {in_dem_raster}, {geoid})

    Orthorectifies the input synthetic aperture radar (SAR) data using a range-Doppler backgeocoding algorithm.

    Arguments:
    in_radar_data -- The input radar data.
    polarization_band -- The polarization bands to be corrected.
    in_dem_raster -- The input DEM.
    geoid -- Specifies whether the vertical reference system of the input DEM will be transformed to ellipsoidal height. Most elevation datasets are referenced to sea level orthometric height, so a correction is required in these cases to convert to ellipsoidal height.

    Results:
    out_radar_data -- Output Radar Data"""
    ...

def ApplyOrbitCorrection(in_radar_data, in_orbit_file=...):  # -> Any:
    """ApplyOrbitCorrection_ia(in_radar_data, {in_orbit_file})

    Updates the orbital information in the synthetic aperture radar (SAR) dataset using a more accurate orbit state vector (OSV) file.

    Arguments:
    in_radar_data -- The input radar data.
    in_orbit_file -- The input orbit file."""
    ...

def ApplyRadiometricCalibration(
    in_radar_data, polarization_bands=..., calibration_type=...
):
    """ApplyRadiometricCalibration_ia(in_radar_data, {[polarization_band,...]}, {calibration_type})

    Converts the input synthetic aperture radar (SAR) reflectivity into physical units of normalized backscatter by normalizing the reflectivity using a reference plane.

    Arguments:
    in_radar_data -- The input radar data.
    polarization_band -- The polarization bands to be corrected.
    calibration_type -- Specifies the type of calibration that will be applied.

    Results:
    out_radar_data -- Output Radar Data"""
    ...

def ApplyRadiometricTerrainFlattening(
    in_radar_data,
    in_dem_raster,
    geoid=...,
    polarization_bands=...,
    calibration_type=...,
    out_scattering_area=...,
    out_geometric_distortion=...,
    out_geometric_distortion_mask=...,
):
    """ApplyRadiometricTerrainFlattening_ia(in_radar_data, in_dem_raster, {geoid}, {[polarization_band,...]}, {calibration_type}, {out_scattering_area}, {out_geometric_distortion}, {out_geometric_distortion_mask})

    Corrects the input synthetic aperture radar (SAR) data for radiometric distortions due to topography.

    Arguments:
    in_radar_data -- The input radar data.
    in_dem_raster -- The input DEM.
    geoid -- Specifies whether the vertical reference system of the input DEM will be transformed to ellipsoidal height. Most elevation datasets are referenced to sea level orthometric height, so a correction is required in these cases to convert to ellipsoidal height.
    polarization_band -- The polarization bands that will be radiometrically terrain flattened.
    calibration_type -- Specifies whether the output will be terrain flattened using sigma nought or gamma nought.
    out_scattering_area -- The scattering area radar dataset.
    out_geometric_distortion -- The 4-band geometric distortion radar dataset. The first band is the terrain slope, the second band is look angle, the third band is the foreshortening ratio, and the fourth band is the local incidence angle.
    out_geometric_distortion_mask -- The 1-band geometric distortion mask radar dataset. The pixels are classified using six unique values, one for each distortion type:

    Results:
    out_radar_data -- Output Radar Data"""
    ...

def ASin(in_raster_or_constant):
    """ASin_ia(in_raster_or_constant)

    Calculates the inverse sine of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the inverse sine values.

    Results:
    out_raster -- Output raster"""
    ...

def ASinH(in_raster_or_constant):
    """ASinH_ia(in_raster_or_constant)

    Calculates the inverse hyperbolic sine of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the inverse hyperbolic sine values.

    Results:
    out_raster -- Output raster"""
    ...

def ATan(in_raster_or_constant):
    """ATan_ia(in_raster_or_constant)

    Calculates the inverse tangent of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the inverse tangent values.

    Results:
    out_raster -- Output raster"""
    ...

def ATan2(in_raster_or_constant1, in_raster_or_constant2):
    """ATan2_ia(in_raster_or_constant1, in_raster_or_constant2)

    Calculates the inverse tangent (based on x,y) of cells in a raster.

    Arguments:
    in_raster_or_constant1 -- The input that specifies the numerator, or y value, to use when calculating the inverse tangent.
    in_raster_or_constant2 -- The input that specifies the denominator, or x value, to use when calculating the inverse tangent.

    Results:
    out_raster -- Output raster"""
    ...

def ATanH(in_raster_or_constant):
    """ATanH_ia(in_raster_or_constant)

    Calculates the inverse hyperbolic tangent of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the inverse hyperbolic tangent values.

    Results:
    out_raster -- Output raster"""
    ...

def BitwiseAnd(in_raster_or_constant1, in_raster_or_constant2):
    """BitwiseAnd_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Bitwise And operation on the binary values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The first input to use in this bitwise operation.
    in_raster_or_constant2 -- The second input to use in this bitwise operation.

    Results:
    out_raster -- Output raster"""
    ...

def BitwiseLeftShift(in_raster_or_constant1, in_raster_or_constant2):
    """BitwiseLeftShift_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Bitwise Left Shift operation on the binary values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The input on which to perform the shift.
    in_raster_or_constant2 -- The input defining the number of positions to shift the bits.

    Results:
    out_raster -- Output raster"""
    ...

def BitwiseNot(in_raster_or_constant):
    """BitwiseNot_ia(in_raster_or_constant)

    Performs a Bitwise Not (complement) operation on the binary value of an input raster.

    Arguments:
    in_raster_or_constant -- The input raster on which to perform the Bitwise Not (complement) operation.

    Results:
    out_raster -- Output raster"""
    ...

def BitwiseOr(in_raster_or_constant1, in_raster_or_constant2):
    """BitwiseOr_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Bitwise Or operation on the binary values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The first input to use in this bitwise operation.
    in_raster_or_constant2 -- The second input to use in this bitwise operation.

    Results:
    out_raster -- Output raster"""
    ...

def BitwiseRightShift(in_raster_or_constant1, in_raster_or_constant2):
    """BitwiseRightShift_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Bitwise Right Shift operation on the binary values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The input on which to perform the shift.
    in_raster_or_constant2 -- The input defining the number of positions to shift the bits.

    Results:
    out_raster -- Output raster"""
    ...

def BitwiseXOr(in_raster_or_constant1, in_raster_or_constant2):
    """BitwiseXOr_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Bitwise eXclusive Or operation on the binary values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The first input to use in this bitwise operation.
    in_raster_or_constant2 -- The second input to use in this bitwise operation.

    Results:
    out_raster -- Output raster"""
    ...

def BooleanAnd(in_raster_or_constant1, in_raster_or_constant2):
    """BooleanAnd_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Boolean And operation on the cell values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The first input to use in this Boolean operation.
    in_raster_or_constant2 -- The second input to use in this Boolean operation.

    Results:
    out_raster -- Output raster"""
    ...

def BooleanNot(in_raster_or_constant):
    """BooleanNot_ia(in_raster_or_constant)

    Performs a Boolean Not (complement) operation on the cell values of the input raster.

    Arguments:
    in_raster_or_constant -- The input to use in this Boolean operation.

    Results:
    out_raster -- Output raster"""
    ...

def BooleanOr(in_raster_or_constant1, in_raster_or_constant2):
    """BooleanOr_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Boolean Or operation on the cell values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The first input to use in this Boolean operation.
    in_raster_or_constant2 -- The second input to use in this Boolean operation.

    Results:
    out_raster -- Output raster"""
    ...

def BooleanXOr(in_raster_or_constant1, in_raster_or_constant2):
    """BooleanXOr_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Boolean eXclusive Or operation on the cell values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The first input to use in this Boolean operation.
    in_raster_or_constant2 -- The second input to use in this Boolean operation.

    Results:
    out_raster -- Output raster"""
    ...

def CellStatistics(
    in_rasters_or_constants,
    statistics_type=...,
    ignore_nodata=...,
    process_as_multiband=...,
    percentile_value=...,
    percentile_interpolation_type=...,
):
    """CellStatistics_ia([in_rasters_or_constant,...], {statistics_type}, {ignore_nodata}, {process_as_multiband}, {percentile_value}, {percentile_interpolation_type})

    Calculates a per-cell statistic from multiple rasters.

    Arguments:
    in_rasters_or_constant -- A list of input rasters for which a statistical operation will be calculated for each cell in the analysis window.
    statistics_type -- Specifies the statistic type to be calculated.
    ignore_nodata -- Specifies whether NoData values will be ignored by the statistic calculation.
    process_as_multiband -- Specifies how the input multiband raster bands will be processed.
    percentile_value -- The percentile value that will be calculated. The default is 90, indicating the 90th percentile.
    percentile_interpolation_type -- Specifies the method of interpolation that will be used when the specified percentile value is between two input cell values.

    Results:
    out_raster -- Output raster"""
    ...

def ClassifyObjectsUsingDeepLearning(
    in_raster,
    out_feature_class,
    in_model_definition,
    in_features=...,
    class_label_field=...,
    processing_mode=...,
    model_arguments=...,
    caption_field=...,
):  # -> Any:
    """ClassifyObjectsUsingDeepLearning_ia(in_raster, out_feature_class, in_model_definition, {in_features}, {class_label_field}, {processing_mode}, {model_arguments}, {caption_field})

    Runs a trained deep learning model on an input raster and an optional feature class to produce a feature class or table in which each input object or feature has an assigned class or category label.

    Arguments:
    in_raster -- The input image that will be used to classify objects.
    out_feature_class -- The output feature class that will contain geometries surrounding the objects or feature from the input feature class, as well as a field to store the categorization label.
    in_model_definition -- The Model Definition parameter value can be an Esri model definition JSON file (.emd), a JSON string, or a deep learning model package (.dlpk). A JSON string is useful when this tool is used on the server so you can paste the JSON string rather than upload the .emd file. The .dlpk file must be stored locally.
    in_features -- The point, line, or polygon input feature class that identifies the location of each object or feature to be classified and labelled. Each row in the input feature class represents a single object or feature.
    class_label_field -- The name of the field that will contain the class or category label in the output feature class.
    processing_mode -- Specifies how all raster items in a mosaic dataset or an image service will be processed. This parameter is applied when the input raster is a mosaic dataset or an image service.
    model_arguments -- The function arguments defined in the Python raster function class. This is where additional deep learning parameters and arguments for experiments and refinement are listed, such as a confidence threshold for adjusting the sensitivity. The names of the arguments are populated from the Python module.
    caption_field -- The name of the field that will contain the text or caption in the output feature class. This parameter is only supported when an Image Captioner model is used.
    """
    ...

def ClassifyPixelsUsingDeepLearning(
    in_raster,
    in_model_definition,
    arguments=...,
    processing_mode=...,
    out_classified_folder=...,
    out_featureclass=...,
):  # -> Any:
    """ClassifyPixelsUsingDeepLearning_ia(in_raster, in_model_definition, {arguments}, {processing_mode}, {out_classified_folder}, {out_featureclass})

    Runs a trained deep learning model on an input raster to produce a classified raster, with each valid pixel having an assigned class label.

    Arguments:
    in_raster -- The input raster dataset that will be classified.
    in_model_definition -- The Model Definition parameter value can be an Esri model definition JSON file (.emd), a JSON string, or a deep learning model package (.dlpk). A JSON string is useful when this tool is used on the server so you can paste the JSON string rather than upload the .emd file. The .dlpk file must be stored locally.
    arguments -- The function arguments are defined in the Python raster function class. This is where you list additional deep learning parameters and arguments for experiments and refinement, such as a confidence threshold for adjusting sensitivity. The names of the arguments are populated from reading the Python module.
    processing_mode -- Specifies how all raster items in a mosaic dataset or an image service will be processed. This parameter is applied when the input raster is a mosaic dataset or an image service.
    out_classified_folder -- The folder where the output classified rasters will be stored. A mosaic dataset will be generated using the classified rasters in this folder.
    out_featureclass -- The feature class where the output classified rasters will be stored.

    Results:
    out_classified_raster -- Output Raster Dataset"""
    ...

def ClassifyRaster(in_raster, in_classifier_definition, in_additional_raster=...):
    """ClassifyRaster_ia(in_raster, in_classifier_definition, {in_additional_raster})

    Classifies a raster dataset based on an Esri classifier definition file (.ecd) and raster dataset inputs.

    Arguments:
    in_raster -- The raster dataset to classify.
    in_classifier_definition -- The input Esri classifier definition file (.ecd) containing the statistics for the chosen attributes for the classifier.
    in_additional_raster -- Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for the classifier. This raster is necessary when calculating attributes such as mean or standard deviation. This parameter is optional.

    Results:
    out_raster_dataset -- Output Classified Raster"""
    ...

def ClassifyRasterUsingSpectra(
    in_raster,
    in_spectra_file,
    method=...,
    thresholds=...,
    out_score_raster=...,
    out_classifier_definition=...,
):
    """ClassifyRasterUsingSpectra_ia(in_raster, in_spectra_file, {method}, {thresholds}, {out_score_raster}, {out_classifier_definition})

    Classifies a multiband raster dataset using spectral matching techniques. The input spectral data can be provided as a point feature class or a .json file.

    Arguments:
    in_raster -- The input multiband raster.
    in_spectra_file -- The spectral information for different pixel classes.
    method -- Specifies the spectral matching method that will be used.
    thresholds -- The threshold for spectral matching. Pixel values that exceed this value will be classified as undefined. This can be a single value applied to all spectral classes or a space-delimited list of values for each class.
    out_score_raster -- A multiband raster that stores the matching results for each end member. The band order follows the order of the classes in the Spectra or Points parameter value. If the input is a multidimensional raster, the output format must be CRF.
    out_classifier_definition -- The output .ecd file.

    Results:
    out_classified_raster -- Output Classified Raster"""
    ...

def CombinatorialAnd(in_raster_or_constant1, in_raster_or_constant2):
    """CombinatorialAnd_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Combinatorial And operation on the cell values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The first input to use in this combinatorial operation.
    in_raster_or_constant2 -- The second input to use in this combinatorial operation.

    Results:
    out_raster -- Output raster"""
    ...

def CombinatorialOr(in_raster_or_constant1, in_raster_or_constant2):
    """CombinatorialOr_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Combinatorial Or operation on the cell values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The first input to use in this combinatorial operation.
    in_raster_or_constant2 -- The second input to use in this combinatorial operation.

    Results:
    out_raster -- Output raster"""
    ...

def CombinatorialXOr(in_raster_or_constant1, in_raster_or_constant2):
    """CombinatorialXOr_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Combinatorial eXclusive Or operation on the cell values of two input rasters.

    Arguments:
    in_raster_or_constant1 -- The first input to use in this combinatorial operation.
    in_raster_or_constant2 -- The second input to use in this combinatorial operation.

    Results:
    out_raster -- Output raster"""
    ...

def ComputeAccuracyForObjectDetection(
    detected_features,
    ground_truth_features,
    out_accuracy_table,
    out_accuracy_report=...,
    detected_class_value_field=...,
    ground_truth_class_value_field=...,
    min_iou=...,
    mask_features=...,
):  # -> Any:
    """ComputeAccuracyForObjectDetection_ia(detected_features, ground_truth_features, out_accuracy_table, {out_accuracy_report}, {detected_class_value_field}, {ground_truth_class_value_field}, {min_iou}, {mask_features})

    Calculates the accuracy of a deep learning model by comparing the detected objects from the Detect Objects Using Deep Learning tool to ground truth data.

    Arguments:
    detected_features -- The polygon feature class containing the objects detected from the Detect Objects Using Deep Learning tool.
    ground_truth_features -- The polygon feature class containing ground truth data.
    out_accuracy_table -- The output accuracy table.
    out_accuracy_report -- The name of the output accuracy report. The report is a PDF document containing accuracy metrics and charts.
    detected_class_value_field -- The field in the detected objects feature class that contains the class values or class names.
    ground_truth_class_value_field -- The field in the ground truth feature class that contains the class values.
    min_iou -- The IoU ratio to use as a threshold to evaluate the accuracy of the object-detection model. The numerator is the area of overlap between the predicted bounding box and the ground reference bounding box. The denominator is the area of union or the area encompassed by both bounding boxes. The IoU ranges from 0 to 1.
    mask_features -- A polygon feature class that delineates the area or areas where accuracy will be computed. Only the features that intersect the mask will be assessed for accuracy.
    """
    ...

def ComputeChangeRaster(
    from_raster,
    to_raster,
    compute_change_method=...,
    from_classes=...,
    to_classes=...,
    filter_method=...,
    define_transition_colors=...,
    from_classname_field=...,
    to_classname_field=...,
):
    """ComputeChangeRaster_ia(from_raster, to_raster, {compute_change_method}, {[from_classe,...]}, {[to_classe,...]}, {filter_method}, {define_transition_colors}, {from_classname_field}, {to_classname_field})

    Calculates the absolute, relative, categorical, or spectral difference between two raster datasets.

    Arguments:
    from_raster -- The initial or earlier raster to be analyzed.
    to_raster -- The final or later raster to be analyzed. This is the raster that will be compared to the initial raster.
    compute_change_method -- Specifies the type of calculation that will be performed between the two rasters.
    from_classe -- The list of class names from the From Raster parameter that will be included in the computation. If no classes are provided, all classes will be included.
    to_classe -- The list of class names from the To Raster parameter that will be included in the computation. If no classes are provided, all classes will be included.
    filter_method -- Specifies the pixels that will be categorized in the output raster. This parameter is active when the Compute Change Method parameter is set to Categorical difference.
    define_transition_colors -- Specifies the color that will be used to symbolize the output classes. When a pixel changes from one class type to another, the output pixel color represents the initial class type, the final class type, or a blend of the two.
    from_classname_field -- The field that will store class names in the From Raster parameter value. The tool automatically searches for the ClassName field or Class_Name field to use.
    to_classname_field -- The field that will store class names in the To Raster parameter value. The tool will automatically search for the ClassName field or Class_Name field to use.

    Results:
    out_raster_dataset -- Output Raster"""
    ...

def ComputeConfusionMatrix(
    in_accuracy_assessment_points, out_confusion_matrix
):  # -> Any:
    """ComputeConfusionMatrix_ia(in_accuracy_assessment_points, out_confusion_matrix)

    Computes a confusion matrix with errors of omission and commission and derives a kappa index of agreement, Intersection over Union (IoU),  and an overall accuracy between the classified map and the reference data.

    Arguments:
    in_accuracy_assessment_points -- The accuracy assessment point feature class created from the Create Accuracy Assessment Points tool, containing the Classified and GrndTruth fields. The Classified and GrndTruth fields are both long integer field types.
    out_confusion_matrix -- The output file name of the confusion matrix in table format.
    """
    ...

def ComputeSegmentAttributes(
    in_segmented_raster, in_additional_raster=..., used_attributes=...
):
    """ComputeSegmentAttributes_ia(in_segmented_raster, {in_additional_raster}, {[used_attribute,...]})

    Computes a set of attributes associated with the segmented image. The input raster can be a single-band or 3-band, 8-bit segmented image.

    Arguments:
    in_segmented_raster -- The input segmented raster dataset, where all the pixels belonging to a segment have the same converged RGB color. Usually, it is an 8-bit, 3-band RGB raster, but it can also be a 1-band grayscale raster.
    in_additional_raster -- Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for the classifier. This raster is necessary when calculating attributes such as mean or standard deviation. This parameter is optional.
    used_attribute -- Specifies the attributes that will be included in the attribute table associated with the output raster.

    Results:
    out_index_raster_dataset -- Output Segment Index Raster"""
    ...

def Con(
    in_conditional_raster,
    in_true_raster_or_constant,
    in_false_raster_or_constant=...,
    where_clause=...,
):
    """Con_ia(in_conditional_raster, in_true_raster_or_constant, {in_false_raster_or_constant}, {where_clause})

    Performs a conditional if/else evaluation on each of the input cells of an input raster.

    Arguments:
    in_conditional_raster -- The input raster representing the true or false result of the desired condition.
    in_true_raster_or_constant -- The input whose values will be used as the output cell values if the condition is true.
    in_false_raster_or_constant -- The input whose values will be used as the output cell values if the condition is false.
    where_clause -- A logical expression that determines which of the input cells are to be true or false.

    Results:
    out_raster -- Output raster"""
    ...

def ConvertSARUnits(in_radar_data, conversion_type=...):
    """ConvertSARUnits_ia(in_radar_data, {conversion_type})

    Converts the scaling of the input synthetic aperture radar (SAR) data between amplitude and intensity and between  linear and decibels (dB).

    Arguments:
    in_radar_data -- The input radar data.
    conversion_type -- Specifies the type of backscatter conversion that will be applied.

    Results:
    out_radar_data -- Output Radar Data"""
    ...

def Cos(in_raster_or_constant):
    """Cos_ia(in_raster_or_constant)

    Calculates the cosine of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the cosine values.

    Results:
    out_raster -- Output raster"""
    ...

def CosH(in_raster_or_constant):
    """CosH_ia(in_raster_or_constant)

    Calculates the hyperbolic cosine of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the hyperbolic cosine values.

    Results:
    out_raster -- Output raster"""
    ...

def CreateAccuracyAssessmentPoints(
    in_class_data,
    out_points,
    target_field=...,
    num_random_points=...,
    sampling=...,
    polygon_dimension_field=...,
):  # -> Any:
    """CreateAccuracyAssessmentPoints_ia(in_class_data, out_points, {target_field}, {num_random_points}, {sampling}, {polygon_dimension_field})

    Creates randomly sampled points for post-classification accuracy assessment.

    Arguments:
    in_class_data -- The input classification image or other thematic GIS reference data. The input can be a raster or feature class.
    out_points -- The output point shapefile or feature class that contains the random points to be used for accuracy assessment.
    target_field -- Specifies whether the input data is a classified image or ground truth data.
    num_random_points -- The total number of random points that will be generated.
    sampling -- Specifies the sampling scheme that will be used.
    polygon_dimension_field -- A field that defines the dimension (time) of the features. This parameter is used only if the classification result is multidimensional raster and you want to generate assessment points from a feature class, such as land classification polygons for multiple years.
    """
    ...

def CreateColorComposite(
    in_raster, method, red_expression, green_expression, blue_expression
):
    """CreateColorComposite_ia(in_raster, method, red_expression, green_expression, blue_expression)

    Creates a three-band raster dataset from a multiband raster dataset.

    Arguments:
    in_raster -- The input multiband raster data.
    method -- Specifies the method that will be used to extract bands.
    red_expression -- The calculation that will be assigned to the first band.
    green_expression -- The calculation that will be assigned to the second band.
    blue_expression -- The calculation that will be assigned to the third band.

    Results:
    out_raster -- Output Raster"""
    ...

def DeepLearningModelToEcd(
    in_deep_learning_model, in_classification_info_json, out_classifier_definition
):  # -> Any:
    """DeepLearningModelToEcd_ia(in_deep_learning_model, in_classification_info_json, out_classifier_definition)

    Converts a deep learning model to an Esri classifier definition file (.ecd).

    Arguments:
    in_deep_learning_model -- The binary model file generated by a deep learning package such as Google TensorFlow, Microsoft CNTK, or similar application.
    in_classification_info_json -- The class information JSON file. See the JSON file example above.
    out_classifier_definition -- The .ecd file that can be used in the Classify function and Classify Raster tool.
    """
    ...

def Despeckle(
    in_radar_data,
    polarization_bands=...,
    filter_type=...,
    filter_size=...,
    noise_model=...,
    noise_variance=...,
    add_noise_mean=...,
    mult_noise_mean=...,
    number_of_looks=...,
    damp_factor=...,
):
    """Despeckle_ia(in_radar_data, {[polarization_band,...]}, {filter_type}, {filter_size}, {noise_model}, {noise_variance}, {add_noise_mean}, {mult_noise_mean}, {number_of_looks}, {damp_factor})

    Corrects the input synthetic aperture radar (SAR) data for speckle,  which is a result of coherent illumination that resembles a grainy or salt and pepper effect.

    Arguments:
    in_radar_data -- The input radar data.
    polarization_band -- The polarization bands that will be filtered.
    filter_type -- Specifies the type of smoothing algorithm or filter that will be applied.
    filter_size -- Specifies the size of the pixel window that will be used to filter noise.
    noise_model -- Specifies the type of noise that is reducing the quality of the radar image.
    noise_variance -- The noise variance of the radar image. The default is 0.25.
    add_noise_mean -- The mean value of additive noise. A larger noise mean value will produce less smoothing, while a smaller value results in more smoothing. The default value is 0.
    mult_noise_mean -- The mean value of multiplicative noise. A larger noise mean value will produce less smoothing, while a smaller value results in more smoothing. The default value is 1.
    number_of_looks -- The number of looks value of the image, which controls image smoothing and estimates noise variance. A smaller value results in more smoothing, while a larger value retains more image features. The default value is 1.
    damp_factor -- The exponential damping level of smoothing that will be applied. A damping value greater than 1 will result in better edge preservation but less smoothing. Values less than 1 will result in more smoothing. A value of 0 will produce results similar to a low-pass filter. The default is 1.

    Results:
    out_radar_data -- Output Radar Data"""
    ...

def DetectChangeUsingChangeAnalysisRaster(
    in_change_analysis_raster,
    change_type,
    max_number_changes=...,
    segment_date=...,
    change_direction=...,
    filter_by_year=...,
    min_year=...,
    max_year=...,
    filter_by_duration=...,
    min_duration=...,
    max_duration=...,
    filter_by_magnitude=...,
    min_magnitude=...,
    max_magnitude=...,
    filter_by_start_value=...,
    min_start_value=...,
    max_start_value=...,
    filter_by_end_value=...,
    min_end_value=...,
    max_end_value=...,
):
    """DetectChangeUsingChangeAnalysisRaster_ia(in_change_analysis_raster, change_type, {max_number_changes}, {segment_date}, {change_direction}, {filter_by_year}, {min_year}, {max_year}, {filter_by_duration}, {min_duration}, {max_duration}, {filter_by_magnitude}, {min_magnitude}, {max_magnitude}, {filter_by_start_value}, {min_start_value}, {max_start_value}, {filter_by_end_value}, {min_end_value}, {max_end_value})

    Generates a raster containing pixel change information using the output change analysis raster from the Analyze Changes Using CCDC tool or the Analyze Changes Using LandTrendr tool.

    Arguments:
    in_change_analysis_raster -- The change analysis raster generated from the Analyze Changes Using CCDC tool or the Analyze Changes Using LandTrendr tool.
    change_type -- Specifies the change information that will be calculated for each pixel.
    max_number_changes -- The maximum number of changes per pixel that will be calculated. This number corresponds to the number of bands in the output raster. The default is 1, meaning only one change date will be calculated, and the output raster will contain only one band.
    segment_date -- Specifies whether the date at the beginning of a change segment will be extracted or at the end.
    change_direction -- Specifies the direction of change that will be included in the analysis.
    filter_by_year -- Specifies whether the output will be filtered by a range of years.
    min_year -- The earliest year that will be used to filter results. This parameter is required if the Filter by Year parameter is checked.
    max_year -- The latest year that will be used to filter results.
    filter_by_duration -- Specifies whether results will be filtered by the change duration.
    min_duration -- The minimum number of consecutive years that will be included in the results.
    max_duration -- The maximum number of consecutive years that will be included in the results.
    filter_by_magnitude -- Specifies whether results will be filtered by change magnitude.
    min_magnitude -- The minimum magnitude that will be included in the results.
    max_magnitude -- The maximum magnitude that will be included in the results.
    filter_by_start_value -- Specifies whether results will be filtered by start value.
    min_start_value -- The minimum start value that will be included in the results.
    max_start_value -- The maximum start value that will be included in the results.
    filter_by_end_value -- Specifies whether results will be filtered by end value.
    min_end_value -- The minimum end value that will be included in the results.
    max_end_value -- The maximum end value that will be included in the results.

    Results:
    out_raster -- Output Raster"""
    ...

def DetectChangeUsingDeepLearning(
    from_raster, to_raster, in_model_definition, arguments=...
):
    """DetectChangeUsingDeepLearning_ia(from_raster, to_raster, in_model_definition, {arguments})

    Runs a trained deep learning model to detect change between two rasters.

    Arguments:
    from_raster -- The input raster before the change.
    to_raster -- The input raster after the change.
    in_model_definition -- The Model Definition parameter value can be an Esri model definition JSON file (.emd), a JSON string, or a deep learning model package (.dlpk). A JSON string is useful when this tool is used on the server so you can paste the JSON string rather than upload the .emd file. The .dlpk file must be stored locally.
    arguments -- The function arguments are defined in the Python raster function class. This is where you list additional deep learning parameters and arguments for experiments and refinement, such as a confidence threshold for adjusting sensitivity. The names of the arguments are populated from reading the Python module.

    Results:
    out_classified_raster -- Output Classified Raster"""
    ...

def DetectObjectsUsingDeepLearning(
    in_raster,
    out_detected_objects,
    in_model_definition,
    arguments=...,
    run_nms=...,
    confidence_score_field=...,
    class_value_field=...,
    max_overlap_ratio=...,
    processing_mode=...,
):  # -> Any:
    """DetectObjectsUsingDeepLearning_ia(in_raster, out_detected_objects, in_model_definition, {arguments}, {run_nms}, {confidence_score_field}, {class_value_field}, {max_overlap_ratio}, {processing_mode})

    Runs a trained deep learning model on an input raster to produce a feature class containing the objects it finds. The features can be bounding boxes or polygons around the objects found or points at the centers of the objects.

    Arguments:
    in_raster -- The input image used to detect objects. The input can be a single raster or multiple rasters in a mosaic dataset, image service, or folder of images. A feature class with image attachments is also supported.
    out_detected_objects -- The output feature class that will contain geometries circling the object or objects detected in the input image.
    in_model_definition -- This parameter can be an Esri model definition JSON file (.emd), a JSON string, or a deep learning model package (.dlpk). A JSON string is useful when this tool is used on the server so you can paste the JSON string rather than upload the .emd file. The .dlpk file must be stored locally.
    arguments -- The function arguments defined in the Python raster function class. This is where additional deep learning parameters and arguments for experiments and refinement are listed, such as a confidence threshold for adjusting the sensitivity. The names of the arguments are populated from the Python module.
    run_nms -- Specifies whether nonmaximum suppression will be performed in which duplicate objects are identified and the duplicate features with lower confidence value are removed.
    confidence_score_field -- The name of the field in the feature class that will contain the confidence scores as output by the object detection method.
    class_value_field -- The name of the class value field in the input feature class.
    max_overlap_ratio -- The maximum overlap ratio for two overlapping features, which is defined as the ratio of intersection area over union area. The default is 0.
    processing_mode -- Specifies how all raster items in a mosaic dataset or an image service will be processed. This parameter is applied when the input raster is a mosaic dataset or an image service.
    """
    ...

def Diff(in_raster_or_constant1, in_raster_or_constant2):
    """Diff_ia(in_raster_or_constant1, in_raster_or_constant2)

    Determines which values from the first input are logically different from the values of the second input on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input to which the second input will be compared.
    in_raster_or_constant2 -- The input to which the first input will be compared.

    Results:
    out_raster -- Output raster"""
    ...

def DimensionalMovingStatistics(
    in_raster,
    dimension=...,
    backward_window=...,
    forward_window=...,
    nodata_handling=...,
    statistics_type=...,
    percentile_value=...,
    percentile_interpolation_type=...,
    circular_wrap_value=...,
):
    """DimensionalMovingStatistics_ia(in_raster, {dimension}, {backward_window}, {forward_window}, {nodata_handling}, {statistics_type}, {percentile_value}, {percentile_interpolation_type}, {circular_wrap_value})

    Calculates statistics over a moving window on multidimensional data along a specified dimension.

    Arguments:
    in_raster -- The input raster can only be a multidimensional raster in Cloud Raster Format (.crf file).
    dimension -- The name of the dimension along which the window will move.
    backward_window -- The value of how many slices before or above to be included in the defined window. The value must be a positive integer from 1 to 100. The default value is 1.
    forward_window -- The value of how many slices after or below to be included in the defined window. The value must be a positive integer from 1 to 100. The default value is 1.
    nodata_handling -- Specifies how NoData values will be handled by the statistic calculation.
    statistics_type -- Specifies the statistic type to be calculated.
    percentile_value -- The percentile value that will be calculated. The default is 90, for the 90th percentile.
    percentile_interpolation_type -- Specifies the method of interpolation that will be used when the percentile value falls between two cell values.
    circular_wrap_value -- The value that will be used to convert a linear value to the range of a given circular mean. Its value must be positive. The default value is 360 degrees.

    Results:
    out_raster -- Output Multidimensional Raster"""
    ...

def Divide(in_raster_or_constant1, in_raster_or_constant2):
    """Divide_ia(in_raster_or_constant1, in_raster_or_constant2)

    Divides the values of two rasters on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input whose values will be divided by the second input.
    in_raster_or_constant2 -- The input whose values the first input are to be divided by.

    Results:
    out_raster -- Output raster"""
    ...

def DownloadOrbitFile(
    in_radar_data, orbit_type=..., username=..., password=...
):  # -> Any:
    """DownloadOrbitFile_ia(in_radar_data, {orbit_type}, {username}, {password})

    Downloads the updated orbit  files for the  input synthetic aperture radar (SAR) data.

    Arguments:
    in_radar_data -- The input radar data.
    orbit_type -- Specifies the orbit state vector type that will be downloaded.
    username -- The username credential.
    password -- The password credential."""
    ...

def EqualTo(in_raster_or_constant1, in_raster_or_constant2):
    """EqualTo_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Relational equal-to operation on two inputs on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input that will be compared to for equality by the second input.
    in_raster_or_constant2 -- The input that will be compared from for equality by the first input.

    Results:
    out_raster -- Output raster"""
    ...

def Exp(in_raster_or_constant):
    """Exp_ia(in_raster_or_constant)

    Calculates the base e exponential of the cells in a raster.

    Arguments:
    in_raster_or_constant -- The input values for which to find the base e exponential.

    Results:
    out_raster -- Output raster"""
    ...

def Exp10(in_raster_or_constant):
    """Exp10_ia(in_raster_or_constant)

    Calculates the base 10 exponential of the cells in a raster.

    Arguments:
    in_raster_or_constant -- The input values for which to find the base 10 exponential.

    Results:
    out_raster -- Output raster"""
    ...

def Exp2(in_raster_or_constant):
    """Exp2_ia(in_raster_or_constant)

    Calculates the base 2 exponential of the cells in a raster.

    Arguments:
    in_raster_or_constant -- The input values for which to find the base 2 exponential.

    Results:
    out_raster -- Output raster"""
    ...

def ExportTrainingDataForDeepLearning(
    in_raster,
    out_folder,
    in_class_data=...,
    image_chip_format=...,
    tile_size_x=...,
    tile_size_y=...,
    stride_x=...,
    stride_y=...,
    output_nofeature_tiles=...,
    metadata_format=...,
    start_index=...,
    class_value_field=...,
    buffer_radius=...,
    in_mask_polygons=...,
    rotation_angle=...,
    reference_system=...,
    processing_mode=...,
    blacken_around_feature=...,
    crop_mode=...,
    in_raster2=...,
    in_instance_data=...,
    instance_class_value_field=...,
    min_polygon_overlap_ratio=...,
):  # -> Any:
    """ExportTrainingDataForDeepLearning_ia(in_raster, out_folder, {in_class_data}, {image_chip_format}, {tile_size_x}, {tile_size_y}, {stride_x}, {stride_y}, {output_nofeature_tiles}, {metadata_format}, {start_index}, {class_value_field}, {buffer_radius}, {in_mask_polygons}, {rotation_angle}, {reference_system}, {processing_mode}, {blacken_around_feature}, {crop_mode}, {in_raster2}, {in_instance_data}, {instance_class_value_field}, {min_polygon_overlap_ratio})

    Converts labeled vector or raster data into deep learning training datasets using a remote sensing image. The output will be a folder of image chips and a folder of metadata files in the specified format.

    Arguments:
    in_raster -- The input source imagery, typically multispectral imagery.
    out_folder -- The folder where the output image chips and metadata will be stored.
    in_class_data -- The training sample data in either vector or raster form. Vector inputs should follow the training sample format generated using the Training Samples Manager pane. Raster inputs should follow a classified raster format generated by the Classify Raster tool.
    image_chip_format -- Specifies the raster format that will be used for the image chip outputs.
    tile_size_x -- The size of the image chips for the x dimension.
    tile_size_y -- The size of the image chips for the y dimension.
    stride_x -- The distance to move in the x direction when creating the next image chips.
    stride_y -- The distance to move in the y direction when creating the next image chips.
    output_nofeature_tiles -- Specifies whether image chips that do not capture training samples will be exported.
    metadata_format -- Specifies the format that will be used for the output metadata labels.
    start_index -- This parameter has been deprecated.
    class_value_field -- The field that contains the class values. If no field is specified, the system searches for a value or classvalue field. If the feature does not contain a class field, the system determines that all records belong to one class.
    buffer_radius -- The radius of a buffer around each training sample that will be used to delineate a training sample area. This allows you to create circular polygon training samples from points.
    in_mask_polygons -- A polygon feature class that delineates the area where image chips will be created.
    rotation_angle -- The rotation angle that will be used to generate additional image chips.
    reference_system -- Specifies the type of reference system that will be used to interpret the input image. The reference system specified must match the reference system used to train the deep learning model.
    processing_mode -- Specifies how all raster items in a mosaic dataset or an image service will be processed. This parameter is applied when the input raster is a mosaic dataset or an image service.
    blacken_around_feature -- Specifies whether the pixels around each object or feature in each image tile will be masked out.
    crop_mode -- Specifies whether the exported tiles will be cropped so that they are all the same size.
    in_raster2 -- An additional input imagery source that will be used for image translation methods.
    in_instance_data -- The training sample data collected that contains classes for instance segmentation.
    instance_class_value_field -- The field that contains the class values for instance segmentation. If no field is specified, the tool will use a value or class value field, if one is present. If the feature does not contain a class field, the tool will determine that all records belong to one class.
    min_polygon_overlap_ratio -- The minimum overlap percentage for a feature to be included in the training data. If the percentage overlap is less than the value specified, the feature will be excluded from the training chip, and will not be added to the label file.
    """
    ...

def ExtractFeaturesUsingAIModels(
    in_raster,
    mode,
    out_location,
    out_prefix,
    area_of_interest=...,
    pretrained_models=...,
    additional_models=...,
    confidence_threshold=...,
    save_intermediate_output=...,
    test_time_augmentation=...,
    buffer_distance=...,
    extend_length=...,
    smoothing_tolerance=...,
    dangle_length=...,
    in_road_features=...,
    road_buffer_width=...,
    regularize_parcels=...,
    post_processing_workflow=...,
    out_features=...,
    parcel_tolerance=...,
    regularization_method=...,
    poly_tolerance=...,
):  # -> Any:
    """ExtractFeaturesUsingAIModels_ia(in_raster, mode, out_location, out_prefix, {area_of_interest}, {[pretrained_model,...]}, {additional_models}, {confidence_threshold}, {save_intermediate_output}, {test_time_augmentation}, {buffer_distance}, {extend_length}, {smoothing_tolerance}, {dangle_length}, {in_road_features}, {road_buffer_width}, {regularize_parcels}, {post_processing_workflow}, {out_features}, {parcel_tolerance}, {regularization_method}, {poly_tolerance})

    Runs one or more pretrained deep learning models on an input raster to extract features and automate the postprocessing of the inferenced outputs.

    Arguments:
    in_raster -- The input raster on which processing will be performed.
    mode -- Specifies the mode that will be used for the processing of the input raster.
    out_location -- The file geodatabase where the intermediate output from the models and the final postprocessed output will be stored.
    out_prefix -- A prefix that will be added to the name of the outputs that will be saved to the output location. The prefix will also be used as the name of a group layer that will be used to display all outputs.
    area_of_interest -- The geographical extent that will be used to extract features. Only features within the area of interest will be extracted.
    pretrained_model -- The ArcGIS pretrained models from ArcGIS Living Atlas of the World that can be used on the provided input raster. This parameter requires internet connection to download the pretrained models.
    additional_models -- The deep learning models that can be used on the provided input raster and the postprocessing workflow that will be used for additional model files (.dlpk and .emd). Available postprocessing workflow are as follows:
    confidence_threshold -- The minimum confidence of deep learning model that will be used when detecting objects. The value must be between 0 and 1.
    save_intermediate_output -- Specifies whether the intermediate outputs will be saved to the output location. The term intermediate outputs refers to the results generated after the model has been inferenced.
    test_time_augmentation -- Specifies whether predictions of flipped and rotated variants of the input image will be merged into the final output.
    buffer_distance -- The distance that will be used to buffer polyline features before they are used in postprocessing. The default is 15 meters.
    extend_length -- The maximum distance a line segment will be extended to an intersecting feature. The default is 25 meters.
    smoothing_tolerance -- The tolerance used by the Polynomial Approximation with Exponential Kernel (PAEK) algorithm. The default is 30 meters.
    dangle_length -- The length at which line segments that do not touch another line at both endpoints (dangles) will be trimmed. The default is 5 meters.
    in_road_features -- A road feature class that will be used for refining the parcels. The input can be a polygon or polyline feature class.
    road_buffer_width -- The buffer distance that will be used for the Input Road Features value. The default value is 5 meters for polyline features and 0 meters for polygon features.
    regularize_parcels -- Specifies whether extracted parcels will be normalized by eliminating undesirable artifacts in their geometry.
    post_processing_workflow -- Specifies the postprocessing workflow that will be used.
    out_features -- The feature class containing the postprocessed output.
    parcel_tolerance -- The minimum distance between coordinates before they are considered equal. This parameter is used to reduce slivers between extracted parcels. The default is 3 meters.
    regularization_method -- Specifies the regularization method that will be used in postprocessing.
    poly_tolerance -- The maximum distance that the regularized footprint can deviate from the boundary of its originating feature. The default is 1 meter.
    """
    ...

def ExtractVideoFramesToImages(
    in_video,
    out_folder,
    image_type=...,
    image_overlap=...,
    require_fresh_metadata=...,
    min_time=...,
):  # -> Any:
    """ExtractVideoFramesToImages_ia(in_video, out_folder, {image_type}, {image_overlap}, {require_fresh_metadata}, {min_time})

    Extracts video frame images and associated metadata from a FMV-compliant video stream.  The extracted images can be added to a mosaic dataset or other tools and functions for further analysis.

    Arguments:
    in_video -- The input video file in any of the supported video file formats, including PS, TS, MPG, MPEG, MP2, MPG2, MPEG2, MP4, MPG4, MPEG4, H264, VOB, and M2TS.
    out_folder -- The file directory where the output images and metadata will be saved.
    image_type -- Specifies the output image format.
    image_overlap -- The maximum overlap percentage between two images. If the overlap between a candidate image and the last image written to disk is greater than this value, the candidate image will be ignored. The default percentage is 100 percent, which writes all images to disk.
    require_fresh_metadata -- Specifies whether video frames with associated metadata will be extracted and saved.
    min_time -- The minimum time interval between video frames to be saved. If this is not specified, all video frames will be saved as images.
    """
    ...

def FindArgumentStatistics(
    in_raster,
    dimension=...,
    dimension_def=...,
    interval_keyword=...,
    variables=...,
    statistics_type=...,
    min=...,
    max=...,
    multiple_occurrence=...,
    ignore_nodata=...,
    value=...,
    comparison=...,
    occurrence=...,
):
    """FindArgumentStatistics_ia(in_raster, {dimension}, {dimension_def}, {interval_keyword}, {[variable,...]}, {statistics_type}, {min}, {max}, {multiple_occurrence}, {ignore_nodata}, {value}, {comparison}, {occurrence})

    Extracts the dimension value or band index at which a given statistic is attained for each pixel in a multidimensional or multiband raster.

    Arguments:
    in_raster -- The input multidimensional or multiband raster to be analyzed.
    dimension -- The dimension from which the statistic will be extracted. If the input raster is not a multidimensional raster, this parameter is not required.
    dimension_def -- Specifies how the statistic will be extracted from the dimension.
    interval_keyword -- The unit of time for which the statistic will be extracted.
    variable -- The variable or variables to be analyzed. If the input raster is not multidimensional, the pixel values of the multiband raster are considered the variable. If the input raster is multidimensional and no variable is specified, all variables with the selected dimension will be analyzed.
    statistics_type -- Specifies the statistic to extract from the variable or variables along the given dimension.
    min -- The minimum variable value to be used to extract the duration.
    max -- The maximum variable value to be used to extract the duration.
    multiple_occurrence -- The pixel value to use to indicate that a given argument statistic was reached more than once in the input raster dataset. If not specified, the pixel value will be the value of the dimension as specified by the Occurrence parameter, either the first or last occurrence.
    ignore_nodata -- Specifies whether NoData values will be ignored in the analysis.
    value -- The value at which a comparison will be made to extract the dimension value.
    comparison -- Specifies the comparison type that will be used to extract the dimension value.
    occurrence -- Specifies whether the value of the dimension will be returned the first time or last time the argument statistic is reached.

    Results:
    out_raster -- Output Raster"""
    ...

def Float(in_raster_or_constant):
    """Float_ia(in_raster_or_constant)

    Converts each cell value of a raster into a floating-point representation.

    Arguments:
    in_raster_or_constant -- The input raster to be converted to floating point.

    Results:
    out_raster -- Output raster"""
    ...

def FocalStatistics(
    in_raster,
    neighborhood=...,
    statistics_type=...,
    ignore_nodata=...,
    percentile_value=...,
):
    """FocalStatistics_ia(in_raster, {neighborhood}, {statistics_type}, {ignore_nodata}, {percentile_value})

    Calculates for each input cell location a statistic of the values within a specified neighborhood around it.

    Arguments:
    in_raster -- The raster for which the focal statistics for each input cell will be calculated.
    neighborhood -- The cells surrounding a processing cell that will be used in the statistic calculation. There are several predefined neighborhood types to choose from, or a custom kernel can be defined.
    statistics_type -- Specifies the statistic type to be calculated.
    ignore_nodata -- Specifies whether NoData values will be ignored by the statistic calculation.
    percentile_value -- The percentile value that will be calculated. The default is 90, for the 90th percentile.

    Results:
    out_raster -- Output raster"""
    ...

def GenerateMultidimensionalAnomaly(
    in_multidimensional_raster,
    variables=...,
    method=...,
    calculation_interval=...,
    ignore_nodata=...,
    reference_mean_raster=...,
):
    """GenerateMultidimensionalAnomaly_ia(in_multidimensional_raster, {[variable,...]}, {method}, {calculation_interval}, {ignore_nodata}, {reference_mean_raster})

    Computes the anomaly for each slice in an existing multidimensional raster to generate a new multidimensional raster.

    Arguments:
    in_multidimensional_raster -- The input multidimensional raster dataset.
    variable -- The variable or variables for which anomalies will be calculated. If no variable is specified, all variables with a time dimension will be analyzed.
    method -- Specifies the method that will be used to calculate the anomaly.
    calculation_interval -- Specifies the temporal interval that will be used to calculate the mean.
    ignore_nodata -- Specifies whether NoData values will be ignored in the analysis.
    reference_mean_raster -- The reference raster dataset that contains a previously calculated mean for each pixel. The anomalies will be calculated in comparison to this mean.

    Results:
    out_multidimensional_raster -- Output Multidimensional Raster"""
    ...

def GenerateTrainingSamplesFromSeedPoints(
    in_class_data,
    in_seed_points,
    out_training_feature_class,
    min_sample_area=...,
    max_sample_radius=...,
):  # -> Any:
    """GenerateTrainingSamplesFromSeedPoints_ia(in_class_data, in_seed_points, out_training_feature_class, {min_sample_area}, {max_sample_radius})

    Generates training samples from seed points, such as accuracy assessment points or training sample points. A typical use case is generating training samples from an existing source, such as a thematic raster or a feature class.

    Arguments:
    in_class_data -- The data source that labels the training samples.
    in_seed_points -- A point shapefile or feature class to provide the centers of training sample polygons.
    out_training_feature_class -- The output training sample feature class in the format that can be used in training tools, including shapefiles. The output feature class can be either a polygon feature class or a point feature class.
    min_sample_area -- The minimum area needed for each training sample, in square meters. The minimum value must be greater than or equal to 0.
    max_sample_radius -- The longest distance (in meters) from any point within the training sample to its center seed point. If set to 0, the output training sample will be points instead of polygons. The minimum value must be greater than or equal to 0.
    """
    ...

def GenerateTrendRaster(
    in_multidimensional_raster,
    dimension,
    variables=...,
    line_type=...,
    frequency=...,
    ignore_nodata=...,
    cycle_length=...,
    cycle_unit=...,
    rmse=...,
    r2=...,
    slope_p_value=...,
    seasonal_period=...,
):
    """GenerateTrendRaster_ia(in_multidimensional_raster, dimension, {[variable,...]}, {line_type}, {frequency}, {ignore_nodata}, {cycle_length}, {cycle_unit}, {rmse}, {r2}, {slope_p_value}, {seasonal_period})

    Estimates the trend for each pixel along a dimension for one or more variables in a multidimensional raster.

    Arguments:
    in_multidimensional_raster -- The input multidimensional raster dataset.
    dimension -- The dimension along which a trend will be extracted for the variable or variables selected in the analysis.
    variable -- The variable or variables for which trends will be calculated. If no variable is specified, the first variable in the multidimensional raster will be analyzed.
    line_type -- Specifies the type of trend analysis to perform to pixel values along a dimension.
    frequency -- The frequency or the polynomial order number to use in the trend fitting. If the trend type is polynomial, this parameter specifies the polynomial order. If the trend type is harmonic, this parameter specifies the number of models to use to fit the trend.
    ignore_nodata -- Specifies whether NoData values will be ignored in the analysis.
    cycle_length -- The length of periodic variation to model. This parameter is required when Trend Type is set to Harmonic. For example, leaf greenness often has one strong cycle of variation in a single year, so the cycle length is 1 year. Hourly temperature data has one strong cycle of variation throughout a single day, so the cycle length is 1 day.
    cycle_unit -- Specifies the time unit to be used for the length of a harmonic cycle.
    rmse -- Specifies whether the root mean square error (RMSE) of the trend fit line will be calculated.
    r2 -- Specifies whether the R-squared goodness-of-fit statistic for the trend fit line will be calculated.
    slope_p_value -- Specifies whether the p-value statistic for the slope coefficient of the trend line will be calculated.
    seasonal_period -- Specifies the time unit to be used for the length of a seasonal period when performing the Seasonal-Kendall test.

    Results:
    out_multidimensional_raster -- Output Multidimensional Raster"""
    ...

def GreaterThan(in_raster_or_constant1, in_raster_or_constant2):
    """GreaterThan_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Relational greater-than operation on two inputs on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input being tested to determine if it is greater than the second input.
    in_raster_or_constant2 -- The input against which the first input is tested to be greater than.

    Results:
    out_raster -- Output raster"""
    ...

def GreaterThanEqual(in_raster_or_constant1, in_raster_or_constant2):
    """GreaterThanEqual_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Relational greater-than-or-equal-to operation on two inputs on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input being tested to determine if it is greater than or equal to the second input.
    in_raster_or_constant2 -- The input against which the first input is tested to be greater than or equal to.

    Results:
    out_raster -- Output raster"""
    ...

def InList(in_raster_or_constant, in_raster_or_constants, process_as_multiband=...):
    """InList_ia(in_raster_or_constant, [in_raster_or_constant,...], {process_as_multiband})

    Determines which values from the first input are contained in a set of other inputs, on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant -- The input that defines the value that will be looked for in a list of rasters on a cell-by-cell basis.
    in_raster_or_constant -- A list of input rasters that the first input will be evaluated against. For each location, if the cell value from the first input exists in any of the other rasters, that value will be assigned to the output raster. If the value does not exist in any of the other rasters, the output value at that location will be NoData.
    process_as_multiband -- Specifies how the input multiband raster bands will be processed.

    Results:
    out_raster -- Output raster"""
    ...

def InspectTrainingSamples(
    in_raster,
    in_training_features,
    in_classifier_definition,
    out_training_feature_class,
    in_additional_raster=...,
):
    """InspectTrainingSamples_ia(in_raster, in_training_features, in_classifier_definition, out_training_feature_class, {in_additional_raster})

    Estimates the accuracy of individual training samples. The cross validation accuracy is computed using the previously generated classification training result in an .ecd file and the training samples. Outputs include a raster dataset containing the misclassified class values and a training sample dataset with the accuracy score for each training sample.

    Arguments:
    in_raster -- The input raster to be classified.
    in_training_features -- A training sample feature class created in the Training Samples Manager pane.
    in_classifier_definition -- The .ecd output classifier file from any of the train classifier tools. The .ecd file is a JSON file that contains attribute information, statistics, or other information needed for the classifier.
    out_training_feature_class -- The output individual training samples saved as a feature class. The associated attribute table contains an addition field listing the accuracy score.
    in_additional_raster -- Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for the classifier. This raster is necessary when calculating attributes such as mean or standard deviation. This parameter is optional.

    Results:
    out_misclassified_raster -- Output Misclassified Raster"""
    ...

def Int(in_raster_or_constant):
    """Int_ia(in_raster_or_constant)

    Converts each cell value of a raster to an integer by truncation.

    Arguments:
    in_raster_or_constant -- The input raster to be converted to integer.

    Results:
    out_raster -- Output raster"""
    ...

def InterpolateFromSpatiotemporalPoints(
    in_dataset,
    variable_field,
    time_field,
    temporal_aggregation,
    cell_size,
    interpolation_method,
):
    """InterpolateFromSpatiotemporalPoints_ia(in_dataset, variable_field, time_field, temporal_aggregation, cell_size, interpolation_method)

    Interpolates temporal point data into a multidimensional raster.

    Arguments:
    in_dataset -- The input point layer, trajectory file, or trajectory mosaic dataset.
    variable_field -- A field containing variable values.
    time_field -- A field containing time values.
    temporal_aggregation -- Specifies the temporal aggregation of the output multidimensional raster. The interpolation algorithm uses all available data within these time periods to calculate the output slice.
    cell_size -- The output cell size. By default, the cell size will be the shorter of the width or the height of the input point feature extent, divided by 250.
    interpolation_method -- Specifies the interpolation method that will be used.

    Results:
    out_raster -- Output Raster"""
    ...

def IsNull(in_raster):
    """IsNull_ia(in_raster)

    Determines which values from the input raster are NoData on a cell-by-cell basis.

    Arguments:
    in_raster -- The input raster being tested to identify the cells that are NoData (null).

    Results:
    out_raster -- Output raster"""
    ...

def LessThan(in_raster_or_constant1, in_raster_or_constant2):
    """LessThan_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Relational less-than operation on two inputs on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input being tested to determine if it is less than the second input.
    in_raster_or_constant2 -- The input against which the first input is tested to be less than.

    Results:
    out_raster -- Output raster"""
    ...

def LessThanEqual(in_raster_or_constant1, in_raster_or_constant2):
    """LessThanEqual_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Relational less-than-or-equal-to operation on two inputs on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input being tested to determine if it is less than or equal to the second input.
    in_raster_or_constant2 -- The input against which the first input is tested to be less than or equal to.

    Results:
    out_raster -- Output raster"""
    ...

def LinearSpectralUnmixing(in_raster, in_spectral_profile_file, value_option=...):
    """LinearSpectralUnmixing_ia(in_raster, in_spectral_profile_file, {[value_option,...]})

    Performs subpixel classification and calculates the fractional abundance of different land-cover types for individual pixels.

    Arguments:
    in_raster -- The input raster dataset.
    in_spectral_profile_file -- The spectral information for the different land-cover classes.
    value_option -- Specifies how the output pixel values will be defined.

    Results:
    out_raster -- Output Raster"""
    ...

def Ln(in_raster_or_constant):
    """Ln_ia(in_raster_or_constant)

    Calculates the natural logarithm (base e) of cells in a raster.

    Arguments:
    in_raster_or_constant -- Input values for which to find the natural logarithm (Ln).

    Results:
    out_raster -- Output raster"""
    ...

def Log10(in_raster_or_constant):
    """Log10_ia(in_raster_or_constant)

    Calculates the base 10 logarithm of cells in a raster.

    Arguments:
    in_raster_or_constant -- Input values for which to find the base 10 logarithm.

    Results:
    out_raster -- Output raster"""
    ...

def Log2(in_raster_or_constant):
    """Log2_ia(in_raster_or_constant)

    Calculates the base 2 logarithm of cells in a raster.

    Arguments:
    in_raster_or_constant -- Input values for which to find the base 2 logarithm.

    Results:
    out_raster -- Output raster"""
    ...

def Minus(in_raster_or_constant1, in_raster_or_constant2):
    """Minus_ia(in_raster_or_constant1, in_raster_or_constant2)

    Subtracts the value of the second input raster from the value of the first input raster on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input from which to subtract the values in the second input.
    in_raster_or_constant2 -- The input values to subtract from the values in the first input.

    Results:
    out_raster -- Output raster"""
    ...

def Mod(in_raster_or_constant1, in_raster_or_constant2):
    """Mod_ia(in_raster_or_constant1, in_raster_or_constant2)

    Finds the remainder (modulo) of the first raster when divided by the second raster on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The numerator input.
    in_raster_or_constant2 -- The denominator input.

    Results:
    out_raster -- Output raster"""
    ...

def MultidimensionalPrincipalComponents(
    in_multidimensional_raster,
    mode,
    dimension,
    out_pc,
    out_loadings,
    out_eigenvalues=...,
    variable=...,
    number_of_pc=...,
):  # -> Any:
    """MultidimensionalPrincipalComponents_ia(in_multidimensional_raster, mode, dimension, out_pc, out_loadings, {out_eigenvalues}, {variable}, {number_of_pc})

    Transforms multidimensional rasters into  their principal components, loadings, and eigenvalues. The tool transforms the data into a reduced number of components that account for the variance of the data, so that spatial and temporal patterns can be readily identified.

    Arguments:
    in_multidimensional_raster -- The input multidimensional raster.
    mode -- Specifies the method that will be used to perform principal component analysis.
    dimension -- The dimension name used to process the principal components.
    out_pc -- The name of the output raster dataset.
    out_loadings -- The output loadings data contributing to the principal components.
    out_eigenvalues -- The output Eigenvalues table. Eigenvalues are values indicating the variance percentage of each component. Eigenvalues help you define the number of principal components that are needed to represent the dataset.
    variable -- The variable of the input multidimensional raster used in computation. If the input raster is multidimensional and no variable is specified, only the first variable will be analyzed, by default.
    number_of_pc -- The number of principal components to compute, usually fewer than the number of input rasters.
    """
    ...

def Negate(in_raster_or_constant):
    """Negate_ia(in_raster_or_constant)

    Changes the sign (multiplies by -1) of the cell values of the input raster on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant -- The input raster to be negated (multiplied by -1).

    Results:
    out_raster -- Output raster"""
    ...

def NonMaximumSuppression(
    in_featureclass,
    confidence_score_field,
    out_featureclass,
    class_value_field=...,
    max_overlap_ratio=...,
):  # -> Any:
    """NonMaximumSuppression_ia(in_featureclass, confidence_score_field, out_featureclass, {class_value_field}, {max_overlap_ratio})

    Identifies duplicate features from the output of the Detect Objects Using Deep Learning tool as a postprocessing step and creates a new output with no duplicate features. The Detect Objects Using Deep Learning tool can return more than one bounding box or polygon for the same object, especially as a tiling side effect. If two features overlap more than a given maximum ratio, the feature with the lower confidence value will be removed.

    Arguments:
    in_featureclass -- The input feature class or feature layer containing overlapping or duplicate features.
    confidence_score_field -- The field in the feature class that contains the confidence scores as output by the object detection method.
    out_featureclass -- The output feature class with the duplicate features removed.
    class_value_field -- The class value field in the input feature class. If not specified, the tool will use the standard class value fields Classvalue and Value. If these fields do not exist, all features will be treated as the same object class.
    max_overlap_ratio -- The maximum overlap ratio for two overlapping features. This is defined as the ratio of intersection area over union area. The default is 0.
    """
    ...

def NotEqual(in_raster_or_constant1, in_raster_or_constant2):
    """NotEqual_ia(in_raster_or_constant1, in_raster_or_constant2)

    Performs a Relational not-equal-to operation on two inputs on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input that will be compared to for inequality by the second input.
    in_raster_or_constant2 -- The input that will be compared from for inequality by the first input.

    Results:
    out_raster -- Output raster"""
    ...

def Over(in_raster_or_constant1, in_raster_or_constant2):
    """Over_ia(in_raster_or_constant1, in_raster_or_constant2)

    For the cell values in the first input that are not 0, the output value will be that of the first input. Where the cell values are 0, the output will be that of the second input raster.

    Arguments:
    in_raster_or_constant1 -- The input for which cell values of 0 will be replaced with the value from the second input.
    in_raster_or_constant2 -- The input whose value will be assigned to the output raster cells where the first input value is 0.

    Results:
    out_raster -- Output raster"""
    ...

def Pick(in_position_raster, in_rasters_or_constants, process_as_multiband=...):
    """Pick_ia(in_position_raster, [in_rasters_or_constant,...], {process_as_multiband})

    The value from a position raster is used to determine from which raster in a list of input rasters the output cell value will be obtained.

    Arguments:
    in_position_raster -- The input raster defining the position of the raster to use for the output value.
    in_rasters_or_constant -- The list of inputs from which the output value will be selected.
    process_as_multiband -- Specifies how the input multiband raster bands will be processed.

    Results:
    out_raster -- Output raster"""
    ...

def Plus(in_raster_or_constant1, in_raster_or_constant2):
    """Plus_ia(in_raster_or_constant1, in_raster_or_constant2)

    Adds (sums) the values of two rasters on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input whose values will be added to.
    in_raster_or_constant2 -- The input whose values will be added to the first input.

    Results:
    out_raster -- Output raster"""
    ...

def Power(in_raster_or_constant1, in_raster_or_constant2):
    """Power_ia(in_raster_or_constant1, in_raster_or_constant2)

    Raises the cell values in a raster to the power of the values found in another raster.

    Arguments:
    in_raster_or_constant1 -- The input values to be raised to the power defined by the second input.
    in_raster_or_constant2 -- The input that determines the power the values in the first input will be raised to.

    Results:
    out_raster -- Output raster"""
    ...

def PredictUsingRegressionModel(in_rasters, in_regression_definition):
    """PredictUsingRegressionModel_ia([in_raster,...], in_regression_definition)

    Predicts data values using the output from the Train Random Trees Regression Model tool.

    Arguments:
    in_raster -- The single-band, multidimensional, or multiband raster datasets, or mosaic datasets containing explanatory variables.
    in_regression_definition -- A JSON format file that contains attribute information, statistics, or other information from the regression model. The file has an .ecd extension. The file is the output of the Train Random Trees Regression Model tool.

    Results:
    out_raster_dataset -- Output predicted raster"""
    ...

def PredictUsingTrendRaster(
    in_multidimensional_raster,
    variables=...,
    dimension_def=...,
    dimension_values=...,
    start=...,
    end=...,
    interval_value=...,
    interval_unit=...,
):
    """PredictUsingTrendRaster_ia(in_multidimensional_raster, {[variable,...]}, {dimension_def}, {[dimension_value,...]}, {start}, {end}, {interval_value}, {interval_unit})

    Computes a forecasted multidimensional raster using the output trend raster from the Generate Trend Raster tool.

    Arguments:
    in_multidimensional_raster -- The input multidimensional trend raster from the Generate Trend Raster tool.
    variable -- The variable or variables that will be predicted in the analysis. If no variables are specified, all variables will be used.
    dimension_def -- Specifies the method used to provide prediction dimension values.
    dimension_value -- The dimension value or values to be used in the prediction.
    start -- The start date, height, or depth of the dimension interval to be used in the prediction.
    end -- The end date, height, or depth of the dimension interval to be used in the prediction.
    interval_value -- The number of steps between two dimension values to be included in the prediction. The default value is 1.
    interval_unit -- Specifies the unit that will be used for the interval value. This parameter only applies when the dimension of analysis is a time dimension.

    Results:
    out_multidimensional_raster -- Output Multidimensional Raster"""
    ...

def RemoveRasterSegmentTilingArtifacts(
    in_segmented_raster, tileSizeX=..., tileSizeY=...
):
    """RemoveRasterSegmentTilingArtifacts_ia(in_segmented_raster, {tileSizeX}, {tileSizeY})

    Corrects segments or objects cut by tile boundaries during the segmentation process performed as a raster function. This tool is helpful for some regional processes, such as image segmentation, that have inconsistencies near image tile boundaries.

    Arguments:
    in_segmented_raster -- Select the segmented raster with the tiling artifacts that you want to remove.
    tileSizeX -- Specify the tile width from Segment Mean Shift. If left blank, the default is 512 pixels.
    tileSizeY -- Specify the tile height from Segment Mean Shift. If left blank, the default is 512 pixels.

    Results:
    out_raster_dataset -- Output Segmented Raster"""
    ...

def RemoveThermalNoise(in_radar_data, polarization_bands=...):
    """RemoveThermalNoise_ia(in_radar_data, {[polarization_band,...]})

    Corrects backscatter disturbances caused by thermal noise in the input synthetic aperture radar (SAR) data, resulting in a more seamless image.

    Arguments:
    in_radar_data -- The input radar data.
    polarization_band -- The polarization bands to be corrected.

    Results:
    out_radar_data -- Output Radar Data"""
    ...

def RoundDown(in_raster_or_constant):
    """RoundDown_ia(in_raster_or_constant)

    Returns the next lower integer value, just represented as a floating point, for each cell in a raster.

    Arguments:
    in_raster_or_constant -- The input values to be rounded down.

    Results:
    out_raster -- Output raster"""
    ...

def RoundUp(in_raster_or_constant):
    """RoundUp_ia(in_raster_or_constant)

    Returns the next higher integer value, just represented as a floating point, for each cell in a raster.

    Arguments:
    in_raster_or_constant -- The input values to be rounded up.

    Results:
    out_raster -- Output raster"""
    ...

def Sample(
    in_rasters,
    in_location_data,
    out_table,
    resampling_type=...,
    unique_id_field=...,
    process_as_multidimensional=...,
    acquisition_definition=...,
    statistics_type=...,
    percentile_value=...,
    buffer_distance=...,
    layout=...,
    generate_feature_class=...,
):  # -> Any:
    """Sample_ia([in_raster,...], in_location_data, out_table, {resampling_type}, {unique_id_field}, {process_as_multidimensional}, {acquisition_definition}, {statistics_type}, {percentile_value}, {buffer_distance}, {layout}, {generate_feature_class})

    Creates a table or a point feature class that shows the values of cells from a raster, or a set of rasters, for defined locations. The locations are defined by raster cells, points, polylines, or polygons.

    Arguments:
    in_raster -- The rasters with values that will be sampled based on the input location data.
    in_location_data -- The data identifying positions where a sample will be taken.
    out_table -- The output table or feature class containing the sampled cell values.
    resampling_type -- The resampling algorithm that will be used to sample a raster to determine how the values will be obtained from the raster.
    unique_id_field -- A field containing a different value for every location or feature in the input location raster or features.
    process_as_multidimensional -- Specifies how the input rasters will be processed.
    acquisition_definition -- Specifies the time, depth, or other acquisition data associated with the location features.
    statistics_type -- Specifies the statistic type to be calculated.
    percentile_value -- This value can range from 0 to 100. The default is 90.
    buffer_distance -- The distance around the location data features. The buffer distance is specified in the linear unit of the location feature's spatial reference. If the feature uses a geographic reference, the unit will be degrees.
    layout -- Specifies whether sampled values will appear in rows or columns in the output table.
    generate_feature_class -- Specifies whether a point feature class with sampled values in its attribute table or a table with sampled values will be generated.
    """
    ...

def SegmentMeanShift(
    in_raster,
    spectral_detail=...,
    spatial_detail=...,
    min_segment_size=...,
    band_indexes=...,
    max_segment_size=...,
):
    """SegmentMeanShift_ia(in_raster, {spectral_detail}, {spatial_detail}, {min_segment_size}, {band_indexes}, {max_segment_size})

    Groups into segments adjacent pixels that have similar spectral characteristics.

    Arguments:
    in_raster -- The raster dataset to segment. This can be a multispectral or grayscale image.
    spectral_detail -- The level of importance given to the spectral differences of features in the imagery.
    spatial_detail -- The level of importance given to the proximity between features in the imagery.
    min_segment_size -- The minimum size of a segment. Merge segments smaller than this size with their best fitting neighbor segment. This is related to the minimum mapping unit for your project.
    band_indexes -- The bands that will be used to segment the imagery, separated by a space. If no band indexes are specified, they are determined by the following criteria:
    max_segment_size -- The maximum size of a segment. Segments that are larger than the specified size will be divided. Use this parameter to prevent artifacts in the output raster resulting from large segments.

    Results:
    out_raster_dataset -- Output Raster Dataset"""
    ...

def SetNull(in_conditional_raster, in_false_raster_or_constant, where_clause=...):
    """SetNull_ia(in_conditional_raster, in_false_raster_or_constant, {where_clause})

    Set Null sets identified cell locations to NoData based on a specified criteria. It returns NoData if a conditional evaluation is true, and returns the value specified by another raster if it is false.

    Arguments:
    in_conditional_raster -- The input raster representing the true or false result of the desired condition.
    in_false_raster_or_constant -- The input whose values will be used as the output cell values if the condition is false.
    where_clause -- A logical expression that determines which of the input cells are to be true or false.

    Results:
    out_raster -- Output raster"""
    ...

def Sin(in_raster_or_constant):
    """Sin_ia(in_raster_or_constant)

    Calculates the sine of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the sine values.

    Results:
    out_raster -- Output raster"""
    ...

def SinH(in_raster_or_constant):
    """SinH_ia(in_raster_or_constant)

    Calculates the hyperbolic sine of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the hyperbolic sine values.

    Results:
    out_raster -- Output raster"""
    ...

def Square(in_raster_or_constant):
    """Square_ia(in_raster_or_constant)

    Calculates the square of the cell values in a raster.

    Arguments:
    in_raster_or_constant -- The input values to find the square of.

    Results:
    out_raster -- Output raster"""
    ...

def SquareRoot(in_raster_or_constant):
    """SquareRoot_ia(in_raster_or_constant)

    Calculates the square root of the cell values in a raster.

    Arguments:
    in_raster_or_constant -- The input values to find the square root of.

    Results:
    out_raster -- Output raster"""
    ...

def SummarizeCategoricalRaster(
    in_raster, out_table, dimension=..., aoi=..., aoi_id_field=...
):  # -> Any:
    """SummarizeCategoricalRaster_ia(in_raster, out_table, {dimension}, {aoi}, {aoi_id_field})

    Generates a table containing the pixel count for each class, in each slice of an input categorical raster.

    Arguments:
    in_raster -- The input multidimensional raster of integer type.
    out_table -- The output summary table. Geodatabase, database, text, Microsoft Excel, and comma-separated value (CSV) tables are supported.
    dimension -- The input dimension to use for the summary. If there is more than one dimension and no value is specified, all slices will be summarized using all combinations of dimension values.
    aoi -- The polygon feature layer containing the area or areas of interest to use when calculating the pixel count per category. If no area of interest is specified, the entire raster dataset will be included in the analysis.
    aoi_id_field -- The field in the polygon feature layer that defines each area of interest. Text and integer fields are supported.
    """
    ...

def Tan(in_raster_or_constant):
    """Tan_ia(in_raster_or_constant)

    Calculates the tangent of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input for which to calculate the tangent values.

    Results:
    out_raster -- Output raster"""
    ...

def TanH(in_raster_or_constant):
    """TanH_ia(in_raster_or_constant)

    Calculates the hyperbolic tangent of cells in a raster.

    Arguments:
    in_raster_or_constant -- The input to calculate the hyperbolic tangent values for.

    Results:
    out_raster -- Output raster"""
    ...

def Test(in_raster, where_clause):
    """Test_ia(in_raster, where_clause)

    Performs a Boolean evaluation of the input raster using a logical expression.

    Arguments:
    in_raster -- The input raster on which the Boolean evaluation is performed, based on a logical expression.
    where_clause -- The logical expression that will determine which input cells will return a value of true (1) and which will be false (0).

    Results:
    out_raster -- Output raster"""
    ...

def Times(in_raster_or_constant1, in_raster_or_constant2):
    """Times_ia(in_raster_or_constant1, in_raster_or_constant2)

    Multiplies the values of two rasters on a cell-by-cell basis.

    Arguments:
    in_raster_or_constant1 -- The input containing the values to be multiplied.
    in_raster_or_constant2 -- The input containing the values by which the first input will be multiplied.

    Results:
    out_raster -- Output raster"""
    ...

def TrainDeepLearningModel(
    in_folder,
    out_folder,
    max_epochs=...,
    model_type=...,
    batch_size=...,
    arguments=...,
    learning_rate=...,
    backbone_model=...,
    pretrained_model=...,
    validation_percentage=...,
    stop_training=...,
    freeze=...,
):  # -> Any:
    """TrainDeepLearningModel_ia([in_folder,...], out_folder, {max_epochs}, {model_type}, {batch_size}, {arguments}, {learning_rate}, {backbone_model}, {pretrained_model}, {validation_percentage}, {stop_training}, {freeze})

    Trains a deep learning model using the output from the Export Training Data For Deep Learning tool.

    Arguments:
    in_folder -- The folders containing the image chips, labels, and statistics required to train the model. This is the output from the Export Training Data For Deep Learning tool.
    out_folder -- The output folder location that will store the trained model.
    max_epochs -- The maximum number of epochs for which the model will be trained. A maximum epoch of one means the dataset will be passed forward and backward through the neural network one time. The default value is 20.
    model_type -- Specifies the model type that will be used to train the deep learning model.
    batch_size -- The number of training samples to be processed for training at one time.
    arguments -- The function arguments are defined in the Python raster function class. This is where you list additional deep learning parameters and arguments for experiments and refinement, such as a confidence threshold for adjusting sensitivity. The names of the arguments are populated from reading the Python module.
    learning_rate -- The rate at which existing information will be overwritten with newly acquired information throughout the training process. If no value is specified, the optimal learning rate will be extracted from the learning curve during the training process.
    backbone_model -- Specifies the preconfigured neural network that will be used as the architecture for training the new model. This method is known as Transfer Learning.
    pretrained_model -- A pretrained model that will be used to fine-tune the new model. The input is an Esri model definition file (.emd) or a deep learning package file (.dlpk).
    validation_percentage -- The percentage of training samples that will be used for validating the model. The default value is 10.
    stop_training -- Specifies whether early stopping will be implemented.
    freeze -- Specifies whether the backbone layers in the pretrained model will be frozen, so that the weights and biases remain as originally designed.
    """
    ...

def TrainIsoClusterClassifier(
    in_raster,
    max_classes,
    out_classifier_definition,
    in_additional_raster=...,
    max_iterations=...,
    min_samples_per_cluster=...,
    skip_factor=...,
    used_attributes=...,
    max_merge_per_iter=...,
    max_merge_distance=...,
):  # -> Any:
    """TrainIsoClusterClassifier_ia(in_raster, max_classes, out_classifier_definition, {in_additional_raster}, {max_iterations}, {min_samples_per_cluster}, {skip_factor}, {[used_attribute,...]}, {max_merge_per_iter}, {max_merge_distance})

    Generates an Esri classifier definition file (.ecd) using the Iso Cluster classification definition.

    Arguments:
    in_raster -- The raster dataset to classify.
    max_classes -- Maximum number of desired classes to group pixels or segments. This should be set to be greater than the number of classes in your legend.
    out_classifier_definition -- The output JSON format file that will contain attribute information, statistics, hyperplane vectors, and other information for the classifier. An .ecd file will be created.
    in_additional_raster -- Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional.
    max_iterations -- The maximum number of iterations the clustering process will run.
    min_samples_per_cluster -- The minimum number of pixels or segments in a valid cluster or class.
    skip_factor -- Number of pixels to skip for a pixel image input. If a segmented image is an input, specify the number of segments to skip.
    used_attribute -- Specifies the attributes that will be included in the attribute table associated with the output raster.
    max_merge_per_iter -- The maximum number of cluster merges per iteration. Increasing the number of merges will reduce the number of classes that are created. A lower value will result in more classes.
    max_merge_distance -- The maximum distance between cluster centers in feature space. Increasing the distance will allow more clusters to merge, resulting in fewer classes. A lower value will result in more classes. Values from 0 to 5 typically return the best results.
    """
    ...

def TrainKNearestNeighborClassifier(
    in_raster,
    in_training_features,
    out_classifier_definition,
    in_additional_raster=...,
    kNN=...,
    max_samples_per_class=...,
    used_attributes=...,
    dimension_value_field=...,
):  # -> Any:
    """TrainKNearestNeighborClassifier_ia(in_raster, in_training_features, out_classifier_definition, {in_additional_raster}, {kNN}, {max_samples_per_class}, {[used_attribute,...]}, {dimension_value_field})

    Generates an Esri classifier definition file (.ecd) using the K-Nearest Neighbor classification method.

    Arguments:
    in_raster -- The raster dataset to classify.
    in_training_features -- The training sample file or layer that delineates the training sites.
    out_classifier_definition -- A JSON formatted .ecd file that contains attribute information, statistics, or other information for the classifier.
    in_additional_raster -- Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional.
    kNN -- The number of neighbors that will be used in searching for each input pixel or segment. Increasing the number of neighbors will decrease the influence of individual neighbors on the outcome of the classification. The default value is 1.
    max_samples_per_class -- The maximum number of training samples that will be used for each class. The default value of 1000 is recommended when the inputs are nonsegmented rasters. A value that is less than or equal to 0 means that the system will use all the samples from the training sites to train the classifier.
    used_attribute -- Specifies the attributes that will be included in the attribute table associated with the output raster.
    dimension_value_field -- Contains dimension values in the input training sample feature class.
    """
    ...

def TrainMaximumLikelihoodClassifier(
    in_raster,
    in_training_features,
    out_classifier_definition,
    in_additional_raster=...,
    used_attributes=...,
    dimension_value_field=...,
):  # -> Any:
    """TrainMaximumLikelihoodClassifier_ia(in_raster, in_training_features, out_classifier_definition, {in_additional_raster}, {[used_attribute,...]}, {dimension_value_field})

    Generates an Esri classifier definition file (.ecd) using the Maximum Likelihood Classifier (MLC) classification definition.

    Arguments:
    in_raster -- The raster dataset to classify.
    in_training_features -- The training sample file or layer that delineates the training sites.
    out_classifier_definition -- The output JSON format file that will contain attribute information, statistics, hyperplane vectors, and other information for the classifier. An .ecd file will be created.
    in_additional_raster -- Incorporates ancillary raster datasets, such as a segmented image or DEM. This parameter is optional.
    used_attribute -- Specifies the attributes that will be included in the attribute table associated with the output raster.
    dimension_value_field -- Contains dimension values in the input training sample feature class.
    """
    ...

def TrainRandomTreesClassifier(
    in_raster,
    in_training_features,
    out_classifier_definition,
    in_additional_raster=...,
    max_num_trees=...,
    max_tree_depth=...,
    max_samples_per_class=...,
    used_attributes=...,
    dimension_value_field=...,
):  # -> Any:
    """TrainRandomTreesClassifier_ia(in_raster, in_training_features, out_classifier_definition, {in_additional_raster}, {max_num_trees}, {max_tree_depth}, {max_samples_per_class}, {[used_attribute,...]}, {dimension_value_field})

    Generates an Esri classifier definition file (.ecd) using the Random Trees classification method.

    Arguments:
    in_raster -- The raster dataset to classify.
    in_training_features -- The training sample file or layer that delineates the training sites.
    out_classifier_definition -- A JSON file that contains attribute information, statistics, or other information for the classifier. An .ecd file is created.
    in_additional_raster -- Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional.
    max_num_trees -- The maximum number of trees in the forest. Increasing the number of trees will lead to higher accuracy rates, although this improvement will level off eventually. The number of trees increases the processing time linearly.
    max_tree_depth -- The maximum depth of each tree in the forest. Depth is another way of saying the number of rules each tree is allowed to create to come to a decision. Trees will not grow any deeper than this setting.
    max_samples_per_class -- The maximum number of samples that will be used to define each class.
    used_attribute -- Specifies the attributes that will be included in the attribute table associated with the output raster.
    dimension_value_field -- Contains dimension values in the input training sample feature class.
    """
    ...

def TrainRandomTreesRegressionModel(
    in_rasters,
    in_target_data,
    out_regression_definition,
    target_value_field=...,
    target_dimension_field=...,
    raster_dimension=...,
    out_importance_table=...,
    max_num_trees=...,
    max_tree_depth=...,
    max_samples=...,
    average_points_per_cell=...,
    percent_testing=...,
    out_scatterplots=...,
    out_sample_features=...,
):  # -> Any:
    """TrainRandomTreesRegressionModel_ia([in_raster,...], in_target_data, out_regression_definition, {target_value_field}, {target_dimension_field}, {raster_dimension}, {out_importance_table}, {max_num_trees}, {max_tree_depth}, {max_samples}, {average_points_per_cell}, {percent_testing}, {out_scatterplots}, {out_sample_features})

    Models the relationship between explanatory variables (independent variables) and a target dataset (dependent variable).

    Arguments:
    in_raster -- The single-band, multidimensional, or multiband raster datasets, or mosaic datasets containing explanatory variables.
    in_target_data -- The raster or point feature class containing the target variable (dependant variable) data.
    out_regression_definition -- A JSON format file with an .ecd extension that contains attribute information, statistics, or other information for the classifier.
    target_value_field -- The field name of the information to model in the target point feature class or raster dataset.
    target_dimension_field -- A date field or numeric field in the input point feature class that defines the dimension values.
    raster_dimension -- The dimension name of the input multidimensional raster (explanatory variables) that links to the dimension in the target data.
    out_importance_table -- A table containing information describing the importance of each explanatory variable used in the model. A larger number indicates the corresponding variable is more correlated to the predicted variable and will contribute more in prediction. Values range between 0 and 1, and the sum of all the values equals 1.
    max_num_trees -- The maximum number of trees in the forest. Increasing the number of trees will lead to higher accuracy rates, although this improvement will level off. The number of trees increases the processing time linearly. The default is 50.
    max_tree_depth -- The maximum depth of each tree in the forest. Depth determines the number of rules each tree can create, resulting in a decision. Trees will not grow any deeper than this setting. The default is 30.
    max_samples -- The maximum number of samples that will be used for the regression analysis. A value that is less than or equal to 0 means that the system will use all the samples from the input target raster or point feature class to train the regression model. The default value is 10,000.
    average_points_per_cell -- Specifies whether the average will be calculated when multiple training points fall into one cell. This parameter is applicable only when the input target is a point feature class.
    percent_testing -- The percentage of test points that will be used for error checking. The tool checks for three types of errors: errors on training points, errors on test points, and errors on test location points. The default is 10.
    out_scatterplots -- The output scatter plots in PDF or HTML format. The output will include scatter plots of training data, test data, and location test data.
    out_sample_features -- The output feature class that will contain target values and predicted values for training points, test points, and location test points.
    """
    ...

def TrainSupportVectorMachineClassifier(
    in_raster,
    in_training_features,
    out_classifier_definition,
    in_additional_raster=...,
    max_samples_per_class=...,
    used_attributes=...,
    dimension_value_field=...,
):  # -> Any:
    """TrainSupportVectorMachineClassifier_ia(in_raster, in_training_features, out_classifier_definition, {in_additional_raster}, {max_samples_per_class}, {[used_attribute,...]}, {dimension_value_field})

    Generates an Esri classifier definition file (.ecd) using the Support Vector Machine (SVM) classification definition.

    Arguments:
    in_raster -- The raster dataset to classify.
    in_training_features -- The training sample file or layer that delineates the training sites.
    out_classifier_definition -- The output JSON format file that will contain attribute information, statistics, hyperplane vectors, and other information for the classifier. An .ecd file will be created.
    in_additional_raster -- Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional.
    max_samples_per_class -- The maximum number of samples that will be used to define each class.
    used_attribute -- Specifies the attributes that will be included in the attribute table associated with the output raster.
    dimension_value_field -- Contains dimension values in the input training sample feature class.
    """
    ...

def TrainUsingAutoDL(
    in_data,
    out_model,
    pretrained_model=...,
    total_time_limit=...,
    autodl_mode=...,
    networks=...,
    save_evaluated_models=...,
):  # -> Any:
    """TrainUsingAutoDL_ia(in_data, out_model, {pretrained_model}, {total_time_limit}, {autodl_mode}, {[network,...]}, {save_evaluated_models})

    Trains a deep learning model by building training pipelines and automating much of the training process.  This includes data augmentation, model selection, hyperparameter tuning, and batch size deduction. Its outputs include performance metrics of the best model on the training data, as well as the trained  deep learning model package (.dlpk file) that can be used as input for the Extract Features Using AI Models tool to predict on a new imagery.

    Arguments:
    in_data -- The folders containing the image chips, labels, and statistics required to train the model. This is the output from the Export Training Data For Deep Learning tool. The metadata format of the exported data must be Classified_Tiles, PASCAL_VOC_rectangles, or KITTI_rectangles.
    out_model -- The output trained model that will be saved as a deep learning package (.dlpk file).
    pretrained_model -- A pretrained model that will be used to fine-tune the new model. The input is an Esri model definition file (.emd) or a deep learning package file (.dlpk).
    total_time_limit -- The total time limit in hours it will take for AutoDL model training. The default is 2 hours.
    autodl_mode -- Specifies the AutoDL mode that will be used and how intensive the AutoDL search will be.
    network -- Specifies the architectures that will be used to train the model.
    save_evaluated_models -- Specifies whether all evaluated models will be saved."""
    ...

def UpdateAccuracyAssessmentPoints(
    in_class_data,
    in_points,
    out_points,
    target_field=...,
    polygon_dimension_field=...,
    point_dimension_field=...,
):  # -> Any:
    """UpdateAccuracyAssessmentPoints_ia(in_class_data, in_points, out_points, {target_field}, {polygon_dimension_field}, {point_dimension_field})

    Updates the Target field in the attribute table to compare reference points to the classified image.

    Arguments:
    in_class_data -- The input classification image or other thematic GIS reference data. The input can be a raster or feature class.
    in_points -- The point feature class providing the accuracy assessment points to be updated.
    out_points -- The output point feature class that contains the updated random point field for accuracy assessment purposes.
    target_field -- Specifies whether the input data is a classified image or ground truth data.
    polygon_dimension_field -- The dimension field for the Input Accuracy Assessment Points parameter value. The assessment points will be updated based on the matching dimension values with this field.
    point_dimension_field -- The dimension field in the Input Accuracy Assessment Points parameter value. Input data with identical dimension values will be used to update corresponding points.
    """
    ...

def VideoMetadataToFeatureClass(
    in_video,
    csv_file=...,
    flightpath=...,
    flightpath_type=...,
    imagepath=...,
    imagepath_type=...,
    footprint=...,
    start_time=...,
    stop_time=...,
    min_distance=...,
    min_time=...,
):  # -> Any:
    """VideoMetadataToFeatureClass_ia(in_video, {csv_file}, {flightpath}, {flightpath_type}, {imagepath}, {imagepath_type}, {footprint}, {start_time}, {stop_time}, {min_distance}, {min_time})

    Extracts the platform, frame center, frame outline, and attributes metadata from an FMV-compliant video. The output geometry and attributes are saved as feature classes.

    Arguments:
    in_video -- The FMV-compliant input video file containing essential metadata for each frame of the video data. The supported video file types include PS, TS, MPG, MPEG, MP2, MPG2, MPEG2, MP4, MPG4, MPEG4, H264, VOB, and M2TS.
    csv_file -- A comma-separated values (CSV) file containing metadata about the video frames for specific times.
    flightpath -- The feature class containing the sensor's flight path information.
    flightpath_type -- Specifies the feature class type for the flight path.
    imagepath -- The output feature class containing the image path information.
    imagepath_type -- Specifies the feature class type for the image path. If you're using a point output, the center of each video frame image will appear on the map.
    footprint -- The output feature class containing the video image footprint information.
    start_time -- The metadata recording start time from the beginning of the video. The input format is d.hh:mm:ss, and the default start time is 0.00:00:00. Metadata time stamps are not used in this field; the time of the video file is used.
    stop_time -- The metadata recording end time. The input format is d.hh:mm:ss. If not set, the value will default to the end of the video. Metadata time stamps are not used in this field.
    min_distance -- The distance between the features in sequential video frames. If left blank, every metadata feature will be extracted and added to the feature class.
    min_time -- The time interval between the features in sequential video frames. If left blank, every metadata feature will be extracted and added to the feature class.
    """
    ...

def VideoMultiplexer(
    in_video_file,
    metadata_file,
    out_video_file,
    metadata_mapping_file=...,
    timeshift_file=...,
    elevation_layer=...,
):  # -> Any:
    """VideoMultiplexer_ia(in_video_file, metadata_file, out_video_file, {metadata_mapping_file}, {timeshift_file}, {elevation_layer})

    Creates a video file that combines an archived video stream file and an associated metadata file synchronized by a time stamp.

    Arguments:
    in_video_file -- The input video file that will be converted to a FMV-compliant video file.
    metadata_file -- A comma-separated values (CSV) file containing metadata about the video frames for specific times.
    out_video_file -- The name of the output video file, including the file extension.
    metadata_mapping_file -- A CSV file that contains 5 columns and 87 rows and is based on the FMV_Multiplexer_Field_Mapping_Template.csv template file obtained from C:\\Program Files\\ArcGIS\\Pro\\Resources\\FullMotionVideo.
    timeshift_file -- A file containing defined time shift intervals.
    elevation_layer -- The source of the elevation needed for calculating the video frame corner coordinates. The source can be a layer, image service, or an average ground elevation or ocean depth. The average elevation value must include the units of measurement such as meters or feet or other measure of length.
    """
    ...

def WeightedSum(in_weighted_sum_table):
    """WeightedSum_ia(in_weighted_sum_table)

    Overlays several rasters, multiplying each by their given weight and summing them together.

    Arguments:
    in_weighted_sum_table -- The weighted sum table allows you to apply different weights to individual input rasters before they are summed together.

    Results:
    out_raster -- Output raster"""
    ...

def ZonalStatistics(
    in_zone_data,
    zone_field,
    in_value_raster,
    statistics_type=...,
    ignore_nodata=...,
    process_as_multidimensional=...,
    percentile_value=...,
    percentile_interpolation_type=...,
    circular_calculation=...,
    circular_wrap_value=...,
):
    """ZonalStatistics_ia(in_zone_data, zone_field, in_value_raster, {statistics_type}, {ignore_nodata}, {process_as_multidimensional}, {percentile_value}, {percentile_interpolation_type}, {circular_calculation}, {circular_wrap_value})

    Summarizes the values of a raster within the zones of another dataset.

    Arguments:
    in_zone_data -- The dataset that defines the zones.
    zone_field -- The field that contains the values that define each zone.
    in_value_raster -- The raster that contains the values on which to calculate a statistic.
    statistics_type -- Specifies the statistic type to be calculated.
    ignore_nodata -- Specifies whether NoData values in the value input will be ignored in the results of the zone that they fall within.
    process_as_multidimensional -- Specifies how the input rasters will be calculated if they are multidimensional.
    percentile_value -- The percentile to calculate. The default is 90, indicating the 90th percentile.
    percentile_interpolation_type -- Specifies the method of interpolation that will be used when the percentile value falls between two cell values from the input value raster.
    circular_calculation -- Specifies how the input raster will be processed for circular data.
    circular_wrap_value -- The value that will be used to round a linear value to the range of a given circular statistic. Its value must be a positive integer or a floating-point value. The default value is 360 degrees.

    Results:
    out_raster -- Output Raster"""
    ...

def ZonalStatisticsAsTable(
    in_zone_data,
    zone_field,
    in_value_raster,
    out_table,
    ignore_nodata=...,
    statistics_type=...,
    process_as_multidimensional=...,
    percentile_values=...,
    percentile_interpolation_type=...,
    circular_calculation=...,
    circular_wrap_value=...,
):  # -> Any:
    """ZonalStatisticsAsTable_ia(in_zone_data, zone_field, in_value_raster, out_table, {ignore_nodata}, {statistics_type}, {process_as_multidimensional}, {[percentile_value,...]}, {percentile_interpolation_type}, {circular_calculation}, {circular_wrap_value})

    Summarizes the values of a raster within the zones of another dataset and reports the results as a table.

    Arguments:
    in_zone_data -- The dataset that defines the zones.
    zone_field -- The field that contains the values that define each zone.
    in_value_raster -- The raster that contains the values on which to calculate a statistic.
    out_table -- The output table that will contain the summary of the values in each zone.
    ignore_nodata -- Specifies whether NoData values in the value input will be ignored in the results of the zone that they fall within.
    statistics_type -- Specifies the statistic type to be calculated.
    process_as_multidimensional -- Specifies how the input rasters will be calculated if they are multidimensional.
    percentile_value -- The percentile to calculate. The default is 90, indicating the 90th percentile.
    percentile_interpolation_type -- Specifies the method of interpolation that will be used when the percentile value falls between two cell values from the input value raster.
    circular_calculation -- Specifies how the input raster will be processed for circular data.
    circular_wrap_value -- The value that will be used to round a linear value to the range of a given circular statistic. Its value must be a positive integer or a floating-point value. The default value is 360 degrees.
    """
    ...

def ApplyEnvironment(in_raster):
    """ApplyEnvironment(in_raster)

    Creates a copy of in_raster with environment settings applied.

    Arguments:
    in_raster -- The input that will be copied.

    Results:
    out_raster -- Output raster"""
    ...

def FloatDivide(in_raster_or_constant1, in_raster_or_constant2):
    """FloatDivide(in_raster_or_constant1, in_raster_or_constant2)

    Divides the values of two rasters on a cell-by-cell basis. The result will
    be a true floating point division.

    Arguments:
    in_raster_or_constant1 -- The input whose values will be divided by the second input.
    in_raster_or_constant2 -- The input whose values the first input are to be divided by.

    Results:
    out_raster -- Output raster"""
    ...

def FloorDivide(in_raster_or_constant1, in_raster_or_constant2):
    """FloorDivide(in_raster_or_constant1, in_raster_or_constant2)

    Divides the values of two rasters on a cell-by-cell basis. The result will
    be a floored floating point division.

    Arguments:
    in_raster_or_constant1 -- The input whose values will be divided by the second input.
    in_raster_or_constant2 -- The input whose values the first input are to be divided by.

    Results:
    out_raster -- Output raster"""
    ...
