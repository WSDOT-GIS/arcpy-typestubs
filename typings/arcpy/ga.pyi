"""
This type stub file was generated by pyright.
"""

from arcpy.geoprocessing._base import gptooldoc
from arcpy import _ga
from arcpy._ga import *

r"""With Geostatistical Analyst, you can easily create a continuous
surface or map from measurements stored in a point feature layer or
raster layer or by using polygon centroids. The sample points may be
measurements such as elevation, depth to the water table, or levels of
pollution. Geostatistical Analyst provides a comprehensive set of
tools for creating surfaces that can be used to visualize, analyze,
and understand spatial phenomena."""
__all__ = [
    "ArealInterpolationLayerToPolygons",
    "CompareGeostatisticalLayers",
    "CreateSpatiallyBalancedPoints",
    "CrossValidation",
    "DensifySamplingNetwork",
    "DiffusionInterpolationWithBarriers",
    "EBKRegressionPrediction",
    "EmpiricalBayesianKriging",
    "EmpiricalBayesianKriging3D",
    "ExploratoryInterpolation",
    "ExtractValuesToTable",
    "GACalculateZValue",
    "GACreateGeostatisticalLayer",
    "GAGetModelParameter",
    "GALayer3DToMultidimensionalRaster",
    "GALayer3DToNetCDF",
    "GALayerToContour",
    "GALayerToGrid",
    "GALayerToPoints",
    "GALayerToRasters",
    "GAMovingWindowKriging",
    "GANeighborhoodSelection",
    "GASemivariogramSensitivity",
    "GASetModelParameter",
    "GaussianGeostatisticalSimulations",
    "GenerateSubsetPolygons",
    "GlobalPolynomialInterpolation",
    "IDW",
    "KernelInterpolationWithBarriers",
    "LocalPolynomialInterpolation",
    "NearestNeighbor3D",
    "RadialBasisFunctions",
    "SubsetFeatures",
]
__alias__ = ...
__all__ += _ga.__all__

@gptooldoc("DiffusionInterpolationWithBarriers_ga", None)
def DiffusionInterpolationWithBarriers(
    in_features=...,
    z_field=...,
    out_ga_layer=...,
    out_raster=...,
    cell_size=...,
    in_barrier_features=...,
    bandwidth=...,
    number_iterations=...,
    weight_field=...,
    in_additive_barrier_raster=...,
    in_cumulative_barrier_raster=...,
    in_flow_barrier_raster=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """DiffusionInterpolationWithBarriers_ga(in_features, z_field, {out_ga_layer}, {out_raster}, {cell_size}, {in_barrier_features}, {bandwidth}, {number_iterations}, {weight_field}, {in_additive_barrier_raster}, {in_cumulative_barrier_raster}, {in_flow_barrier_raster})

       Interpolates a surface using a kernel that is based upon the heat
       equation and allows one to use raster and feature barriers to redefine
       distances between input points.

    INPUTS:
     in_features (Feature Layer):
         The input point features containing the z-values to be interpolated.
     z_field (Field):
         Field that holds a height or magnitude value for each point. This can
         be a numeric field or the Shape field if the input features contain
         z-values or m-values.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.
     in_barrier_features {Feature Layer}:
         Absolute barrier features using non-Euclidean distances rather than
         line-of-sight distances.
     bandwidth {Double}:
         Used to specify the maximum distance at which data points are used for
         prediction. With increasing bandwidth, prediction bias increases and
         prediction variance decreases.
     number_iterations {Long}:
         The iteration count controls the accuracy of the numerical solution
         because the model solves the diffusion equation numerically. The
         larger this number, the more accurate the predictions, yet the longer
         the processing time. The more complex the barrier's geometry and the
         larger the bandwidth, the more iterations are required for accurate
         predictions.
     weight_field {Field}:
         Used to emphasize an observation. The larger the weight, the more
         impact it has on the prediction. For coincident observations, assign
         the largest weight to the most reliable measurement.
     in_additive_barrier_raster {Raster Layer}:
         The travel distance from one raster cell to the next based on this
         formula:(average cost value in the neighboring cells) x (distance
         between cell
         centers)
     in_cumulative_barrier_raster {Raster Layer}:
         The travel distance from one raster cell to the next based on this
         formula:(difference between cost values in the neighboring cells) +
         (distance
         between cell centers)
     in_flow_barrier_raster {Raster Layer}:
         A flow barrier is used when interpolating data with preferential
         direction of data variation, based on this formula:        Indicator
         (cost values in theneighboring cell > cost values in
         theneighboring cell) * (cost values in theneighboring cell - cost
         values in theneighboring cell) + (distance between cell centers),
         tofromtofromwhere indicator(true) = 1 and indicator(false) = 0.

    OUTPUTS:
     out_ga_layer {Geostatistical Layer}:
         The geostatistical layer produced. This layer is required output only
         if no output raster is requested.
     out_raster {Raster Dataset}:
         The output raster. This raster is required output only if no output
         geostatistical layer is requested."""
    ...

@gptooldoc("EBKRegressionPrediction_ga", None)
def EBKRegressionPrediction(
    in_features=...,
    dependent_field=...,
    in_explanatory_rasters=...,
    out_ga_layer=...,
    out_raster=...,
    out_diagnostic_feature_class=...,
    measurement_error_field=...,
    min_cumulative_variance=...,
    in_subset_features=...,
    transformation_type=...,
    semivariogram_model_type=...,
    max_local_points=...,
    overlap_factor=...,
    number_simulations=...,
    search_neighborhood=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """EBKRegressionPrediction_ga(in_features, dependent_field, in_explanatory_rasters;in_explanatory_rasters..., out_ga_layer, {out_raster}, {out_diagnostic_feature_class}, {measurement_error_field}, {min_cumulative_variance}, {in_subset_features}, {transformation_type}, {semivariogram_model_type}, {max_local_points}, {overlap_factor}, {number_simulations}, {search_neighborhood})

       EBK Regression Prediction is a geostatistical interpolation method
       that uses Empirical Bayesian Kriging with explanatory variable rasters
       that are known to affect the value of the data that you are
       interpolating. This approach combines kriging with regression analysis
       to make predictions that are more accurate than either regression or
       kriging can achieve on their own.

    INPUTS:
     in_features (Feature Layer):
         The input point features containing the field that will be
         interpolated.
     dependent_field (Field):
         The field of the Input dependent variable features containing the
         values of the dependent variable. This is the field that will be
         interpolated.
     in_explanatory_rasters (Raster Layer / Mosaic Layer):
         Input rasters representing the explanatory variables that will be used
         to build the regression model. These rasters should represent
         variables that are known to influence the values of the dependent
         variable. For example, when interpolating temperature data, an
         elevation raster should be used as an explanatory variable because
         temperature is influenced by elevation. You can use up to 62
         explanatory rasters.
     measurement_error_field {Field}:
         A field that specifies the measurement error for each point in the
         dependent variable features. For each point, the value of this field
         should correspond to one standard deviation of the measured value of
         the point. Use this field if the measurement error values are not the
         same at each point.A common source of nonconstant measurement error is
         when the data is
         measured with different devices. One device might be more precise than
         another, which means that it will have a smaller measurement error.
         For example, one thermometer rounds to the nearest degree and another
         thermometer rounds to the nearest tenth of a degree. The variability
         of measurements is often provided by the manufacturer of the measuring
         device, or it may be known from empirical practice.Leave this
         parameter empty if there are no measurement error values or
         the measurement error values are unknown.
     min_cumulative_variance {Double}:
         Defines the minimum cumulative percent of variance from the principal
         components of the explanatory variable rasters. Before building the
         regression model, the principal components of the explanatory
         variables are calculated, and these principal components are used as
         explanatory variables in the regression. Each principal component
         captures a certain percent of the variance of the explanatory
         variables, and this parameter controls the minimum percent of variance
         that must be captured by the principal components of each local model.
         For example, if a value of 75 is provided, the software will use the
         minimum number of principal components that are necessary to capture
         at least 75 percent of the variance of the explanatory
         variables.Principal components are all mutually uncorrelated with each
         other, so
         using principal components solves the problem of multicollinearity
         (explanatory variables that are correlated with each other). Most of
         the information contained in all explanatory variables can frequently
         be captured in just a few principal components. By discarding the
         least useful principal components, the model calculation becomes more
         stable and efficient without significant loss of accuracy.To calculate
         principal components, there must be variability in the
         explanatory variables, so if any of your Input explanatory variable
         rasters contain constant values within a subset, these constant
         rasters will not be used to compute principal components for that
         subset. If all explanatory variable rasters in a subset contain
         constant values, the Output diagnostic feature class will report that
         zero principal components were used and that they captured zero
         percent of the variability.
     in_subset_features {Feature Layer}:
         Polygon features defining where the local models will be calculated.
         The points inside each polygon will be used for the local models. This
         parameter is useful when you know that the values of the dependent
         variable changes according to known regions. For example, these
         polygons may represent administrative health districts where health
         policy changes in different districts.You can also use the Generate
         Subset Polygons tool to create subset
         polygons. The polygons created by this tool will be non-overlapping
         and compact.
     transformation_type {String}:
         Type of transformation to be applied to the input data.

         * NONE-Do not apply any transformation. This is the default.

         * EMPIRICAL-Multiplicative Skewing transformation with Empirical base
         function.

         * LOGEMPIRICAL-Multiplicative Skewing transformation with Log
         Empirical base function. All data values must be positive. If this
         option is chosen, all predictions will be positive.
     semivariogram_model_type {String}:
         The semivariogram model that will be used for the interpolation.

         * EXPONENTIAL-Exponential semivariogram

         * NUGGET-Nugget semivariogram

         * WHITTLE-Whittle semivariogram

         * K_BESSEL-K-Bessel semivariogram
     max_local_points {Long}:
         The input data will automatically be divided into subsets that do not
         have more than this number of points. If Subset polygon features are
         supplied, the value of this parameter will be ignored.
     overlap_factor {Double}:
         A factor representing the degree of overlap between local models (also
         called subsets). Each input point can fall into several subsets, and
         the overlap factor specifies the average number of subsets that each
         point will fall into. A high value of the overlap factor makes the
         output surface smoother, but it also increases processing time. Values
         must be between 1 and 5. If Subset polygon features are supplied, the
         value of this parameter will be ignored.
     number_simulations {Long}:
         The number of simulated semivariograms of each local model. Using more
         simulations will make the model calculations more stable, but the
         model will take longer to calculate.
     search_neighborhood {Geostatistical Search Neighborhood}:
         Defines which surrounding points will be used to control the output.
         Standard is the default.The following are Search Neighborhood classes:
         SearchNeighborhoodStandardCircular and
         SearchNeighborhoodSmoothCircular.Standard Circular

         * radius-The length of the radius of the search circle.

         * angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * nbrMax-The maximum number of neighbors that will be used to estimate
         the value at the unknown location.

         * nbrMin-The minimum number of neighbors that will be used to estimate
         the value at the unknown location.

         * sectorType-The geometry of the neighborhood.

         * ONE_SECTOR-Single ellipse.

         * FOUR_SECTORS-Ellipse divided into four sectors.

         * FOUR_SECTORS_SHIFTED-Ellipse divided into four sectors and shifted
         45 degrees.

         * EIGHT_SECTORS-Ellipse divided into eight sectors.

         Smooth Circular

         * radius-The length of the radius of the search circle.

         * smoothFactor-The Smooth Interpolation option creates an outer
         ellipse and an inner ellipse at a distance equal to the Major Semiaxis
         multiplied by the Smoothing factor. The points that fall outside the
         smallest ellipse but inside the largest ellipse are weighted using a
         sigmoidal function with a value between zero and one.

    OUTPUTS:
     out_ga_layer (Geostatistical Layer):
         The output geostatistical layer displaying the result of the
         interpolation.
     out_raster {Raster Dataset}:
         The output raster displaying the result of the interpolation. The
         default cell size will be the maximum of the cell sizes of the Input
         explanatory variable rasters. To use a different cell size, use the
         cell size environmental setting.
     out_diagnostic_feature_class {Feature Class}:
         Output polygon feature class that shows the regions of each local
         model and contains fields with diagnostic information for the local
         models. For each subset, a polygon will be created that surrounds the
         points in the subset so you can easily identify which points were used
         in each subset. For example, if there are 10 local models, there will
         be ten polygons in this output. The feature class will contain the
         following fields:

         * Number of Principal Components (PrincComps)-The number of principal
         components that were used as explanatory variables. The value will
         always be less than or equal to the number of explanatory variable
         rasters.

         * Percent of Variance (PercVar)-The percent of variance captured by
         the principal components. This value will be greater than or equal to
         the value specified in the Minimum cumulative percent of variance
         parameter below.

         * Root Mean Square Error (RMSE)-The square root of the average squared
         cross-validation errors. The smaller this value, the better the model
         fits.

         * Percent 90 Interval (Perc90)-The percent of data points that fall
         within a 90 percent cross-validation confidence interval. Ideally,
         this number should be close to 90. A value significantly smaller than
         90 indicates that standard errors are being underestimated. A value
         significantly larger than 90 indicates that standard errors are being
         overestimated.

         * Percent 95 Interval (Perc95)-The percent of data points that fall
         within a 95 percent cross-validation confidence interval. Ideally,
         this number should be close to 95. A value significantly smaller than
         95 indicates that standard errors are being underestimated. A value
         significantly larger than 95 indicates that standard errors are being
         overestimated.

         * Mean Absolute Error (MeanAbsErr)-The average of the absolute values
         of the cross-validation errors. This value should be as small as
         possible. It is similar to Root Mean Square Error, but it is less
         influenced by extreme values.

         * Mean Error (MeanError)-The average of the cross-validation errors.
         This value should be close to zero. A value significantly different
         than zero indicates that the predictions are biased.

         * Continuous Ranked Probability Score (CRPS)-The continuous ranked
         probability score is a diagnostic that measures the deviation from the
         predictive cumulative distribution function to each observed data
         value. This value should be as small as possible. This diagnostic has
         advantages over cross-validation diagnostics because it compares the
         data to a full distribution rather than to single-point predictions."""
    ...

@gptooldoc("EmpiricalBayesianKriging_ga", None)
def EmpiricalBayesianKriging(
    in_features=...,
    z_field=...,
    out_ga_layer=...,
    out_raster=...,
    cell_size=...,
    transformation_type=...,
    max_local_points=...,
    overlap_factor=...,
    number_semivariograms=...,
    search_neighborhood=...,
    output_type=...,
    quantile_value=...,
    threshold_type=...,
    probability_threshold=...,
    semivariogram_model_type=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """EmpiricalBayesianKriging_ga(in_features, z_field, {out_ga_layer}, {out_raster}, {cell_size}, {transformation_type}, {max_local_points}, {overlap_factor}, {number_semivariograms}, {search_neighborhood}, {output_type}, {quantile_value}, {threshold_type}, {probability_threshold}, {semivariogram_model_type})

       Empirical Bayesian kriging is an interpolation method that accounts
       for the error in estimating the underlying semivariogram through
       repeated simulations.

    INPUTS:
     in_features (Feature Layer):
         The input point features containing the z-values to be interpolated.
     z_field (Field):
         Field that holds a height or magnitude value for each point. This can
         be a numeric field or the Shape field if the input features contain
         z-values or m-values.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.
     transformation_type {String}:
         Type of transformation to be applied to the input data.

         * NONE-Do not apply any transformation. This is the default.

         * EMPIRICAL-Multiplicative Skewing transformation with Empirical base
         function.

         * LOGEMPIRICAL-Multiplicative Skewing transformation with Log
         Empirical base function. All data values must be positive. If this
         option is chosen, all predictions will be positive.
     max_local_points {Long}:
         The input data will automatically be divided into groups that do not
         have more than this number of points.
     overlap_factor {Double}:
         A factor representing the degree of overlap between local models (also
         called subsets). Each input point can fall into several subsets, and
         the overlap factor specifies the average number of subsets that each
         point will fall into. A high value of the overlap factor makes the
         output surface smoother, but it also increases processing time.
         Typical values vary between 0.01 and 5.
     number_semivariograms {Long}:
         The number of simulated semivariograms of each local model.
     search_neighborhood {Geostatistical Search Neighborhood}:
         Defines which surrounding points will be used to control the output.
         Standard Circular is the default.The following are Search Neighborhood
         classes:
         SearchNeighborhoodStandardCircular and
         SearchNeighborhoodSmoothCircular.Standard Circular

         * radius-The length of the radius of the search circle.

         * angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * nbrMax-The maximum number of neighbors that will be used to estimate
         the value at the unknown location.

         * nbrMin-The minimum number of neighbors that will be used to estimate
         the value at the unknown location.

         * sectorType-The geometry of the neighborhood.

         * ONE_SECTOR-Single ellipse.

         * FOUR_SECTORS-Ellipse divided into four sectors.

         * FOUR_SECTORS_SHIFTED-Ellipse divided into four sectors and shifted
         45 degrees.

         * EIGHT_SECTORS-Ellipse divided into eight sectors.

         Smooth Circular

         * radius-The length of the radius of the search circle.

         * smoothFactor-The Smooth Interpolation option creates an outer
         ellipse and an inner ellipse at a distance equal to the Major Semiaxis
         multiplied by the Smoothing factor. The points that fall outside the
         smallest ellipse but inside the largest ellipse are weighted using a
         sigmoidal function with a value between zero and one.
     output_type {String}:
         Surface type to store the interpolation results.For more information
         about the output surface types, see What output
         surface types can the interpolation models generate?

         * PREDICTION-Prediction surfaces are produced from the interpolated
         values.

         * PREDICTION_STANDARD_ERROR-Standard Error surfaces are produced from
         the standard errors of the interpolated values.

         * PROBABILITY-Probability surface of values exceeding or not exceeding
         a certain threshold.

         * QUANTILE-Quantile surface predicting the specified quantile of the
         prediction distribution.
     quantile_value {Double}:
         The quantile value for which the output raster will be generated.
     threshold_type {String}:
         Specifies whether to calculate the probability of exceeding or not
         exceeding the specified threshold.

         * EXCEED-Probability values exceed the threshold. This is the default.

         * NOT_EXCEED-Probability values will not exceed the threshold.
     probability_threshold {Double}:
         The probability threshold value. If left empty, the median (50th
         quantile) of the input data will be used.
     semivariogram_model_type {String}:
         The semivariogram model that will be used for the interpolation.

         * POWER-Power semivariogram

         * LINEAR-Linear semivariogram

         * THIN_PLATE_SPLINE-Thin Plate Spline semivariogram

         * EXPONENTIAL-Exponential semivariogram

         * EXPONENTIAL_DETRENDED-Exponential semivariogram with first order
         trend removal

         * WHITTLE-Whittle semivariogram

         * WHITTLE_DETRENDED-Whittle semivariogram with first order trend
         removal

         * K_BESSEL-K-Bessel semivariogram

         * K_BESSEL_DETRENDED-K-Bessel semivariogram with first order trend
         removal
         The available choices depend on the value of the transformation_type
         parameter. If the transformation type is set to NONE, only the first
         three semivariograms are available. If the type is EMPIRICAL or
         LOGEMPIRICAL, the last six semivariograms are available.For more
         information about choosing an appropriate semivariogram for
         your data, see the topic What is Empirical Bayesian Kriging.

    OUTPUTS:
     out_ga_layer {Geostatistical Layer}:
         The geostatistical layer produced. This layer is required output only
         if no output raster is requested.
     out_raster {Raster Dataset}:
         The output raster. This raster is required output only if no output
         geostatistical layer is requested."""
    ...

@gptooldoc("EmpiricalBayesianKriging3D_ga", None)
def EmpiricalBayesianKriging3D(
    in_features=...,
    elevation_field=...,
    value_field=...,
    out_ga_layer=...,
    elevation_units=...,
    measurement_error_field=...,
    semivariogram_model_type=...,
    transformation_type=...,
    subset_size=...,
    overlap_factor=...,
    number_simulations=...,
    trend_removal=...,
    elev_inflation_factor=...,
    search_neighborhood=...,
    output_elevation=...,
    output_type=...,
    quantile_value=...,
    threshold_type=...,
    probability_threshold=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """EmpiricalBayesianKriging3D_ga(in_features, elevation_field, value_field, out_ga_layer, {elevation_units}, {measurement_error_field}, {semivariogram_model_type}, {transformation_type}, {subset_size}, {overlap_factor}, {number_simulations}, {trend_removal}, {elev_inflation_factor}, {search_neighborhood}, {output_elevation}, {output_type}, {quantile_value}, {threshold_type}, {probability_threshold})

       Interpolates 3D points using Empirical Bayesian Kriging methodology.
       All points must have x-, y-, and z-coordinates and a measured value to
       be interpolated. The output is a 3D geostatistical layer that
       calculates and renders itself as a 2D transect at a given elevation.
       The elevation of the layer can be changed using the range slider, and
       the layer will update to show the interpolated predictions for the new
       elevation.

    INPUTS:
     in_features (Feature Layer):
         The input point features containing the field that will be
         interpolated.
     elevation_field (Field):
         The field of the input features containing the elevation value of each
         input point.If the elevation values are stored as geometry attributes
         in Shape.Z,
         it is recommended that you use that field. If the elevation values are
         stored in an attribute field, the elevation values must indicate
         distance from mean sea level. Positive values indicate distance above
         sea level, and negative values indicate distance below sea level.
     value_field (Field):
         The field of the input features containing the measured values that
         will be interpolated.
     elevation_units {String}:
         The units of the elevation field.If Shape.Z is provided as the
         elevation field, the units will
         automatically match the z-units of the vertical coordinate system.

         * INCH-Elevations are in U.S. survey inches.

         * FOOT-Elevations are in U.S. survey feet.

         * YARD-Elevations are in U.S. survey yards.

         * MILE_US-Elevations are in U.S. survey miles.

         * NAUTICAL_MILE-Elevations are in U.S. survey nautical miles.

         * MILLIMETER-Elevations are in millimeters.

         * CENTIMETER-Elevations are in centimeters.

         * DECIMETER-Elevations are in decimeters.

         * METER-Elevations are in meters.

         * KILOMETER-Elevations are in kilometers.

         * INCH_INT-Elevations are in international inches.

         * FOOT_INT-Elevations are in international feet.

         * YARD_INT-Elevations are in international yards.

         * MILE_INT-Elevations are in statute miles.

         * NAUTICAL_MILE_INT-Elevations are in international nautical miles.
     measurement_error_field {Field}:
         The field of the input features containing measurement error values
         for each point. The value should correspond to one standard deviation
         of the measured value of each point. Use this field if the measurement
         error values are not the same at each point.A common source of
         nonconstant measurement error is when the data is
         measured with different devices. One device may be more precise than
         another, which means that it will have a smaller measurement error.
         For example, a thermometer rounds to the nearest degree and another
         thermometer rounds to the nearest tenth of a degree. The variability
         of measurements is often provided by the manufacturer of the measuring
         device, or it may be known from empirical practice.Leave this
         parameter empty if there are no measurement error values or
         the measurement error values are unknown.
     semivariogram_model_type {String}:
         The semivariogram model that will be used for the interpolation.

         * POWER-The Power semivariogram model will be used.

         * LINEAR-The Linear semivariogram model will be used.

         * THIN_PLATE_SPLINE-The Thin Plate Spline semivariogram model will be
         used.

         * EXPONENTIAL-The Exponential semivariogram model will be used.

         * WHITTLE-The Whittle semivariogram model will be used.

         * K_BESSEL-The K-Bessel semivariogram model will be used.
     transformation_type {String}:
         The type of transformation that will be applied to the input features.

         * NONE-No transformation will be applied. This is the default.

         * EMPIRICAL-Multiplicative Skewing transformation with Empirical base
         function will be applied.

         * LOGEMPIRICAL-Multiplicative Skewing transformation with Log
         Empirical base function will be applied. All data values must be
         positive. If this option is chosen, all predictions will be positive.
     subset_size {Long}:
         The size of the subset. The input data will automatically be divided
         into subsets before processing. This parameter controls the number of
         points that will be in each subset.
     overlap_factor {Double}:
         A factor representing the degree of overlap between local models (also
         called subsets).Each input point can fall into several subsets, and
         the overlap factor
         specifies the average number of subsets into which each point will
         fall. A high value of the overlap factor produces a smoother output
         surface, but it also increases processing time. Values must be between
         1 and 5. The actual overlap that will be used will usually be larger
         than this value, so each subset will contain the same number of
         points.
     number_simulations {Long}:
         The number of simulated semivariograms that will be used for each
         local model.Using more simulations will make the model calculations
         more stable,
         but the model will take longer to calculate.
     trend_removal {String}:
         Specifies the order of trend removal in the vertical direction.For
         most 3D data, the values of the points change faster vertically
         than horizontally. Removing trend in the vertical direction will help
         alleviate this and stabilize calculations.

         * NONE-Vertical trend will not be removed. This is the default.

         * FIRST-First order vertical trend will be removed.
     elev_inflation_factor {Double}:
         A constant value that is multiplied by the Elevation field value prior
         to subsetting and model estimation. For most 3D data, the values of
         the points change faster vertically than horizontally, and this factor
         stretches the locations of the points so that one unit of distance
         vertically is statistically equivalent to one unit of distance
         horizontally. The locations of the points will be moved back to their
         original locations before returning the result of the interpolation.
         This correction is needed to accurately estimate the semivariogram
         model as well as the correct neighbors for the Search neighborhood
         parameter. The elevation inflation factor is unitless and will provide
         the same results regardless of the units of the x-, y-, or
         z-coordinate of the input points.If no value is provided for this
         parameter, one will be calculated at
         run time using a maximum likelihood estimation. The value will be
         printed as a geoprocessing message. The value calculated at run time
         will be between 1 and 1000. However, you can provide values between
         0.01 and 1,000,000. If the calculated value is equal to 1 or 1000, you
         can provide values outside that range and choose a value based on
         cross validation.
     search_neighborhood {Geostatistical Search Neighborhood}:
         Specifies the number and orientation of the neighbors using the
         SearchNeighborhoodStandard3D class.Standard3D

         * radius-The length of the radius of the search neighborhood.

         * nbrMax-The maximum number of neighbors per sector that will be used
         to estimate the value at the unknown location.

         * nbrMin-The minimum number of neighbors per sector that will be used
         to estimate the value at the unknown location.

         * sectorType-The geometry of the 3D neighborhood. Sectors are
         used to ensure that neighbors are used in different directions around
         the prediction location. All sector types are formed from the Platonic
         solids.

         * ONE_SECTOR-The closest neighbors from any direction will be used.

         * FOUR_SECTORS-Space will be divided into 4 regions, and neighbors
         will be used in each of the 4 regions.

         * SIX_SECTORS-Space will be divided into 6 regions, and neighbors will
         be used in each of the 6 regions.

         * EIGHT_SECTORS-Space will be divided into 8 regions, and neighbors
         will be used in each of the 8 regions.

         * TWELVE_SECTORS-Space will be divided into 12 regions, and neighbors
         will be used in each of the 12 regions.

         * TWENTY_SECTORS-Space will be divided into 20 regions, and neighbors
         will be used in each of the 20 regions.
     output_elevation {Double}:
         The default elevation of the out_ga_layer parameter value.The
         geostatistical layer will draw as a horizontal surface at a given
         elevation, and this parameter specifies this elevation. After it's
         created, the elevation of the geostatistical layer can be changed
         using the range slider.
     output_type {String}:
         Surface type to store the interpolation results.For more information
         about output surface types, see What output
         surface types can the interpolation models generate.

         * PREDICTION-Prediction surfaces are produced from the interpolated
         values.

         * PREDICTION_STANDARD_ERROR-Standard Error surfaces are produced from
         the standard errors of the interpolated values.

         * PROBABILITY-The output surface will be probability surfaces of
         values exceeding or not exceeding a certain threshold.

         * QUANTILE-The output surface will be quantile surfaces predicting the
         specified quantile of the prediction distribution.
     quantile_value {Double}:
         The quantile value for which the output layer will be generated.
     threshold_type {String}:
         Specifies whether to calculate the probability that a value exceeds or
         does not exceed the specified threshold.

         * EXCEED-The probability that the value exceeds the threshold will be
         calculated. This is the default.

         * NOT_EXCEED-The probability that the value does not exceed the
         threshold will be calculated.
     probability_threshold {Double}:
         The probability threshold value. If no value is provided, the median
         (50th quantile) of the input data will be used.

    OUTPUTS:
     out_ga_layer (Geostatistical Layer):
         The output geostatistical layer that will display the interpolation
         result."""
    ...

@gptooldoc("GAMovingWindowKriging_ga", None)
def GAMovingWindowKriging(
    in_ga_model_source=...,
    in_datasets=...,
    in_locations=...,
    neighbors_max=...,
    out_featureclass=...,
    cell_size=...,
    out_surface_grid=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GAMovingWindowKriging_ga(in_ga_model_source, in_datasets;in_datasets..., in_locations, neighbors_max, out_featureclass, {cell_size}, {out_surface_grid})

       Recalculates the Range, Nugget, and Partial Sill semivariogram
       parameters based on a smaller neighborhood, moving through all
       location points.

    INPUTS:
     in_ga_model_source (Geostatistical Layer / File):
         The geostatistical model source to be analyzed.
     in_datasets (Geostatistical Value Table):
         A GeostatisticalDatasets object.Alternatively, it can be a semicolon-
         delimited string of elements.
         Each element is comprised of the following components:

         * The catalog path and name to a dataset or the name of a layer in the
         current table of contents, followed by a space.

         * A sequence of field names, each field name separated by a space. In
         the case of a raster, the cell values will be used.
     in_locations (Feature Layer):
         Point locations where predictions will be performed.
     neighbors_max (Long):
         Number of neighbors to use in the moving window.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.

    OUTPUTS:
     out_featureclass (Feature Class):
         Feature class storing the results.
     out_surface_grid {Raster Dataset}:
         The prediction values in the output feature class are interpolated
         onto a raster using the Local polynomial interpolation method."""
    ...

@gptooldoc("GlobalPolynomialInterpolation_ga", None)
def GlobalPolynomialInterpolation(
    in_features=...,
    z_field=...,
    out_ga_layer=...,
    out_raster=...,
    cell_size=...,
    power=...,
    weight_field=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GlobalPolynomialInterpolation_ga(in_features, z_field, {out_ga_layer}, {out_raster}, {cell_size}, {power}, {weight_field})

       Fits a smooth surface that is defined by a mathematical function (a
       polynomial) to the input sample points.

    INPUTS:
     in_features (Feature Layer):
         The input point features containing the z-values to be interpolated.
     z_field (Field):
         Field that holds a height or magnitude value for each point. This can
         be a numeric field or the Shape field if the input features contain
         z-values or m-values.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.
     power {Long}:
         The order of the polynomial.
     weight_field {Field}:
         Used to emphasize an observation. The larger the weight, the more
         impact it has on the prediction. For coincident observations, assign
         the largest weight to the most reliable measurement.

    OUTPUTS:
     out_ga_layer {Geostatistical Layer}:
         The geostatistical layer produced. This layer is required output only
         if no output raster is requested.
     out_raster {Raster Dataset}:
         The output raster. This raster is required output only if no output
         geostatistical layer is requested."""
    ...

@gptooldoc("IDW_ga", None)
def IDW(
    in_features=...,
    z_field=...,
    out_ga_layer=...,
    out_raster=...,
    cell_size=...,
    power=...,
    search_neighborhood=...,
    weight_field=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """IDW_ga(in_features, z_field, {out_ga_layer}, {out_raster}, {cell_size}, {power}, {search_neighborhood}, {weight_field})

       Uses the measured values surrounding the prediction location to
       predict a value for any unsampled location, based on the assumption
       that things that are close to one another are more alike than those
       that are farther apart.

    INPUTS:
     in_features (Feature Layer):
         The input point features containing the z-values to be interpolated.
     z_field (Field):
         Field that holds a height or magnitude value for each point. This can
         be a numeric field or the Shape field if the input features contain
         z-values or m-values.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.
     power {Double}:
         The exponent of distance that controls the significance of surrounding
         points on the interpolated value. A higher power results in less
         influence from distant points.
     search_neighborhood {Geostatistical Search Neighborhood}:
         Defines which surrounding points will be used to control the output.
         Standard is the default.The following are Search Neighborhood classes:
         SearchNeighborhoodStandard, SearchNeighborhoodSmooth,
         SearchNeighborhoodStandardCircular, and
         SearchNeighborhoodSmoothCircular.Standard

         * majorSemiaxis-The major semiaxis value of the searching
         neighborhood.

         * minorSemiaxis-The minor semiaxis value of the searching
         neighborhood.

         * angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * nbrMax-The maximum number of neighbors that will be used to estimate
         the value at the unknown location.

         * nbrMin-The minimum number of neighbors that will be used to estimate
         the value at the unknown location.

         * sectorType-The geometry of the neighborhood.

         * ONE_SECTOR-Single ellipse.

         * FOUR_SECTORS-Ellipse divided into four sectors.

         * FOUR_SECTORS_SHIFTED-Ellipse divided into four sectors and shifted
         45 degrees.

         * EIGHT_SECTORS-Ellipse divided into eight sectors.

         Smooth

         * majorSemiaxis-The major semiaxis value of the searching
         neighborhood.

         * minorSemiaxis-The minor semiaxis value of the searching
         neighborhood.

         * angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * smoothFactor-The Smooth Interpolation option creates an outer
         ellipse and an inner ellipse at a distance equal to the Major Semiaxis
         multiplied by the Smoothing factor. The points that fall outside the
         smallest ellipse but inside the largest ellipse are weighted using a
         sigmoidal function with a value between zero and one.
         Standard Circular

         * radius-The length of the radius of the search circle.

         * angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * nbrMax-The maximum number of neighbors that will be used to estimate
         the value at the unknown location.

         * nbrMin-The minimum number of neighbors that will be used to estimate
         the value at the unknown location.

         * sectorType-The geometry of the neighborhood.

         * ONE_SECTOR-Single ellipse.

         * FOUR_SECTORS-Ellipse divided into four sectors.

         * FOUR_SECTORS_SHIFTED-Ellipse divided into four sectors and shifted
         45 degrees.

         * EIGHT_SECTORS-Ellipse divided into eight sectors.

         Smooth Circular

         * radius-The length of the radius of the search circle.

         * smoothFactor-The Smooth Interpolation option creates an outer
         ellipse and an inner ellipse at a distance equal to the Major Semiaxis
         multiplied by the Smoothing factor. The points that fall outside the
         smallest ellipse but inside the largest ellipse are weighted using a
         sigmoidal function with a value between zero and one.
     weight_field {Field}:
         Used to emphasize an observation. The larger the weight, the more
         impact it has on the prediction. For coincident observations, assign
         the largest weight to the most reliable measurement.

    OUTPUTS:
     out_ga_layer {Geostatistical Layer}:
         The geostatistical layer produced. This layer is required output only
         if no output raster is requested.
     out_raster {Raster Dataset}:
         The output raster. This raster is required output only if no output
         geostatistical layer is requested."""
    ...

@gptooldoc("KernelInterpolationWithBarriers_ga", None)
def KernelInterpolationWithBarriers(
    in_features=...,
    z_field=...,
    out_ga_layer=...,
    out_raster=...,
    cell_size=...,
    in_barrier_features=...,
    kernel_function=...,
    bandwidth=...,
    power=...,
    ridge=...,
    output_type=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """KernelInterpolationWithBarriers_ga(in_features, z_field, {out_ga_layer}, {out_raster}, {cell_size}, {in_barrier_features}, {kernel_function}, {bandwidth}, {power}, {ridge}, {output_type})

       A moving window predictor that uses the shortest distance between
       points so that points on either side of the line barriers are
       connected.

    INPUTS:
     in_features (Feature Layer):
         The input point features containing the z-values to be interpolated.
     z_field (Field):
         Field that holds a height or magnitude value for each point. This can
         be a numeric field or the Shape field if the input features contain
         z-values or m-values.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.
     in_barrier_features {Feature Layer}:
         Absolute barrier features using non-Euclidean distances rather than
         line-of-sight distances.
     kernel_function {String}:
         The kernel function used in the simulation.

         * EXPONENTIAL-The function grows or decays proportionally.

         * GAUSSIAN-Bell-shaped function that falls off quickly toward
         plus/minus infinity.

         * QUARTIC-Fourth-order polynomial function.

         * EPANECHNIKOV-A discontinuous parabolic function.

         * POLYNOMIAL5-Fifth-order polynomial function.

         * CONSTANT-An indicator function.
     bandwidth {Double}:
         Used to specify the maximum distance at which data points are used for
         prediction. With increasing bandwidth, prediction bias increases and
         prediction variance decreases.
     power {Long}:
         Sets the order of the polynomial.
     ridge {Double}:
         Used for the numerical stabilization of the solution of the system of
         linear equations. It does not influence predictions in the case of
         regularly distributed data without barriers. Predictions for areas in
         which the data is located near the feature barrier or isolated by the
         barriers can be unstable and tend to require relatively large ridge
         parameter values.
     output_type {String}:
         Surface type to store the interpolation results.For more information
         about the output surface types, see What output
         surface types can the interpolation models generate?

         * PREDICTION-Prediction surfaces are produced from the interpolated
         values.

         * PREDICTION_STANDARD_ERROR-Standard Error surfaces are produced from
         the standard errors of the interpolated values.

    OUTPUTS:
     out_ga_layer {Geostatistical Layer}:
         The geostatistical layer produced. This layer is required output only
         if no output raster is requested.
     out_raster {Raster Dataset}:
         The output raster. This raster is required output only if no output
         geostatistical layer is requested."""
    ...

@gptooldoc("LocalPolynomialInterpolation_ga", None)
def LocalPolynomialInterpolation(
    in_features=...,
    z_field=...,
    out_ga_layer=...,
    out_raster=...,
    cell_size=...,
    power=...,
    search_neighborhood=...,
    kernel_function=...,
    bandwidth=...,
    use_condition_number=...,
    condition_number=...,
    weight_field=...,
    output_type=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """LocalPolynomialInterpolation_ga(in_features, z_field, {out_ga_layer}, {out_raster}, {cell_size}, {power}, {search_neighborhood}, {kernel_function}, {bandwidth}, {use_condition_number}, {condition_number}, {weight_field}, {output_type})

       Fits the specified order (zero, first, second, third, and so on)
       polynomial, each within specified overlapping neighborhoods, to
       produce an output surface.

    INPUTS:
     in_features (Feature Layer):
         The input point features containing the z-values to be interpolated.
     z_field (Field):
         Field that holds a height or magnitude value for each point. This can
         be a numeric field or the Shape field if the input features contain
         z-values or m-values.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.
     power {Long}:
         The order of the polynomial.
     search_neighborhood {Geostatistical Search Neighborhood}:
         Defines which surrounding points will be used to control the output.
         Standard is the default.The following are Search Neighborhood classes:
         SearchNeighborhoodStandard, SearchNeighborhoodSmooth,
         SearchNeighborhoodStandardCircular, and
         SearchNeighborhoodSmoothCircular.Standard

         * majorSemiaxis-The major semiaxis value of the searching
         neighborhood.

         * minorSemiaxis-The minor semiaxis value of the searching
         neighborhood.

         * angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * nbrMax-The maximum number of neighbors that will be used to estimate
         the value at the unknown location.

         * nbrMin-The minimum number of neighbors that will be used to estimate
         the value at the unknown location.

         * sectorType-The geometry of the neighborhood.

         * ONE_SECTOR-Single ellipse.

         * FOUR_SECTORS-Ellipse divided into four sectors.

         * FOUR_SECTORS_SHIFTED-Ellipse divided into four sectors and shifted
         45 degrees.

         * EIGHT_SECTORS-Ellipse divided into eight sectors.

         Smooth

         * majorSemiaxis-The major semiaxis value of the searching
         neighborhood.

         * minorSemiaxis-The minor semiaxis value of the searching
         neighborhood.

         * angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * smoothFactor-The Smooth Interpolation option creates an outer
         ellipse and an inner ellipse at a distance equal to the Major Semiaxis
         multiplied by the Smoothing factor. The points that fall outside the
         smallest ellipse but inside the largest ellipse are weighted using a
         sigmoidal function with a value between zero and one.
         Standard Circular

         * radius-The length of the radius of the search circle.

         * angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * nbrMax-The maximum number of neighbors that will be used to estimate
         the value at the unknown location.

         * nbrMin-The minimum number of neighbors that will be used to estimate
         the value at the unknown location.

         * sectorType-The geometry of the neighborhood.

         * ONE_SECTOR-Single ellipse.

         * FOUR_SECTORS-Ellipse divided into four sectors.

         * FOUR_SECTORS_SHIFTED-Ellipse divided into four sectors and shifted
         45 degrees.

         * EIGHT_SECTORS-Ellipse divided into eight sectors.

         Smooth Circular

         * radius-The length of the radius of the search circle.

         * smoothFactor-The Smooth Interpolation option creates an outer
         ellipse and an inner ellipse at a distance equal to the Major Semiaxis
         multiplied by the Smoothing factor. The points that fall outside the
         smallest ellipse but inside the largest ellipse are weighted using a
         sigmoidal function with a value between zero and one.
     kernel_function {String}:
         The kernel function used in the simulation.

         * EXPONENTIAL-The function grows or decays proportionally.

         * GAUSSIAN-Bell-shaped function that falls off quickly toward plus or
         minus infinity.

         * QUARTIC-Fourth-order polynomial function.

         * EPANECHNIKOV-A discontinuous parabolic function.

         * POLYNOMIAL5-Fifth-order polynomial function.

         * CONSTANT-An indicator function.
     bandwidth {Double}:
         Used to specify the maximum distance at which data points are used for
         prediction. With increasing bandwidth, prediction bias increases and
         prediction variance decreases.
     use_condition_number {Boolean}:
         Option to control the creation of prediction and prediction standard
         errors where the predictions are unstable. This option is only
         available for polynomials of order 1, 2, and 3.

         * NO_USE_CONDITION_NUMBER-Predictions will be created everywhere,
         including areas where the predictions are unstable. This is the
         default.

         * USE_CONDITION_NUMBER-Prediction and prediction standard errors will
         not be created where the predictions are unstable.
     condition_number {Double}:
         Every invertible square matrix has a condition number that indicates
         how inaccurate the solution to the linear equations can be with a
         small change in the matrix coefficients (it can be due to imprecise
         data). If the condition number is large, a small change in the matrix
         coefficients results in a large change in the solution vector.
     weight_field {Field}:
         Used to emphasize an observation. The larger the weight, the more
         impact it has on the prediction. For coincident observations, assign
         the largest weight to the most reliable measurement.
     output_type {String}:
         Surface type to store the interpolation results.For more information
         about the output surface types, see What output
         surface types can the interpolation models generate?

         * PREDICTION-Prediction surfaces are produced from the interpolated
         values.

         * PREDICTION_STANDARD_ERROR-Standard Error surfaces are produced from
         the standard errors of the interpolated values.

         * CONDITION_NUMBER-The Spatial condition number surface indicates the
         stability of calculations at a particular location. The larger the
         condition number, the more unstable the prediction, so locations with
         large condition numbers may be prone to artifacts and erratic
         predicted values.

    OUTPUTS:
     out_ga_layer {Geostatistical Layer}:
         The geostatistical layer produced. This layer is required output only
         if no output raster is requested.
     out_raster {Raster Dataset}:
         The output raster. This raster is required output only if no output
         geostatistical layer is requested."""
    ...

@gptooldoc("NearestNeighbor3D_ga", None)
def NearestNeighbor3D(
    in_features=...,
    category_field=...,
    out_netcdf_file=...,
    x_spacing=...,
    y_spacing=...,
    elevation_spacing=...,
    elev_inflation_factor=...,
    in_study_area=...,
    min_elev_raster=...,
    max_elev_raster=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """NearestNeighbor3D_ga(in_features, category_field;category_field..., out_netcdf_file, {x_spacing}, {y_spacing}, {elevation_spacing}, {elev_inflation_factor}, {in_study_area}, {min_elev_raster}, {max_elev_raster})

       Creates a voxel layer source file (netCDF) from categorical 3D points
       by assigning each voxel the categories of the nearest neighbor in 3D.

    INPUTS:
     in_features (Feature Layer):
         The input points representing locations with known categories in 3D.
         The points must be in a projected coordinate system, and there must be
         at least three points.
     category_field (Field):
         The fields of the input features containing the categories of each
         point. For each field, the unique values of the field represent the
         categories of the field. Each field must be Text, Short, or Long
         type.For example, you can provide a field of soil classes (shale,
         sand,
         clay, and so on) and a second field of the color of the soil (yellow,
         brown, white, and so on). Each voxel in the output netCDF file will
         store the nearest soil class and soil color as separate variables.
     x_spacing {Linear Unit}:
         The spacing between each gridded point in the x-dimension. The default
         value creates 40 points along the output x-extent.
     y_spacing {Linear Unit}:
         The spacing between each gridded point in the y-dimension. The default
         value creates 40 points along the output y-extent.
     elevation_spacing {Linear Unit}:
         The spacing between each gridded point in the elevation (z) dimension.
         The default value creates 40 points along the output z-extent.
     elev_inflation_factor {Double}:
         A constant value that is multiplied to the elevation (z-coordinates)
         of the input points prior to finding the nearest neighbor. Values
         larger than 1 will search farther horizontally than vertically to find
         the nearest neighbor. For example, a value of 10 means that each voxel
         will search 10 times farther horizontally than vertically to find the
         closest neighbor. The default is 1, meaning that the elevations are
         not adjusted. The value must be between 1 and 1,000.Elevation
         inflation is only used to find the nearest neighbor, and all
         elevations are returned to the original scale before creating the
         output netCDF file. Elevation inflation is recommended when the
         categories of the input points tend to be similar along horizontal
         strata, such as with soil classes and rock types.
     in_study_area {Feature Layer}:
         The polygon features that represent the study area. Only points that
         are within the study area are saved in the output netCDF file. When
         visualized as a voxel layer, only voxels within the study area will
         display in the scene. Points are determined to be inside or outside of
         the study area using only their x- and y-coordinates.
     min_elev_raster {Raster Layer}:
         The elevation raster that will be used to clip the bottom of the voxel
         layer. Only voxels above this elevation raster will be assigned
         categories. For example, if you use a ground elevation raster, the
         voxel layer will only display above the ground. It can also be used
         for bedrock surfaces or the bottom of a shale deposit.The raster must
         be in a projected coordinate system, and the elevation
         values must be in the same unit as the vertical unit of the raster.
     max_elev_raster {Raster Layer}:
         The elevation raster that will be used to clip the top of the voxel
         layer. Only voxels below this elevation raster will be assigned
         categories. For example, if you use a ground elevation raster, the
         voxel layer will only display below the ground. It can also be used to
         clip voxels to the top of a restricted airspace.The raster must be in
         a projected coordinate system, and the elevation
         values must be in the same unit as the vertical unit of the raster.

    OUTPUTS:
     out_netcdf_file (File):
         The output netCDF file containing categories in a 3D grid. Each point
         in the 3D grid is assigned the category of the closest input point.
         This file can be used as the data source of a voxel layer."""
    ...

@gptooldoc("RadialBasisFunctions_ga", None)
def RadialBasisFunctions(
    in_features=...,
    z_field=...,
    out_ga_layer=...,
    out_raster=...,
    cell_size=...,
    search_neighborhood=...,
    radial_basis_functions=...,
    small_scale_parameter=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """RadialBasisFunctions_ga(in_features, z_field, {out_ga_layer}, {out_raster}, {cell_size}, {search_neighborhood}, {radial_basis_functions}, {small_scale_parameter})

       Uses one of five basis functions to interpolate a surfaces that passes
       through the input points exactly.

    INPUTS:
     in_features (Feature Layer):
         The input point features containing the z-values to be interpolated.
     z_field (Field):
         Field that holds a height or magnitude value for each point. This can
         be a numeric field or the Shape field if the input features contain
         z-values or m-values.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.
     search_neighborhood {Geostatistical Search Neighborhood}:
         Defines which surrounding points will be used to control the output.
         Standard is the default.The following are Search Neighborhood classes:
         SearchNeighborhoodStandard and
         SearchNeighborhoodStandardCircular.Standard

         * majorSemiaxis-The major semiaxis value of the searching
         neighborhood.

         * minorSemiaxis-The minor semiaxis value of the searching
         neighborhood.

         * angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * nbrMax-The maximum number of neighbors that will be used to estimate
         the value at the unknown location.

         * nbrMin-The minimum number of neighbors that will be used to estimate
         the value at the unknown location.

         * sectorType-The geometry of the neighborhood.

         * ONE_SECTOR-Single ellipse.

         * FOUR_SECTORS-Ellipse divided into four sectors.

         * FOUR_SECTORS_SHIFTED-Ellipse divided into four sectors and shifted
         45 degrees.

         * EIGHT_SECTORS-Ellipse divided into eight sectors.

         Standard Circular

         * radius-The length of the radius of the search circle.

         * Angle-The angle of rotation for the axis (circle) or semimajor axis
         (ellipse) of the moving window.

         * nbrMax-The maximum number of neighbors that will be used to estimate
         the value at the unknown location.

         * nbrMin-The minimum number of neighbors that will be used to estimate
         the value at the unknown location.

         * sectorType-The geometry of the neighborhood.

         * ONE_SECTOR-Single ellipse.

         * FOUR_SECTORS-Ellipse divided into four sectors.

         * FOUR_SECTORS_SHIFTED-Ellipse divided into four sectors and shifted
         45 degrees.

         * EIGHT_SECTORS-Ellipse divided into eight sectors.
     radial_basis_functions {String}:
         There are five radial basis functions available.

         * THIN_PLATE_SPLINE-Thin-plate spline function

         * SPLINE_WITH_TENSION-Spline with tension function

         * COMPLETELY_REGULARIZED_SPLINE-Completely regularized spline
         function

         * MULTIQUADRIC_FUNCTION-Multiquadric spline function

         * INVERSE_MULTIQUADRIC_FUNCTION-Inverse multiquadric spline function
     small_scale_parameter {Double}:
         Used to calculate the weights assigned to the points located in the
         moving window. Each of the radial basis functions has a parameter that
         controls the degree of small-scale variation of the surface. The
         (optimal) parameter is determined by finding the value that minimizes
         the root mean square prediction error (RMSPE).

    OUTPUTS:
     out_ga_layer {Geostatistical Layer}:
         The geostatistical layer produced. This layer is required output only
         if no output raster is requested.
     out_raster {Raster Dataset}:
         The output raster. This raster is required output only if no output
         geostatistical layer is requested."""
    ...

@gptooldoc("CreateSpatiallyBalancedPoints_ga", None)
def CreateSpatiallyBalancedPoints(
    in_probability_raster=..., number_output_points=..., out_feature_class=...
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CreateSpatiallyBalancedPoints_ga(in_probability_raster, number_output_points, out_feature_class)

       Generates a set of sample points based on inclusion probabilities,
       resulting in a spatially balanced sample design. This tool is
       generally used for designing a monitoring network by suggesting
       locations to take samples, and a preference for particular locations
       can be defined using an inclusion probability raster.

    INPUTS:
     in_probability_raster (Raster Layer / Mosaic Layer):
         This raster defines the inclusion probabilities for each location in
         the area of interest. The location values range from 0 (low inclusion
         probability) to 1 (high inclusion probability).
     number_output_points (Long):
         Specify how many sample locations to generate.

    OUTPUTS:
     out_feature_class (Feature Class):
         The output feature class contains the selected sample locations and
         their inclusion probabilities."""
    ...

@gptooldoc("DensifySamplingNetwork_ga", None)
def DensifySamplingNetwork(
    in_geostat_layer=...,
    number_output_points=...,
    out_feature_class=...,
    selection_criteria=...,
    threshold=...,
    in_weight_raster=...,
    in_candidate_point_features=...,
    inhibition_distance=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """DensifySamplingNetwork_ga(in_geostat_layer, number_output_points, out_feature_class, {selection_criteria}, {threshold}, {in_weight_raster}, {in_candidate_point_features}, {inhibition_distance})

       Uses a predefined geostatistical kriging layer to determine where new
       monitoring stations should be built. It can also be used to determine
       which monitoring stations should be removed from an existing network.

    INPUTS:
     in_geostat_layer (Geostatistical Layer):
         Input a geostatistical layer resulting from a Kriging model.
     number_output_points (Long):
         Specify how many sample locations to generate.
     selection_criteria {String}:
         Methods to densify a sampling network.

         * STDERR-Standard error of prediction criteria

         * STDERR_THRESHOLD-Standard error threshold criteria

         * QUARTILE_THRESHOLD-Lower quartile threshold criteria

         * QUARTILE_THRESHOLD_UPPER-Upper quartile threshold criteria
         The STERR option will give extra weight to locations where the
         standard error of prediction is large. The STDERR_THRESHOLD,
         QUARTILE_THRESHOLD, and QUARTILE_THRESHOLD_UPPER options are useful
         when there is a critical threshold value for the variable under study
         (such as the highest admissible ozone level). The STDERR_THRESHOLD
         option will give extra weight to locations whose values are close to
         the threshold. The QUARTILE_THRESHOLD option will give extra weight to
         locations that are least likely to exceed the critical threshold. The
         QUARTILE_THRESHOLD_UPPER option will give extra weight to locations
         that are most likely to exceed the critical threshold. The
         equations for each option are:        Standard error of
         prediction = stderr Standard error threshold =
         stderr(s)(1 - 2 · abs(prob[Z(s) > threshold] - 0.5)) Lower quartile
         threshold = (Z0.75(s) - Z0.25(s)) · (prob[Z(s) < threshold]) Upper
         quartile threshold = (Z0.75(s) - Z0.25(s)) · (prob[Z(s) > threshold])
     threshold {Double}:
         The threshold value used to densify the sampling network.This
         parameter is only applicable when Standard error threshold, Lower
         quartile threshold, or Upper quartile threshold selection criteria is
         used.
     in_weight_raster {Raster Layer}:
         A raster used to determine which locations to weight for preference.
     in_candidate_point_features {Feature Layer}:
         Sample locations to pick from.
     inhibition_distance {Linear Unit}:
         Used to prevent any samples being placed within this distance from
         each other.

    OUTPUTS:
     out_feature_class (Feature Class):
         The name of the output feature class."""
    ...

@gptooldoc("ExtractValuesToTable_ga", None)
def ExtractValuesToTable(
    in_features=...,
    in_rasters=...,
    out_table=...,
    out_raster_names_table=...,
    add_warning_field=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ExtractValuesToTable_ga(in_features, in_rasters;in_rasters..., out_table, {out_raster_names_table}, {add_warning_field})

       Extracts cell values from a set of rasters to a table, based on a
       point or polygon feature class.

    INPUTS:
     in_features (Feature Layer):
         The points or polygon features to be created.
     in_rasters (Raster Layer / Mosaic Layer):
         The rasters must all have the same extent, coordinate system, and cell
         size.
     add_warning_field {Boolean}:
         Records if input features are partially or completely covered by the
         Input rasters.

         * ADD_WARNING_FIELD-Warning field is added to the output table and
         populated with a P when a feature is partially covered by raster
         values.

         * DO_NOT_ADD_WARNING_FIELD-Warning field is not added to the output
         table.

    OUTPUTS:
     out_table (Table):
         The output table contains a record for each point and each raster that
         has data. If polygon features are input, they are converted to points
         that coincide with the raster cell centers.
     out_raster_names_table {Table}:
         Saves the names of the Input rasters to disc."""
    ...

@gptooldoc("GaussianGeostatisticalSimulations_ga", None)
def GaussianGeostatisticalSimulations(
    in_geostat_layer=...,
    number_of_realizations=...,
    output_workspace=...,
    output_simulation_prefix=...,
    in_conditioning_features=...,
    conditioning_field=...,
    cell_size=...,
    in_bounding_dataset=...,
    save_simulated_rasters=...,
    quantile=...,
    threshold=...,
    in_stats_polygons=...,
    raster_stat_type=...,
    conditioning_measurement_error_field=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GaussianGeostatisticalSimulations_ga(in_geostat_layer, number_of_realizations, output_workspace, output_simulation_prefix, {in_conditioning_features}, {conditioning_field}, {cell_size}, {in_bounding_dataset}, {save_simulated_rasters}, {quantile}, {threshold}, {in_stats_polygons}, {raster_stat_type;raster_stat_type...}, {conditioning_measurement_error_field})

       Performs a conditional or unconditional geostatistical simulation
       based on a Simple Kriging model. The simulated rasters can be
       considered equally probable realizations of the kriging model.

    INPUTS:
     in_geostat_layer (Geostatistical Layer):
         Input a geostatistical layer resulting from a Simple Kriging model.
     number_of_realizations (Long):
         The number of simulations to perform.
     output_workspace (Workspace):
         Stores all the simulation results. The workspace can be either a
         folder or a geodatabase.
     output_simulation_prefix (String):
         A one- to three-character alphanumeric prefix that is automatically
         added to the output dataset names.
     in_conditioning_features {Feature Layer}:
         The features used to condition the realizations. If left blank,
         unconditional realizations are produced.
     conditioning_field {Field}:
         The field used to condition the realizations. If left blank,
         unconditional realizations are produced.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.
     in_bounding_dataset {Feature Layer}:
         Limits the analysis to these features' bounding polygon. If point
         features are entered, then a convex hull polygon is automatically
         created. Realizations are then performed within that polygon. If
         bounding features are supplied, any features or rasters supplied in
         the Mask environment will be ignored.
     save_simulated_rasters {Boolean}:
         Specifies whether or not the simulated rasters are saved to disk.

         * SAVE_SIMULATIONS-Indicates that the simulated rasters will be saved
         to disk.

         * DO_NOT_SAVE_SIMULATIONS-Indicates that the simulated rasters will
         not be saved to disk.
     quantile {Double}:
         The quantile value for which the output raster will be generated.
     threshold {Double}:
         The threshold value for which the output raster will be generated, as
         the percentage of the number of times the set threshold was exceeded,
         on a cell-by-cell basis.
     in_stats_polygons {Feature Layer}:
         These polygons represent areas of interest for which summary
         statistics are calculated.If in_stats_polygons are provided, the
         output polygon feature class
         will be saved in the location defined by output_workspace, and it will
         have the same name as the input polygons, preceded by the
         output_simulation_prefix. For example, if the input statistical
         polygons were named myPolys and you entered aaa as the output prefix,
         then the output polygons will be named aaamyPolys and will be saved in
         the specified output workspace.
     raster_stat_type {String}:
         The simulated rasters are postprocessed on a cell-by-cell basis, and
         each selected statistics type is calculated and reported in an output
         raster.

         * MIN-Calculates the minimum (smallest value).

         * MAX-Calculates the maximum (largest value).

         * MEAN-Calculates the mean (average).

         * STDDEV-Calculates the standard deviation.

         * QUARTILE1-Calculates the 25th quantile.

         * MEDIAN-Calculates the median.

         * QUARTILE3-Calculates the 75th quantile.

         * QUANTILE-Calculates a user-specified quantile (0 < Q < 1).

         * P_THRSHLD-Calculates the percentage of the simulations where the
         cell value exceeds a user-specified threshold value.
     conditioning_measurement_error_field {Field}:
         A field that specifies the measurement error for each input point in
         the conditioning features. For each conditioning feature, the value of
         this field should correspond to one standard deviation of the measured
         value of the feature. Use this field if the measurement error values
         are not the same at each sampling location.A common source of
         nonconstant measurement error is when the data is
         measured with different devices. One device might be more precise than
         another, which means that it will have a smaller measurement error.
         For example, one thermometer rounds to the nearest degree and another
         thermometer rounds to the nearest tenth of a degree. The variability
         of measurements is often provided by the manufacturer of the measuring
         device, or it may be known from empirical practice.Leave this
         parameter blank if there are no measurement error values or
         the measurement error values are unknown."""
    ...

@gptooldoc("CompareGeostatisticalLayers_ga", None)
def CompareGeostatisticalLayers(
    in_geostat_layers=...,
    out_cv_table=...,
    out_geostat_layer=...,
    comparison_method=...,
    criterion=...,
    criteria_hierarchy=...,
    weighted_criteria=...,
    exclusion_criteria=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CompareGeostatisticalLayers_ga(in_geostat_layers;in_geostat_layers..., out_cv_table, {out_geostat_layer}, {comparison_method}, {criterion}, {criteria_hierarchy;criteria_hierarchy...}, {weighted_criteria;weighted_criteria...}, {exclusion_criteria;exclusion_criteria...})

       Compares and ranks geostatistical layers using customizable criteria
       based on cross validation statistics.

    INPUTS:
     in_geostat_layers (Geostatistical Layer):
         The geostatistical layers representing interpolation results. Each
         layer will be compared and ranked.
     comparison_method {String}:
         Specifies the method that will be used to compare and rank the
         interpolation results.

         * SINGLE-A single cross validation statistic will be used to compare
         and rank results, such as highest prediction accuracy or lowest bias.
         The criterion from the criterion parameter is used.

         * SORTING-Hierarchical sorting will be used to compare results.
         Multiple criteria are specified in priority order (highest priority
         first) in the criteria_hierarchy parameter. The interpolation results
         are ranked by the first criterion, and any ties are broken by the
         second criterion. Ties in the second criterion are broken by the third
         criterion, and so on. Cross validation statistics are continuous
         values and generally do not have exact ties, so tolerances (percent or
         absolute) can be specified to create ties in each of the criteria.

         * AVERAGE_RANK-The weighted average rank of multiple criteria will be
         used to compare results. Multiple criteria and associated weights are
         specified in the weighted_criteria parameter. The interpolation
         results are ranked independently by each of the criteria, and a
         weighted average of the ranks is used to determine the final ranks.
         Criteria with larger weights will have more influence on the final
         ranks, so weights can be used to indicate preference for certain
         criteria over others.
     criterion {String}:
         Specifies the criterion that will be used to rank the interpolation
         results.

         * ACCURACY-Results will be ranked by lowest root mean square error.
         This option measures how closely the cross validation predictions
         match the true values, on average. This is the default.

         * BIAS-Results will be ranked by mean error closest to zero. This
         option measures how much the cross validation predictions overpredict
         or underpredict the true values, on average. Interpolation results
         with positive mean errors systematically overpredict the true values
         (positive bias), and results with negative mean errors systematically
         underpredict the true values (negative bias).

         * WORST_CASE-Results will be ranked by lowest maximum absolute error.
         This option measures only the single least accurate cross validation
         prediction (positive or negative). This is useful when you are most
         concerned about worst-case scenarios rather than the accuracy in
         typical conditions.

         * STANDARD_ERROR-Results will be ranked by root mean square
         standardized error closest to one. This option measures how closely
         the variability of the cross validation predictions match the
         estimated standard errors. This is useful if you intend to create
         confidence intervals or margins of error for the predictions.

         * PRECISION-Results will be ranked by lowest average standard error.
         When creating confidence intervals or margins of error for the
         predicted values, results with higher precision will have narrower
         intervals around the predictions. It does not measure whether the
         standard errors are estimated accurately, only that the standard
         errors are small. When using this option, it is recommended that you
         include minimum and maximum root mean square standardized error values
         as exclusion criteria to ensure that the standard errors are both
         accurate and precise.
     criteria_hierarchy {Value Table}:
         The hierarchy of criteria that will be used for hierarchical sorting
         with tolerances. Provide multiple criteria in priority order with the
         first being most important. The interpolation results are ranked by
         the first criterion, and any ties are broken by the second criterion.
         Ties in the second criterion are broken by the third criterion, and so
         on. Cross validation statistics are continuous values and generally do
         not have exact ties, so tolerances are used to induce ties in the
         criteria. For each row, specify a criterion in the first column, a
         tolerance type (percent or absolute) in the second column, and a
         tolerance value in the third column. If no tolerance value is
         provided, no tolerance will be used; this is most useful for the final
         row so that there will be no ties for the interpolation result with
         highest rank. For each row (level of the hierarchy), the
         following criteria
         are available:

         * ACCURACY-Results will be ranked by highest accuracy.

         * BIAS-Results will be ranked by lowest bias.

         * WORST_CASE-Results will be ranked by lowest worst-case error.

         * STANDARD_ERROR-Results will be ranked by highest standard error
         accuracy.

         * PRECISION-Results will be ranked by highest precision.
         For example, you can specify an ACCURACY value with a 5 percent
         tolerance in the first row and a BIAS value with no tolerance in the
         second row. These options will first rank the interpolation results by
         lowest root mean square error (highest prediction accuracy), and all
         interpolation results whose root mean square error values are within 5
         percent of the most accurate result will be considered ties by
         prediction accuracy. Among the tying results, the result with a mean
         error closest to zero (lowest bias) will receive the highest rank.
     weighted_criteria {Value Table}:
         The multiple criteria with weights that will be used to rank
         interpolation results. For each row, provide a criterion and a weight.
         The interpolation results will be ranked independently by each of the
         criteria, and a weighted average of the ranks will be used to
         determine the final ranks of the interpolation results.

         * ACCURACY-Results will be ranked by lowest root mean square error.

         * BIAS-Results will be ranked by mean error closest to zero.

         * WORST_CASE-Results will be ranked by lowest maximum absolute error.

         * STANDARD_ERROR-Results will be ranked by root mean square
         standardized error closest to one.

         * PRECISION-Results will be ranked by lowest average standard error.
     exclusion_criteria {Value Table}:
         The criteria and associated values that will be used to
         exclude interpolation results from the comparison. Excluded results
         will not receive ranks and will have the value No in the Included
         field of the output cross validation table.

         * MAX_RMSE-Results will be excluded if the root mean square error
         exceeds the specified value. The value cannot be negative. This option
         measures prediction accuracy.

         * MAX_WORST_CASE-Results will be excluded if the maximum absolute
         error exceeds the specified value. The value cannot be negative. This
         option measures the worst-case error.

         * MAX_STD_RMSE-Results will be excluded if the root mean square
         standard error exceeds the specified value. The value must be greater
         than or equal to 1. This option measures standard error accuracy.

         * MIN_STD_RMSE-Results will be excluded if the root mean square
         standardized error does not exceed the specified value. The value must
         be between 0 and 1. This option measures standard error accuracy.

         * MAX_MEAN_ERROR-Results will be excluded if the mean error exceeds
         the specified value. The value cannot be negative. This option
         measures bias.

         * MIN_MEAN_ERROR-Results will be excluded if the mean error does not
         exceed the specified value. The value cannot be positive. This option
         measures bias.

         * MAX_ASE-Results will be excluded if the average standard square
         error exceeds the specified value. The value cannot be negative. This
         option measures precision.

         * MIN_PERC_ERROR-Results will be excluded if the interpolation result
         is not sufficiently more accurate than a baseline nonspatial model
         that predicts the global average value at all locations in the map.
         This relative accuracy is measured by comparing the root mean square
         error value to the standard deviation of the values of the points
         being interpolated, and the root mean square error must be at least
         the specified percent less than the standard deviation to be included
         in the comparison. For example, a value of 10 means that the root mean
         square error must be at least 10 percent lower than the standard
         deviation to be included in the comparison and ranking. The value must
         be between 0 and 100. This option measures prediction accuracy.

    OUTPUTS:
     out_cv_table (Table):
         The output table containing cross validation statistics and ranks for
         each interpolation result. The final ranks of the interpolation
         results are stored in the RANK field.
     out_geostat_layer {Geostatistical Layer}:
         The output geostatistical layer of the interpolation result with
         highest rank. This interpolation result will have the value 1 in the
         RANK field of the output cross validation table. If there are ties for
         the interpolation result with highest rank or all results are excluded
         by exclusion criteria, the layer will not be created even if a value
         is provided. Warning messages will be returned by the tool if this
         occurs."""
    ...

@gptooldoc("CrossValidation_ga", None)
def CrossValidation(
    in_geostat_layer=..., out_point_feature_class=...
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CrossValidation_ga(in_geostat_layer, {out_point_feature_class})

       Removes one data location and predicts the associated data using the
       data at the rest of the locations. The primary use for this tool is to
       compare the predicted value to the observed value in order to obtain
       useful information about some of your model parameters.

    INPUTS:
     in_geostat_layer (Geostatistical Layer):
         The geostatistical layer to be analyzed.

    OUTPUTS:
     out_point_feature_class {Feature Class}:
         Stores the cross-validation statistics at each location in the
         geostatistical layer."""
    ...

@gptooldoc("ExploratoryInterpolation_ga", None)
def ExploratoryInterpolation(
    in_features=...,
    value_field=...,
    out_cv_table=...,
    out_geostat_layer=...,
    interp_methods=...,
    comparison_method=...,
    criterion=...,
    criteria_hierarchy=...,
    weighted_criteria=...,
    exclusion_criteria=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ExploratoryInterpolation_ga(in_features, value_field, out_cv_table, {out_geostat_layer}, {interp_methods;interp_methods...}, {comparison_method}, {criterion}, {criteria_hierarchy;criteria_hierarchy...}, {weighted_criteria;weighted_criteria...}, {exclusion_criteria;exclusion_criteria...})

       Generates various interpolation results from input point features and
       a field. The interpolation results are then compared and ranked using
       customizable criteria based on cross validation statistics.

    INPUTS:
     in_features (Feature Layer):
         The input points representing locations of points to be interpolated.
     value_field (Field):
         The field containing the values to be interpolated.
     interp_methods {String}:
         Specifies the interpolation methods that will be performed on the
         input features and value field. For each method specified, 1 to 5
         interpolation results will be generated. By default, all methods will
         be generated except inverse distance weighting, radial basis
         functions, and global polynomial (because these methods cannot create
         standard errors of predictions). By default, 11 interpolation results
         will be generated. If all options are specified, 20 interpolation
         results will be generated.

         * SIMPLE_KRIGING-Four simple kriging results will be generated:
         default, optimized, trend removal, and transformation with trend
         removal.

         * ORDINARY_KRIGING-Two ordinary kriging results will be generated:
         default and optimized.

         * UNIVERSAL_KRIGING-Two universal kriging results will be generated:
         default and optimized.

         * EBK-Two empirical Bayesian kriging results will be generated:
         default and advanced.

         * KERNEL_INTERPOLATION-One default kernel (local polynomial)
         interpolation result will be generated.

         * IDW-Two inverse distance weighting results will be generated:
         default and optimized.

         * RBF-Five radial basis functions results will be generated, one for
         each of the five kernel functions.

         * GPI-Two global polynomial interpolation results will be generated:
         linear (first order) and quadratic (second order) trend.
     comparison_method {String}:
         Specifies the method that will be used to compare and rank the
         interpolation results.

         * SINGLE-A single cross validation statistic will be used to compare
         and rank results, such as highest prediction accuracy or lowest bias.
         The criterion from the criterion parameter is used.

         * SORTING-Hierarchical sorting will be used to compare results.
         Multiple criteria are specified in priority order (highest priority
         first) in the criteria_hierarchy parameter. The interpolation results
         are ranked by the first criterion, and any ties are broken by the
         second criterion. Ties in the second criterion are broken by the third
         criterion, and so on. Cross validation statistics are continuous
         values and generally do not have exact ties, so tolerances (percent or
         absolute) can be specified to create ties in each of the criteria.

         * AVERAGE_RANK-The weighted average rank of multiple criteria will be
         used to compare results. Multiple criteria and associated weights are
         specified in the weighted_criteria parameter. The interpolation
         results are ranked independently by each of the criteria, and a
         weighted average of the ranks is used to determine the final ranks.
         Criteria with larger weights will have more influence on the final
         ranks, so weights can be used to indicate preference for certain
         criteria over others.
     criterion {String}:
         Specifies the criterion that will be used to rank the interpolation
         results.

         * ACCURACY-Results will be ranked by lowest root mean square error.
         This option measures how closely the cross validation predictions
         match the true values, on average. This is the default.

         * BIAS-Results will be ranked by mean error closest to zero. This
         option measures how much the cross validation predictions overpredict
         or underpredict the true values, on average. Interpolation results
         with positive mean errors systematically overpredict the true values
         (positive bias), and results with negative mean errors systematically
         underpredict the true values (negative bias).

         * WORST_CASE-Results will be ranked by lowest maximum absolute error.
         This option measures only the single least accurate cross validation
         prediction (positive or negative). This is useful when you are most
         concerned about worst-case scenarios rather than the accuracy in
         typical conditions.

         * STANDARD_ERROR-Results will be ranked by root mean square
         standardized error closest to one. This option measures how closely
         the variability of the cross validation predictions match the
         estimated standard errors. This is useful if you intend to create
         confidence intervals or margins of error for the predictions.

         * PRECISION-Results will be ranked by lowest average standard error.
         When creating confidence intervals or margins of error for the
         predicted values, results with higher precision will have narrower
         intervals around the predictions. It does not measure whether the
         standard errors are estimated accurately, only that the standard
         errors are small. When using this option, it is recommended that you
         include minimum and maximum root mean square standardized error values
         as exclusion criteria to ensure that the standard errors are both
         accurate and precise.
     criteria_hierarchy {Value Table}:
         The hierarchy of criteria that will be used for hierarchical sorting
         with tolerances. Provide multiple criteria in priority order with the
         first being most important. The interpolation results are ranked by
         the first criterion, and any ties are broken by the second criterion.
         Ties in the second criterion are broken by the third criterion, and so
         on. Cross validation statistics are continuous values and generally do
         not have exact ties, so tolerances are used to induce ties in the
         criteria. For each row, specify a criterion in the first column, a
         tolerance type (percent or absolute) in the second column, and a
         tolerance value in the third column. If no tolerance value is
         provided, no tolerance will be used; this is most useful for the final
         row so that there will be no ties for the interpolation result with
         highest rank. For each row (level of the hierarchy), the
         following criteria
         are available:

         * ACCURACY-Results will be ranked by highest accuracy.

         * BIAS-Results will be ranked by lowest bias.

         * WORST_CASE-Results will be ranked by lowest worst-case error.

         * STANDARD_ERROR-Results will be ranked by highest standard error
         accuracy.

         * PRECISION-Results will be ranked by highest precision.
         For example, you can specify an ACCURACY value with a 5 percent
         tolerance in the first row and a BIAS value with no tolerance in the
         second row. These options will first rank the interpolation results by
         lowest root mean square error (highest prediction accuracy), and all
         interpolation results whose root mean square error values are within 5
         percent of the most accurate result will be considered ties by
         prediction accuracy. Among the tying results, the result with a mean
         error closest to zero (lowest bias) will receive the highest rank.
     weighted_criteria {Value Table}:
         The multiple criteria with weights that will be used to rank
         interpolation results. For each row, provide a criterion and a weight.
         The interpolation results will be ranked independently by each of the
         criteria, and a weighted average of the ranks will be used to
         determine the final ranks of the interpolation results.

         * ACCURACY-Results will be ranked by lowest root mean square error.

         * BIAS-Results will be ranked by mean error closest to zero.

         * WORST_CASE-Results will be ranked by lowest maximum absolute error.

         * STANDARD_ERROR-Results will be ranked by root mean square
         standardized error closest to one.

         * PRECISION-Results will be ranked by lowest average standard error.
     exclusion_criteria {Value Table}:
         The criteria and associated values that will be used to
         exclude interpolation results from the comparison. Excluded results
         will not receive ranks and will have the value No in the Included
         field of the output cross validation table.

         * MAX_RMSE-Results will be excluded if the root mean square error
         exceeds the specified value. The value cannot be negative. This option
         measures prediction accuracy.

         * MAX_WORST_CASE-Results will be excluded if the maximum absolute
         error exceeds the specified value. The value cannot be negative. This
         option measures the worst-case error.

         * MAX_STD_RMSE-Results will be excluded if the root mean square
         standard error exceeds the specified value. The value must be greater
         than or equal to 1. This option measures standard error accuracy.

         * MIN_STD_RMSE-Results will be excluded if the root mean square
         standardized error does not exceed the specified value. The value must
         be between 0 and 1. This option measures standard error accuracy.

         * MAX_MEAN_ERROR-Results will be excluded if the mean error exceeds
         the specified value. The value cannot be negative. This option
         measures bias.

         * MIN_MEAN_ERROR-Results will be excluded if the mean error does not
         exceed the specified value. The value cannot be positive. This option
         measures bias.

         * MAX_ASE-Results will be excluded if the average standard square
         error exceeds the specified value. The value cannot be negative. This
         option measures precision.

         * MIN_PERC_ERROR-Results will be excluded if the interpolation result
         is not sufficiently more accurate than a baseline nonspatial model
         that predicts the global average value at all locations in the map.
         This relative accuracy is measured by comparing the root mean square
         error value to the standard deviation of the values of the points
         being interpolated, and the root mean square error must be at least
         the specified percent less than the standard deviation to be included
         in the comparison. For example, a value of 10 means that the root mean
         square error must be at least 10 percent lower than the standard
         deviation to be included in the comparison and ranking. The value must
         be between 0 and 100. This option measures prediction accuracy.

    OUTPUTS:
     out_cv_table (Table):
         The output table containing cross validation statistics and ranks for
         each interpolation result. The final ranks of the interpolation
         results are stored in the RANK field.
     out_geostat_layer {Geostatistical Layer}:
         The output geostatistical layer of the interpolation result with
         highest rank. This interpolation result will have the value 1 in the
         RANK field of the output cross validation table. If there are ties for
         the interpolation result with highest rank or all results are excluded
         by exclusion criteria, the layer will not be created even if a value
         is provided. Warning messages will be returned by the tool if this
         occurs."""
    ...

@gptooldoc("GANeighborhoodSelection_ga", None)
def GANeighborhoodSelection(
    in_dataset=...,
    out_layer=...,
    point_coord=...,
    neighbors_max=...,
    neighbors_min=...,
    minor_semiaxis=...,
    major_semiaxis=...,
    angle=...,
    shape_type=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GANeighborhoodSelection_ga(in_dataset, out_layer, point_coord, neighbors_max, neighbors_min, minor_semiaxis, major_semiaxis, angle, {shape_type})

       Creates a layer of points based on a user-defined neighborhood.

    INPUTS:
     in_dataset (Feature Layer):
         Points used to create a neighborhood selection.
     point_coord (Point):
         The neighborhood center's x,y coordinate.
     neighbors_max (Long):
         The number of points to use in each sector. If a sector has the
         required number of points, all points in that sector are used.
     neighbors_min (Long):
         The minimum number of points to use in each sector. If the minimum
         number of required points are not available in any given sector, the
         nearest available point outside the sector will be selected.
     minor_semiaxis (Double):
         Size of the minor semiaxis of the search neighborhood.
     major_semiaxis (Double):
         Size of the major semiaxis of the search neighborhood.
     angle (Double):
         The angle of rotation of the neighborhood axis.
     shape_type {String}:
         The geometry of the neighborhood.

         * ONE_SECTOR-Single ellipse

         * FOUR_SECTORS-Ellipse divided into four sectors

         * FOUR_SECTORS_SHIFTED-Ellipse divided into four sectors and shifted
         45 degrees

         * EIGHT_SECTORS-Ellipse divided into eight sectors

    OUTPUTS:
     out_layer (Feature Layer):
         Layer to store the neighborhood selection."""
    ...

@gptooldoc("GASemivariogramSensitivity_ga", None)
def GASemivariogramSensitivity(
    in_ga_model_source=...,
    in_datasets=...,
    in_locations=...,
    nugget_span_percents=...,
    nugget_calc_times=...,
    partialsill_span_percents=...,
    partialsill_calc_times=...,
    range_span_percents=...,
    range_calc_times=...,
    minrange_span_percents=...,
    minrange_calc_times=...,
    out_table=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GASemivariogramSensitivity_ga(in_ga_model_source, in_datasets;in_datasets..., in_locations, {nugget_span_percents}, {nugget_calc_times}, {partialsill_span_percents}, {partialsill_calc_times}, {range_span_percents}, {range_calc_times}, {minrange_span_percents}, {minrange_calc_times}, out_table)

       This tool performs a sensitivity analysis on the predicted values and
       associated standard errors by changing the model's semivariogram
       parameters (the nugget, partial sill, and major/minor ranges) within a
       percentage of the original values.

    INPUTS:
     in_ga_model_source (Geostatistical Layer / File):
         The geostatistical model source to be analyzed.
     in_datasets (Geostatistical Value Table):
         A GeostatisticalDatasets object.Alternatively, it can be a semicolon-
         delimited string of elements.
         Each element is comprised of the following components:

         * The catalog path and name to a dataset or the name of a layer in the
         current table of contents, followed by a space.

         * A sequence of field names, each field name separated by a space. In
         the case of a raster, the cell values will be used.
     in_locations (Feature Layer):
         Point locations where the sensitivity analysis is performed.
     nugget_span_percents {Double}:
         The percentage subtracted and added to the Nugget parameter to create
         a range for a subsequent random Nugget parameter selection.
     nugget_calc_times {Long}:
         Number of random Nugget values randomly sampled from the Nugget span.
     partialsill_span_percents {Double}:
         Percentage subtracted from and added to the Partial Sill parameter to
         create a range for a random Partial Sill selection.
     partialsill_calc_times {Long}:
         Number of Partial Sill values randomly sampled from the Partial Sill
         span.
     range_span_percents {Double}:
         Percentage subtracted and added to the Major Range parameter to create
         a range for a random Major Range selection.
     range_calc_times {Long}:
         Number of Major Range values randomly sampled from the Major Range
         span.
     minrange_span_percents {Double}:
         Percentage subtracted and added to the Minor Range parameter to create
         a range for a random Minor Range selection.
     minrange_calc_times {Long}:
         Number of Minor Range values randomly sampled from the Minor Range
         span.If Anisotropy has been set in the input geostatistical model
         source, a
         value is required.

    OUTPUTS:
     out_table (Table):
         Table storing the sensitivity results."""
    ...

@gptooldoc("GenerateSubsetPolygons_ga", None)
def GenerateSubsetPolygons(
    in_point_features=...,
    out_feature_class=...,
    min_points_per_subset=...,
    max_points_per_subset=...,
    coincident_points=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateSubsetPolygons_ga(in_point_features, out_feature_class, {min_points_per_subset}, {max_points_per_subset}, {coincident_points})

       Generates nonoverlapping subset polygon features from a set of input
       points. The goal is to divide the points into compact, nonoverlapping
       subsets, and create polygon regions around each subset of points. The
       minimum and maximum number of points in each subset can be controlled.

    INPUTS:
     in_point_features (Feature Layer):
         The points that will be grouped into subsets.
     min_points_per_subset {Long}:
         The minimum number of points that can be grouped into a subset. All
         subset polygons will contain at least this many points.
     max_points_per_subset {Long}:
         The maximum number of points that can be grouped into a subset.Each
         subset will always contain fewer than two times the
         min_points_per_subset regardless of the maximum number provided. This
         is because if a subset contains at least twice the minimum number of
         points, it will always be subdivided into two or more new subsets.
     coincident_points {Boolean}:
         Specifies whether coincident points (points that are at the same
         location) are treated like a single point or as multiple individual
         points.If you intend to use the subset polygons as Subset polygon
         features in
         EBK Regression Prediction, you should maintain consistency between
         this parameter and your choice for the Coincident points environment
         in EBK Regression Prediction.If COINCIDENT_ALL is chosen, your
         Out_feature_class polygons may
         overlap.

         * COINCIDENT_SINGLE-Coincident points will be treated as a single
         point in the subsetting. This is the default.

         * COINCIDENT_ALL-Coincident points will be treated as multiple
         individual points in the subsetting.

    OUTPUTS:
     out_feature_class (Feature Class):
         The polygons defining the region of each subset. All points within a
         single polygon feature are considered part of the same subset. The
         polygon feature class will contain a field named PointCount that will
         store the number of points contained in each polygon subset."""
    ...

@gptooldoc("SubsetFeatures_ga", None)
def SubsetFeatures(
    in_features=...,
    out_training_feature_class=...,
    out_test_feature_class=...,
    size_of_training_dataset=...,
    subset_size_units=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """SubsetFeatures_ga(in_features, out_training_feature_class, {out_test_feature_class}, {size_of_training_dataset}, {subset_size_units})

       Divides the original dataset into two parts: one part to be used to
       model the spatial structure and produce a surface, the other to be
       used to compare and validate the output surface.

    INPUTS:
     in_features (Table View):
         Points, lines, polygon features, or table from which to create a
         subset.
     size_of_training_dataset {Double}:
         The size of the output training feature class, entered either as a
         percentage of the input features or as an absolute number of features.
     subset_size_units {Boolean}:
         Type of subset size.

         * PERCENTAGE_OF_INPUT-The percentage of the input features that will
         be in the training dataset.

         * ABSOLUTE_VALUE-The number of features that will be in the training
         dataset.

    OUTPUTS:
     out_training_feature_class (Feature Class / Table):
         The subset of training features to be created.
     out_test_feature_class {Feature Class / Table}:
         The subset of test features to be created."""
    ...

@gptooldoc("ArealInterpolationLayerToPolygons_ga", None)
def ArealInterpolationLayerToPolygons(
    in_areal_interpolation_layer=...,
    in_polygon_features=...,
    out_feature_class=...,
    append_all_fields=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ArealInterpolationLayerToPolygons_ga(in_areal_interpolation_layer, in_polygon_features, out_feature_class, {append_all_fields})

       Reaggregates the predictions of an Areal Interpolation layer to a new
       set of polygons.

    INPUTS:
     in_areal_interpolation_layer (Geostatistical Layer):
         Input geostatistical layer resulting from an Areal Interpolation
         model.
     in_polygon_features (Feature Layer):
         The polygons where predictions and standard errors will be aggregated.
     append_all_fields {Boolean}:
         Determines whether all fields will be copied from the input features
         to the output feature class.

         * ALL-All fields from the input features will be copied to the output
         feature class. This is the default.

         * FID_ONLY-Only the feature ID will be copied, and it will be named
         Source_ID on the output feature class.

    OUTPUTS:
     out_feature_class (Feature Class):
         The output feature class containing the aggregated predictions and
         standard errors for the new polygons."""
    ...

@gptooldoc("GACalculateZValue_ga", None)
def GACalculateZValue(
    in_geostat_layer=..., point_coord=...
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GACalculateZValue_ga(in_geostat_layer, point_coord)

       Uses the interpolation model in a geostatistical layer to predict a
       value at a single location.

    INPUTS:
     in_geostat_layer (Geostatistical Layer):
         The geostatistical layer to be analyzed.
     point_coord (Point):
         The x,y coordinate of the point for which the Z-value will be
         calculated."""
    ...

@gptooldoc("GACreateGeostatisticalLayer_ga", None)
def GACreateGeostatisticalLayer(
    in_ga_model_source=..., in_datasets=..., out_layer=...
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GACreateGeostatisticalLayer_ga(in_ga_model_source, in_datasets;in_datasets..., out_layer)

       Creates a new geostatistical layer. An existing geostatistical layer
       is required to populate the initial values for the new layer.

    INPUTS:
     in_ga_model_source (Geostatistical Layer / File):
         The geostatistical model source to be analyzed.
     in_datasets (Geostatistical Value Table):
         A GeostatisticalDatasets object.Alternatively, it can be a semicolon-
         delimited string of elements.
         Each element is comprised of the following components:

         * The catalog path and name to a dataset or the name of a layer in the
         current table of contents, followed by a space.

         * A sequence of field names, each field name separated by a space. In
         the case of a raster, the cell values will be used.

    OUTPUTS:
     out_layer (Geostatistical Layer):
         The geostatistical layer produced by the tool."""
    ...

@gptooldoc("GAGetModelParameter_ga", None)
def GAGetModelParameter(
    in_ga_model_source=..., model_param_xpath=...
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GAGetModelParameter_ga(in_ga_model_source, model_param_xpath)

       Gets model parameter value from an existing geostatistical model
       source.

    INPUTS:
     in_ga_model_source (Geostatistical Layer / File):
         The geostatistical model source to be analyzed.
     model_param_xpath (String):
         XML path to the required model parameter."""
    ...

@gptooldoc("GALayer3DToMultidimensionalRaster_ga", None)
def GALayer3DToMultidimensionalRaster(
    in_3d_geostat_layer=...,
    out_multidimensional_raster=...,
    cell_size=...,
    explicit_only=...,
    min_elev=...,
    max_elev=...,
    elev_interval=...,
    elev_values=...,
    elev_units=...,
    output_type=...,
    quantile_probability_value=...,
    additional_outputs=...,
    build_transpose=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GALayer3DToMultidimensionalRaster_ga(in_3d_geostat_layer, out_multidimensional_raster, {cell_size}, {explicit_only}, {min_elev}, {max_elev}, {elev_interval}, {elev_values;elev_values...}, {elev_units}, {output_type}, {quantile_probability_value}, {additional_outputs;additional_outputs...}, {build_transpose})

       Exports a 3D geostatistical layer created using the Empirical Bayesian
       Kriging 3D tool to a multidimensional Cloud Raster Format (*.crf file)
       raster dataset. Tools in the Multidimensional Analysis toolset of the
       Image Analyst toolbox are designed to work directly on
       multidimensional rasters and can identify the 3D nature of the data.

    INPUTS:
     in_3d_geostat_layer (Geostatistical Layer):
         The 3D geostatistical layer representing the model to be exported to a
         multivariate raster dataset.
     cell_size {Analysis Cell Size}:
         The cell size of the output multidimensional raster.
     explicit_only {Boolean}:
         Specifies whether elevations will be provided as an explicit list or
         an iterator will be used.

         * EXPLICIT_VALUES-Elevation values will be provided as a list.

         * NO_EXPLICIT_VALUES-Elevation values will be provided using an
         iterator. This is the default.
     min_elev {Double}:
         The minimum elevation that will be used to start the iteration.
     max_elev {Double}:
         The maximum elevation that will be used to stop the iteration.
     elev_interval {Double}:
         The increment that the elevation will increase with each iteration.
     elev_values {Double}:
         The elevation values to export.
     elev_units {String}:
         Specifies the measurement unit of the elevation values.

         * INCH-Elevations are in U.S. survey inches.

         * FOOT-Elevations are in U.S. survey feet.

         * YARD-Elevations are in U.S. survey yards.

         * MILE_US-Elevations are in U.S. survey miles.

         * NAUTICAL_MILE-Elevations are in U.S. survey nautical miles.

         * MILLIMETER-Elevations are in millimeters.

         * CENTIMETER-Elevations are in centimeters.

         * DECIMETER-Elevations are in decimeters.

         * METER-Elevations are in meters.

         * KILOMETER-Elevations are in kilometers.

         * INCH_INT-Elevations are in international inches.

         * FOOT_INT-Elevations are in international feet.

         * YARD_INT-Elevations are in international yards.

         * MILE_INT-Elevations are in statute miles.

         * NAUTICAL_MILE_INT-Elevations are in international nautical miles.
     output_type {String}:
         Specifies the primary output type of the output multidimensional
         raster. The Additional output types parameter can be used to specify
         additional variables in the output multidimensional raster.For more
         information, see What output surface types can the
         interpolation models generate?

         * PREDICTION-A multidimensional raster of predicted values. This is
         the default.

         * PREDICTION_STANDARD_ERROR-A multidimensional raster of standard
         errors of prediction.

         * PROBABILITY-A multidimensional raster predicting the probability
         that a threshold is exceeded.

         * QUANTILE-A multidimensional raster predicting the quantile of the
         predicted value.
     quantile_probability_value {Double}:
         If Output type is set to Quantile, use this parameter to enter the
         requested quantile. If Output type is set to Probability, use this
         parameter to enter the requested threshold value, and the probability
         that the threshold is exceeded will be calculated. Subtract this value
         from one to get the probability that the threshold is not exceeded.
     additional_outputs {Value Table}:
         Specifies the output type and quantile or probability value for each
         additional output type. If multiple output types are provided, the
         output raster will be a multivariate raster dataset with a different
         variable for each output type.For more information, see What output
         surface types can the
         interpolation models generate?
     build_transpose {Boolean}:
         Specifies whether multidimensional transposes will be built on the
         output multidimensional raster.

         * BUILD_TRANSPOSE-Multidimensional transposes will be built on the
         output multidimensional raster.

         * DO_NOT_BUILD_TRANSPOSE-Multidimensional transposes will not be built
         on the output multidimensional raster. This is the default.

    OUTPUTS:
     out_multidimensional_raster (Raster Dataset):
         The output raster dataset containing the results of exporting the
         geostatistical model. The output must be saved as a Cloud Raster
         Format file (*.crf)."""
    ...

@gptooldoc("GALayer3DToNetCDF_ga", None)
def GALayer3DToNetCDF(
    in_3d_geostat_layers=...,
    out_netcdf_file=...,
    export_locations=...,
    x_spacing=...,
    y_spacing=...,
    elevation_spacing=...,
    in_points_3d=...,
    output_variables=...,
    in_study_area=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GALayer3DToNetCDF_ga(in_3d_geostat_layers;in_3d_geostat_layers..., out_netcdf_file, {export_locations}, {x_spacing}, {y_spacing}, {elevation_spacing}, {in_points_3d}, {output_variables;output_variables...}, {in_study_area})

       Exports one or more 3D geostatistical layers created using the
       Empirical Bayesian Kriging 3D tool to netCDF format (*.nc file). The
       primary purpose of this tool is to prepare the 3D geostatistical
       layers for visualization as a voxel layer in a local scene.

    INPUTS:
     in_3d_geostat_layers (Geostatistical Layer):
         The 3D geostatistical layers that will be exported to the Output
         netCDF file. If more than one layer is provided, the output will be a
         multivariate netCDF file.
     export_locations {String}:
         Specifies the locations to export from the Input 3D geostatistical
         layers. You can export to 3D gridded points or provide custom 3D point
         features to represent the export locations. If you choose 3D gridded
         points, you must provide values for the X spacing, Y spacing, and
         Elevation spacing parameters that represent the distance between each
         gridded point in all dimensions. If you choose Custom 3D points, you
         must provide 3D point features in the 3D point locations parameter
         representing the locations to export.

         * 3D_GRIDDED_POINTS-Prediction locations are 3D gridded points. This
         is the default.

         * CUSTOM_3D_POINTS-Prediction locations are defined by custom 3D point
         features.
     x_spacing {Linear Unit}:
         The spacing between each gridded point in the x-dimension. The default
         value creates 40 points along the output x-extent.
     y_spacing {Linear Unit}:
         The spacing between each gridded point in the y-dimension. The default
         value creates 40 points along the output y-extent.
     elevation_spacing {Linear Unit}:
         The spacing between each gridded point in the elevation (z) dimension.
         The default value creates 40 points along the output z-extent.
     in_points_3d {Feature Layer}:
         The 3D point features representing locations to export. The point
         features must have their elevations stored in the Shape.Z geometry
         attribute.
     output_variables {Value Table}:
         Specifies the output types for the Input 3D geostatistical layers. You
         can specify one or more output types for each of the layers or you can
         apply an output type to all input geostatistical layers. By default,
         the predictions for all layers will be exported.To export other output
         types, specify the layer to export (or choose
         All to specify all layers) in the first entry of the value table.
         Specify the output type in the second entry of the value table. If you
         choose Probability or Quantile as the output type, specify the
         threshold value (for probability) or the quantile value (for quantile)
         in the third entry of the value table. If you choose Prediction or
         Prediction standard error as the output type, you can leave the third
         entry in the value table empty.
     in_study_area {Feature Layer}:
         The polygon features that represent the study area. Only points that
         are within the study area are saved in the output netCDF file. When
         visualized as a voxel layer, only voxels within the study area will
         display in the scene. Points are determined to be inside or outside of
         the study area using only their x- and y-coordinates.

    OUTPUTS:
     out_netcdf_file (File):
         The output netCDF file containing the exported values from the Input
         3D geostatistical layers."""
    ...

@gptooldoc("GALayerToContour_ga", None)
def GALayerToContour(
    in_geostat_layer=...,
    contour_type=...,
    out_feature_class=...,
    contour_quality=...,
    classification_type=...,
    classes_count=...,
    classes_breaks=...,
    out_elevation=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GALayerToContour_ga(in_geostat_layer, contour_type, out_feature_class, {contour_quality}, {classification_type}, {classes_count}, {classes_breaks;classes_breaks...}, {out_elevation})

       Creates a feature class of contours from a geostatistical layer. The
       output feature class can be either a line feature class of contour
       lines or a polygon feature class of filled contours.

    INPUTS:
     in_geostat_layer (Geostatistical Layer):
         The geostatistical layer to be analyzed.
     contour_type (String):
         Type of contour to represent the geostatistical layer.

         * CONTOUR-The contour or isoline representation of the geostatistical
         layer. Displays the lines in either draft or presentation quality.

         * FILLED_CONTOUR-The polygon representation of the geostatistical
         layer. It assumes for the graphical display that the values between
         contour lines are the same for all locations within the polygon.
         Displays the lines in either draft or presentation quality.

         * SAME_AS_LAYER-Use the current renderer of the input geostatistical
         layer.
     contour_quality {String}:
         Determines the smoothness of contour line representation.

         * DRAFT-The default Draft quality presents a generalized version of
         isolines for faster display.

         * PRESENTATION-The Presentation option ensures more detailed isolines
         for the output feature class.
     classification_type {String}:
         Specifies how the contour breaks will be calculated.

         * GEOMETRIC_INTERVAL-Contour breaks are calculated based on geometric
         intervals.

         * EQUAL_INTERVAL-Contour breaks are calculated based on equal
         intervals.

         * QUANTILE-Contour breaks are calculated from quantiles of the input
         data.

         * MANUAL-Specify your own break values.
     classes_count {Long}:
         Specify the number of classes in the output feature class.If
         contour_type is set to output filled contour polygons, the number
         of polygons created will equal the value specified in this parameter.
         If it is set to output contour polylines, the number of polylines will
         be one less than the value specified in this parameter (because N
         class intervals define N-1 contour break values).This parameter does
         not apply if the classification_type is set to
         Manual.
     classes_breaks {Double}:
         The list of break values if the classification_type is set to Manual.
         The values should be passed as a list, and the values can be in any
         order.

         * For contour output, these are the values of the contour lines.

         * For filled contour, these are the upper limits of each class
         interval. Note that if the largest break value is less than the
         maximum of the geostatistical layer, the output feature class will not
         fill up the entire rectangular extent; all locations with predicted
         values above the largest break will not receive filled contours.
     out_elevation {Linear Unit}:
         For 3D interpolation models, you can export contours at any elevation.
         Use this parameter to specify the elevation that you want to export.
         If left empty, the elevation will be inherited from the input layer.
         The units will default to the same units of the input layer.

    OUTPUTS:
     out_feature_class (Feature Class):
         The output feature class will either be a polyline or a polygon,
         depending on the selected contour type."""
    ...

@gptooldoc("GALayerToGrid_ga", None)
def GALayerToGrid(
    in_geostat_layer=...,
    out_surface_grid=...,
    cell_size=...,
    points_per_block_horz=...,
    points_per_block_vert=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GALayerToGrid_ga(in_geostat_layer, out_surface_grid, {cell_size}, {points_per_block_horz}, {points_per_block_vert})

       Exports a Geostatistical layer to a raster.

    INPUTS:
     in_geostat_layer (Geostatistical Layer):
         The geostatistical layer to be analyzed.
     cell_size {Analysis Cell Size}:
         The cell size at which the output raster will be created.This value
         can be explicitly set in the Environments by the Cell Size
         parameter.If not set, it is the shorter of the width or the height of
         the extent
         of the input point features, in the input spatial reference, divided
         by 250.
     points_per_block_horz {Long}:
         The number of predictions for each cell in the horizontal direction
         for block interpolation. The default is 1.
     points_per_block_vert {Long}:
         The number of predictions for each cell in the vertical direction for
         block interpolation. The default is 1.

    OUTPUTS:
     out_surface_grid (Raster Dataset):
         The raster to be created."""
    ...

@gptooldoc("GALayerToPoints_ga", None)
def GALayerToPoints(
    in_geostat_layer=...,
    in_locations=...,
    z_field=...,
    out_feature_class=...,
    append_all_fields=...,
    elevation_field=...,
    elevation_units=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GALayerToPoints_ga(in_geostat_layer, in_locations, {z_field}, out_feature_class, {append_all_fields}, {elevation_field}, {elevation_units})

       Exports a geostatistical layer to points. The tool can also be used to
       predict values at unmeasured locations or to validate predictions made
       at measured locations.

    INPUTS:
     in_geostat_layer (Geostatistical Layer):
         The geostatistical layer to be analyzed.
     in_locations (Feature Layer):
         Point locations where predictions or validations will be performed.
     z_field {Field}:
         If this field is left blank, predictions are made at the location
         points. If a field is selected, predictions are made at the location
         points, compared to their Z_value_field values, and a validation
         analysis is performed.
     append_all_fields {Boolean}:
         Determines whether all fields will be copied from the input features
         to the output feature class.

         * ALL-All fields from the input features will be copied to the output
         feature class. This is the default.

         * FID_ONLY-Only the feature ID will be copied, and it will be named
         Source_ID on the output feature class.
     elevation_field {Field}:
         The field containing the elevation of each input point. The parameter
         only applies to 3D geostatistical models. If the elevation values are
         stored as geometry attributes in Shape.Z, it is recommended to use
         that field. If the elevations are stored in an attribute field, the
         elevations must indicate distance from sea level. Positive values
         indicate distance above sea level, and negative values indicate
         distance below sea level.
     elevation_units {String}:
         The units of the elevation field. This parameter only applies to 3D
         geostatistical models. If Shape.Z is provided as the elevation field,
         the units will automatically match the Z-units of the vertical
         coordinate system.

         * INCH-Elevations are in U.S. survey inches.

         * FOOT-Elevations are in U.S. survey feet.

         * YARD-Elevations are in U.S. survey yards.

         * MILE_US-Elevations are in U.S. survey miles.

         * NAUTICAL_MILE-Elevations are in U.S. survey nautical miles.

         * MILLIMETER-Elevations are in millimeters.

         * CENTIMETER-Elevations are in centimeters.

         * DECIMETER-Elevations are in decimeters.

         * METER-Elevations are in meters.

         * KILOMETER-Elevations are in kilometers.

         * INCH_INT-Elevations are in international inches.

         * FOOT_INT-Elevations are in international feet.

         * YARD_INT-Elevations are in international yards.

         * MILE_INT-Elevations are in statute miles.

         * NAUTICAL_MILE_INT-Elevations are in international nautical miles.

    OUTPUTS:
     out_feature_class (Feature Class):
         The output feature class containing either the predictions or the
         predictions and the validation results.The fields in this feature
         class can include the following fields
         (where applicable):

         * Source_ID (Source ID)-The object ID of the source feature
         in the Input point observation locations.

         * The feature or object identifier of the input dataset that was used.

         * Included (Included)-Indicates whether a prediction was
         calculated for this feature. The values in this field can be one of
         the following:

         * Yes-There are no problems making a prediction at this point.

         * Not enough neighbors-There are not enough neighbors to make a
         prediction.

         * Weight parameter is too small-The weight parameter is too small.

         * Overfilling-Overflow of floating-point calculations.

         * Problem with data transformation-The value to be transformed is
         outside of the supported range for the selected transformation (only
         in kriging).

         * No explanatory rasters-The value cannot be calculated because one of
         the explanatory variables is not defined. The point could be outside
         the extent of at least one explanatory variable raster, or the point
         could be on top of a NoData cell in at least one of the explanatory
         variable rasters. This only applies to EBK Regression Prediction
         models.

         * Predicted (Predicted)-The prediction value at this location.

         * Error (Error)-The predicted value minus the value in the validation
         field.

         * StdError (Standard Error)-The kriging standard error.

         * Stdd_Error (Standardized Error)-The standardized prediction errors.
         Ideally, the standardized prediction errors are distributed normally.

         * NormValue (Normal Value)-The normal distribution value (x-axis) that
         corresponds to the standardized prediction errors (y-axis) in the
         normal QQplot.

         * CRPS (Continuous Ranked Probability Score)-The continuous ranked
         probability score is a diagnostic that measures the deviation from the
         predictive cumulative distribution function to each observed data
         value. This value should be as small as possible. This diagnostic has
         advantages over cross-validation diagnostics because it compares the
         data to a full distribution rather than to single-point predictions.
         This field is only created for Empirical Bayesian Kriging and EBK
         Regression Prediction models.

         * Interval90 (Inside 90 Percent Interval)-Indicates whether
         or not the validation point is inside of a 90 percent confidence
         interval. This field is only created for Empirical Bayesian Kriging
         and EBK Regression Prediction models. If the model fits the data,
         approximately 90 percent of the features should be contained in a 90
         percent confidence interval. This field can contain the following
         values:

         * Yes-The validation point is inside the 90 percent confidence
         interval.

         * No-The validation point is not inside the 90 percent confidence
         interval.

         * Excluded-A prediction cannot be made at this location.

         * Interval95 (Inside 95 Percent Interval)-Indicates whether
         or not the validation point is inside of a 95 percent confidence
         interval. This field is only created for Empirical Bayesian Kriging
         and EBK Regression Prediction models. If the model fits the data,
         approximately 95 percent of the features should be contained in a 95
         percent confidence interval. This field can contain the following
         values:

         * Yes-The validation point is inside the 95 percent confidence
         interval.

         * No-The validation point is not inside the 95 percent confidence
         interval.

         * Excluded-A prediction cannot be made at this location.

         * QuanVal (Validation Quantile)-The quantile of the measured value at
         the feature with respect to the prediction distribution. This value
         can range from 0 to 1, and values close to 0 indicate that the
         measured value is on the far left tail of the distribution, and values
         close to 1 indicate that the measured value is on the right tail of
         the distribution. If many values are close to either extreme, this
         could indicate that the prediction distributions do not model the data
         well, and some of the interpolation parameters need to be altered.
         This field is only created for Empirical Bayesian Kriging and EBK
         Regression Prediction models."""
    ...

@gptooldoc("GALayerToRasters_ga", None)
def GALayerToRasters(
    in_geostat_layer=...,
    out_raster=...,
    output_type=...,
    quantile_probability_value=...,
    cell_size=...,
    points_per_block_horz=...,
    points_per_block_vert=...,
    additional_rasters=...,
    out_elevation=...,
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GALayerToRasters_ga(in_geostat_layer, out_raster, {output_type}, {quantile_probability_value}, {cell_size}, {points_per_block_horz}, {points_per_block_vert}, {additional_rasters;additional_rasters...}, {out_elevation})

       Exports a geostatistical layer to one or multiple rasters.

    INPUTS:
     in_geostat_layer (Geostatistical Layer):
         The geostatistical layer to be analyzed.
     output_type {String}:
         The surface type of the output raster.For more information, see What
         output surface types can the
         interpolation models generate?

         * PREDICTION-A raster of predicted values.

         * PREDICTION_STANDARD_ERROR-A raster of standard errors of prediction.

         * PROBABILITY-A raster predicting the probability that a threshold is
         exceeded.

         * QUANTILE-A raster predicting the quantile of the predicted value.

         * STANDARD_ERROR_INDICATORS-A raster of standard errors of indicators.

         * CONDITION_NUMBER-A raster showing the condition number for
         predictions in Local Polynomial Interpolation. The condition number
         surface indicates the stability of calculations at a particular
         location. The larger the condition number, the more unstable the
         prediction, so locations with large condition numbers may be prone to
         artifacts and erratic predicted values.
     quantile_probability_value {Double}:
         If the Output surface type is set to Quantile, use this parameter to
         enter the requested quantile. If the Output surface type is set to
         Probability, use this parameter to enter the requested threshold
         value, then the probability that the threshold is exceeded will be
         calculated.If the Input geostatistical layer is a probability or
         standard errors
         of indicators map that was created with the Not exceed option, then
         the probability that this threshold is not exceeded will be
         calculated. This will apply to all probability raster outputs from
         this tool.
     cell_size {Analysis Cell Size}:
         The cell size of the output rasters. This value will be shared by the
         Output raster and the Additional output rasters parameters.
     points_per_block_horz {Long}:
         The number of predictions for each cell in the horizontal direction
         for block interpolation. The default is 1.
     points_per_block_vert {Long}:
         The number of predictions for each cell in the vertical direction for
         block interpolation. The default is 1.
     additional_rasters {Value Table}:
         Provide the name, output type, and quantile or probability value for
         each additional output raster. See the descriptions of parameters
         above for more information. These additional rasters will be saved in
         the same location as the Output raster.
     out_elevation {Linear Unit}:
         For 3D interpolation models, you can export rasters at any elevation.
         Use this parameter to specify the elevation you want to export. If
         left empty, the elevation will be inherited from the input layer. The
         units will default to the same units of the input layer.

    OUTPUTS:
     out_raster (Raster Dataset):
         The primary output raster to be created. Additional rasters can be
         created with the Additional output rasters parameter."""
    ...

@gptooldoc("GASetModelParameter_ga", None)
def GASetModelParameter(
    in_ga_model_source=..., model_param_xpath=..., in_param_value=..., out_ga_model=...
):  # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GASetModelParameter_ga(in_ga_model_source, model_param_xpath, in_param_value, out_ga_model)

       Sets parameter values in an existing geostatistical model source.

    INPUTS:
     in_ga_model_source (Geostatistical Layer / File):
         The geostatistical model source to be analyzed.
     model_param_xpath (String):
         XML path to the required model parameter.
     in_param_value (String):
         Value for the parameter defined by the XML path.

    OUTPUTS:
     out_ga_model (File):
         Geostatistical model created with the parameter value defined in the
         XML path."""
    ...
