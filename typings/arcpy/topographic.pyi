"""
This type stub file was generated by pyright.
"""

from arcpy.geoprocessing._base import gptooldoc

r"""Topographic Production toolbox contains tools that are used in
topographic production."""
__all__ = ['ApplyBuildingOffsets', 'ApplyFeatureLevelMetadata', 'ApplyMasksFromRules', 'ApplyVisualSpecificationToMap', 'CalculateBridgeOffsets', 'CalculateDefaultValues', 'CalculateMEF', 'CalculateMagneticComponents', 'CalculateMetrics', 'CancelRemainingTasks', 'CopyExtendedProperties', 'CopyJobFiles', 'CreateCrossReferenceGeodatabase', 'CreateJobForTask', 'CreateTaskGroupJobs', 'EliminatePolygon', 'ExportGeneralizedData', 'ExportMetadata', 'ExportTopology', 'ExtractDataByFeature', 'FillGaps', 'GAIT', 'GenerateAdjoiningSheetsFeatures', 'GenerateElevationBands', 'GenerateElevationBandsFromFeatures', 'GenerateElevationGuideFeatures', 'GenerateExcelFromGeodatabase', 'GenerateGeodatabaseFromExcel', 'GenerateLocationDiagramFeatures', 'GenerateProductLayout', 'GenerateSpotHeights', 'GenerateTopographicContours', 'GeoNamesToGeodatabase', 'GeodatabaseToShape', 'GetFeaturesByJobAOI', 'IdentifyContours', 'IdentifyNarrowPolygons', 'ImportGeneralizationData', 'ImportMetadata', 'ImportTopology', 'InsertTaskGroup', 'LoadData', 'MakeGridsAndGraticulesLayer', 'MakeMasksFromRules', 'MergeLinesByPseudoNode', 'PolygonToCenterline', 'PopulateMapSheetInfo', 'RemoveCutbackVertices', 'RemoveSmallLines', 'RepairSelfIntersection', 'SetDataWorkspace', 'SetNextTask', 'SetProductionProperties', 'SetTaskGroupDependencies', 'SetTaskList', 'SetTaskStatus', 'SplitFeatures', 'ThinHydrologyLines', 'ThinSpotHeights', 'UnzipCellAndImport', 'UpdateExtendedProperty', 'UpdateGeoNames', 'UpdatePropertyCount', 'UpdateTaskGroupMetrics', 'ValidateSpotHeights']
__alias__ = ...
@gptooldoc('GenerateElevationBands_topographic', None)
def GenerateElevationBands(in_raster=..., in_aoi=..., out_feature_class=..., contour_interval=..., min_area=..., smooth_tolerance=..., in_hydro_features=..., number_of_bands=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateElevationBands_topographic(in_raster;in_raster..., in_aoi, out_feature_class, contour_interval, min_area, smooth_tolerance, {in_hydro_features}, {number_of_bands})

        Creates an elevation bands feature class from a Digital Elevation
        Model (DEM).

     INPUTS:
      in_raster (Raster Layer / Mosaic Layer):
          The rasters used to create elevation bands.
      in_aoi (Layer):
          The layer that defines the processing extent.
      contour_interval (Long):
          Determines the closest available contour when calculating the
          elevation band area. The default is 20.

          * 10-A contour interval of 10.

          * 20-A contour interval of 20.

          * 40-A contour interval of 40.

          * 80-A contour interval of 80.
      min_area (Double):
          The minimum area for output polygons. Features smaller than
          this value will be removed. The default is 0.00016 square decimal
          degrees. If you're creating an output dataset with a projected
          coordinate
          system, this value should reflect the square units of that coordinate
          system-for example, square meters for a UTM dataset. Otherwise, the
          default value may result in an empty output dataset.
      smooth_tolerance (Linear Unit):
          The tolerance used by the smoothing algorithm. The larger the value,
          the more generalized the output band features. The default is 0.002
          decimal degrees.
      in_hydro_features {Feature Layer}:
          The bodies of water to exclude when calculating the elevation band
          area.
      number_of_bands {Long}:
          The number of elevation bands generated by the tool.

          * 1-One elevation band will be generated.

          * 2-Two elevation bands will be generated.

          * 3-Three elevation bands will be generated.

          * 4-Four elevation bands will be generated.

     OUTPUTS:
      out_feature_class (Feature Class):
          The feature class containing the output elevation band features."""
    ...

@gptooldoc('GenerateElevationBandsFromFeatures_topographic', None)
def GenerateElevationBandsFromFeatures(contour_features=..., elevation_field=..., area_of_interest=..., out_feature_class=..., exclusion_features=..., product=..., band_interval=..., band_values=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateElevationBandsFromFeatures_topographic(contour_features, elevation_field, area_of_interest, out_feature_class, {exclusion_features;exclusion_features...}, {product}, {band_interval}, {band_values;band_values...})

        Generates band features that represent elevation levels on a map
        product. The tool can be run with set values from standardized product
        specifications or with custom-defined values.

     INPUTS:
      contour_features (Feature Layer):
          The polyline feature layer that contains the contours. The information
          for the output bands will be derived from these features.
      elevation_field (Field):
          The field in the contour_features feature layer from which the
          elevation values will be derived.
      area_of_interest (Layer):
          The AOI for the area where the elevation bands will be created. The
          AOI is typically stored in an index feature class that contains the
          extents for standard map sheets. A single feature must be selected on
          the feature class that is specified.
      exclusion_features {Feature Layer}:
          The feature layers that define areas where bands will not be created.
      product {String}:
          A supported map product, which determines the values for the
          band_values parameter unless Custom is specified for this parameter.
          If left blank, at least one pair of Low and High parameter values is
          required.

          * JOG-A-The Joint Operations Graphic-Air product

          * ONC-The Operational Navigation Chart product

          * TPC-The Tactical Pilotage Chart product

          * Custom-A custom product
      band_interval {Long}:
          The interval specified when the band interval type is regular. This
          parameter is only available when Custom is specified as the product
          parameter value.
      band_values {Value Table}:
          The low and high values in the bands that will be created. These
          values will be populated automatically from an .xml file if a
          particular product is specified for the product parameter value;
          however, these values must be provided manually if Custom is specified
          for the product parameter value and at least one pair of Low and High
          values is required. If no product is specified, at least one pair of
          Low and High values is still required.

     OUTPUTS:
      out_feature_class (Feature Class):
          The feature class that will contain the banding features."""
    ...

@gptooldoc('ApplyBuildingOffsets_topographic', None)
def ApplyBuildingOffsets(in_map=..., rule_file=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ApplyBuildingOffsets_topographic(in_map, rule_file)

        Aligns, moves, and hides building or bridge marker symbols based on
        product specification rules defined in an .xml file.

     INPUTS:
      in_map (Map):
          The input map that contains the layers with proper symbology. This can
          be a map in the application or an .mapx file on disk.
      rule_file (File):
          An .xml file containing the offset rules that define how features will
          be aligned and refined in case of any conflict."""
    ...

@gptooldoc('ApplyMasksFromRules_topographic', None)
def ApplyMasksFromRules(in_map=..., rule_file=..., in_feature_dataset=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ApplyMasksFromRules_topographic(in_map, rule_file, in_feature_dataset)

        Applies symbol layer masking to feature layers in a map based on an
        XML rule file and mask features created by the Make Mask From Rules
        tool.

     INPUTS:
      in_map (Map):
          The input map containing symbolized features such as a map in a
          project or a MAPX file on disk.
      rule_file (File):
          The XML file containing rules to define how features should be masked
          based on colors and symbol parts.
      in_feature_dataset (Feature Dataset):
          The feature dataset containing the masking polygon feature classes
          created by the Make Mask From Rules tool."""
    ...

@gptooldoc('ApplyVisualSpecificationToMap_topographic', None)
def ApplyVisualSpecificationToMap(in_map=..., vs_workspace=..., specification=..., in_style_file=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ApplyVisualSpecificationToMap_topographic(in_map, vs_workspace, specification, {in_style_file})

        Applies symbols and Arcade expressions to layers in a map based on the
        symbols and rules defined in a visual specification database.

     INPUTS:
      in_map (Map):
          The map containing layers to which symbols and Arcade expressions will
          be applied.
      vs_workspace (Workspace):
          The database containing the visual specification rules.
      specification (String):
          The specification rules that will be converted to Arcade and applied
          to the map layers.
      in_style_file {String}:
          The style file (.stylx) that contains the symbols defined in the
          visual specification rules."""
    ...

@gptooldoc('CalculateBridgeOffsets_topographic', None)
def CalculateBridgeOffsets(in_bridge_features=..., in_overpassing_features=..., reference_scale=..., search_distance=..., expand=..., offset=..., min_length=..., bridge_subtype=..., overpassing_subtype=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CalculateBridgeOffsets_topographic(in_bridge_features, in_overpassing_features, reference_scale, {search_distance}, {expand}, {offset}, {min_length}, {bridge_subtype}, {overpassing_subtype})

        Calculates the offsets necessary to properly display bridges at a
        given location.

     INPUTS:
      in_bridge_features (Layer):
          The feature layer that contains bridge features for which symbol
          offsets will be updated. Symbolize the bridge features layer with
          proper bridge features and enable attribute-driven symbology on it.
      in_overpassing_features (Layer):
          The feature layer that contains the features overpassing the bridges.
      reference_scale (Long):
          The scale at which symbols appear at their intended size.
      search_distance {Linear Unit}:
          The distance, calculated in map units, by which this tool will buffer
          point bridge features when identifying the overpassing features. This
          parameter is only available for point bridges. The default is 0
          meters.
      expand {Boolean}:
          Specifies whether marker layers on overpassing symbols will be
          included when analyzing widths.

          * EXPAND-Marker layers on overpassing symbols will be included when
          analyzing widths.

          * NO_EXPAND-Marker layers on overpassing symbols will not be included.
          This is the default.
      offset {Linear Unit}:
          An offset added to the bridge width. The default is 0 points.
      min_length {Linear Unit}:
          The minimum length of a line bridge. The default is 1.35
          millimeters.If the length of the bridge is less than the minimum
          length, it will
          be expanded to minimum length.
      bridge_subtype {String}:
          The subtype of the feature class from the in_bridge_features parameter
          that will be modified by this operation.
      overpassing_subtype {String}:
          The subtype of the feature class in the in_overpassing_features
          parameter that will be used in this operation."""
    ...

@gptooldoc('MakeMasksFromRules_topographic', None)
def MakeMasksFromRules(in_map=..., rule_file=..., out_feature_dataset=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """MakeMasksFromRules_topographic(in_map, rule_file, out_feature_dataset)

        Creates polygon masks for features based on color rules.

     INPUTS:
      in_map (Map):
          The input map containing symbolized features.
      rule_file (File):
          The .xml file containing rules that define how features should be
          masked based on colors and symbol parts.

     OUTPUTS:
      out_feature_dataset (Feature Dataset):
          The output feature dataset. The tool will create a feature dataset
          containing polygon feature classes that will be used for masking. The
          spatial reference for the feature dataset will be taken from the map
          for which masks are generated."""
    ...

@gptooldoc('ThinSpotHeights_topographic', None)
def ThinSpotHeights(in_features=..., area_of_interest=..., elevation_field=..., invisibility_field=..., high_low_spots=..., search_distance=..., max_spots=..., input_contours=..., contour_code_field=..., depression_code_value=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ThinSpotHeights_topographic(in_features, area_of_interest, elevation_field, invisibility_field, {high_low_spots}, {search_distance}, {max_spots}, {input_contours}, {contour_code_field}, {depression_code_value;depression_code_value...})

        Generalizes spot heights for a given area of interest in accordance
        with product specifications.

     INPUTS:
      in_features (Feature Layer):
          A point feature layer or feature class representing the spot heights
          for a given area of interest.
      area_of_interest (Layer):
          The selected feature in the area of interest (AOI) that is used to
          identify input features to process. There should be one and only one
          selected AOI.
      elevation_field (Field):
          The elevation field in Input Features to use for the spot height.
      invisibility_field (Field):
          The field where the visibility attribute will be written.
      high_low_spots {Field}:
          The field that will be used to identify the highest and lowest spots.
      search_distance {Linear Unit}:
          The minimum distance between spot heights. For example, if the search
          distance is 3,000 meters, there will be at least 3,000 meters between
          a chosen spot height and the next chosen spot height. The default
          value will be 1,300 meters, as this is the optimal value for 50K
          sheets.
      max_spots {Long}:
          The number of spot heights will not exceed this number.
      input_contours {Feature Layer}:
          Input contours used to identify if point features are in depressions
          or tops.
      contour_code_field {Field}:
          The field in the database that contains the domain value for index
          contour, intermediate contour, depression contour, and depression
          intermediate contour. It is a string value of the field, such as HQC.
      depression_code_value {Long}:
          Used to identify depression code values. A depression refers to an
          elevation completely surrounded by higher-elevation contour lines."""
    ...

@gptooldoc('CalculateMEF_topographic', None)
def CalculateMEF(target_mef_features=..., in_terrain=..., obstruction_features=..., mef_field=..., max_vo_field=..., max_terrain_field=..., specification=..., terrain_elev_field=..., vo_allowance=..., vo_accuracy=..., terrain_accuracy=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CalculateMEF_topographic(target_mef_features, in_terrain;in_terrain..., obstruction_features;obstruction_features..., mef_field, max_vo_field, max_terrain_field, specification, {terrain_elev_field}, {vo_allowance}, {vo_accuracy}, {terrain_accuracy})

        Calculates the maximum elevation figures (MEF) for each polygon cell
        or quadrangle in a polygon layer. These values are used as labels for
        the MEF feature layer.

     INPUTS:
      target_mef_features (Feature Layer):
          The input polygon features representing the quadrangle or cell that
          will be updated with MEF values.
      in_terrain (Raster Layer / Mosaic Layer / Layer):
          The input terrain that will be used to determine elevation values in
          an MEF feature cell. If a point feature layer is used, elevation
          values are obtained from the field defined in the terrain_elev_field
          parameter.
      obstruction_features (Value Table):
          The layers that will be used to identify the highest human-made
          structure in a cell. This is a value table defining features,
          elevation fields, and elevation units.
      mef_field (Field):
          The existing field in the target_mef_features layer where the maximum
          elevation figure value will be stored.
      max_vo_field (Field):
          The field in the target_mef_features layer where the maximum vertical
          obstruction value will be stored.
      max_terrain_field (Field):
          The field in the target_mef_features layer where the maximum elevation
          values from the terrain layer will be stored.
      specification (String):
          Specifies the specification that will be used to calculate maximum
          elevation figures.

          * JOG_MIL_J_89100-The Joint Operations Graphic specification will be
          used.

          * ONC_MIL_O_89102-The Operational Navigation Chart specification will
          be used.

          * TPC_MIL_T_89101-The Tactical Pilotage Chart will be used.

          * STANAG_3591_ED6-The NATO Standard Agreement will be used.
      terrain_elev_field {Field}:
          A field in the in_terrain value that represents the elevation values
          for each feature. If a point feature layer is used for the in_terrain
          parameter value, this parameter is required. This parameter is
          unavailable if a raster or mosaic layer is used as input for the
          in_terrain parameter.
      vo_allowance {Linear Unit}:
          A vertical allowance value that will be added to each calculated MEF
          value. The value accounts for nonrepresented natural or manufactured
          features. The default is 150 feet.
      vo_accuracy {Linear Unit}:
          The accuracy of the vertical obstruction feature layer within a
          specified number of units. The default is 20 meters.
      terrain_accuracy {Linear Unit}:
          The accuracy of the terrain layer within a specified number of units.
          The default is 20 meters."""
    ...

@gptooldoc('CalculateMagneticComponents_topographic', None)
def CalculateMagneticComponents(in_features=..., altitude=..., date=..., magnetic_component=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CalculateMagneticComponents_topographic(in_features, altitude, date, magnetic_component;magnetic_component...)

        Calculates the magnetic field at point locations for given date and
        altitude.

     INPUTS:
      in_features (Feature Layer):
          The point features for which magnetic field values will be calculated.
      altitude (Linear Unit):
          The elevation of the in_features value including the linear unit. Do
          not use decimal degrees or unknown units. The default is 0 meters.
      date (Date):
          The date for which magnetic field values will be calculated. The date
          must be valid for the specified World Magnetic Model. The format must
          use two digits for the month, two digits for the day, and four digits
          for the year. The default is the system current date.
      magnetic_component (Value Table):
          The magnetic component that will be calculated and the field to which
          the values will be written.

          * Component-The magnetic component to calculate.

          * DECLINATION-The angle between magnetic north and true north. This
          value varies by location on the globe.

          * ANNUAL_DRIFT-The annual rate of change in magnetic declination. This
          value varies by location on the globe.

          * INCLINATION-The angle between a compass needle and the plane of the
          horizon. Inclination is also known as magnetic dip or the dip of the
          compass needle. This value varies by latitude.

          * HORIZONTAL-This value is calculated using north and east components.
          Horizontal is also known as Horizontal intensity, or H. This value
          varies by location on the globe.

          * EAST_COMPONENT-The easterly intensity of the geomagnetic field. East
          component is also known as Y. This value varies by location on the
          globe.

          * NORTH_COMPONENT-The northerly intensity of the geomagnetic field.
          North component is also known as X. This value varies by location on
          the globe.

          * VERTICAL_INTENSITY-The vertical intensity of the geomagnetic field.
          Vertical intensity is also known as Z. This value varies by location
          on the globe.

          * TOTAL_INTENSITY-This value is calculated using horizontal and
          vertical components. Total intensity is also known as F. This value
          varies by location on the globe.

          * GRID_VARIATION-The angle between magnetic north and grid north. You
          must use the Lambert conformal conic projected coordinate system in
          the map frame, in the geoprocessing environment, or in the input point
          data.

          * Field-The field to which calculated results will be written."""
    ...

@gptooldoc('GenerateAdjoiningSheetsFeatures_topographic', None)
def GenerateAdjoiningSheetsFeatures(in_feature_dataset=..., area_of_interest=..., land_features=..., scale=..., clip_aoi_to_sheets=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateAdjoiningSheetsFeatures_topographic(in_feature_dataset, area_of_interest, {land_features}, {scale}, {clip_aoi_to_sheets})

        Generates features necessary for display in a typical topographic map
        adjoining sheets diagram.

     INPUTS:
      in_feature_dataset (Feature Dataset):
          An existing feature dataset that will contain the ASG_ feature
          classes. The tool will create these feature classes if they do not
          exist.
      area_of_interest (Feature Layer):
          A feature layer with a single selected feature used to identify the
          center and surrounding AOIs. Adjoining sheets features will be created
          from the selected AOI and the intersecting AOIs as required.
      land_features {Feature Layer}:
          Land features used to generate adjoining sheets features in the
          ASG_COAST_A and ASG_COAST_L feature classes in the target feature
          dataset.
      scale {String}:
          Defines a factor by which the extent of the area_of_interest
          is expanded. The expanded extent is used to select adjoining areas of
          interest. Data from the adjoining areas of interest is included in the
          adjoining sheets diagram.

          * 1:25000-Uses specification MIL-T-89301A as a guide to determine how
          to expand the width and height of the extent of the area_of_interest.

          * 1:50000-Uses specification MIL-T-89301A to determine how to expand
          the width and height of the extent of the area_of_interest. This is
          the default.

          * 1:100000-Uses specification MIL-T-89306 to determine how to expand
          the width and height of the extent of the area_of_interest.
      clip_aoi_to_sheets {Boolean}:
          Determines if the AOI created for the extent of the adjoining sheets
          diagram will be clipped to the extents of the sheets to be displayed.
          If set to CLIP_AOI, the AOI for the adjoining sheets diagram will be
          modified from its originally calculated rectangular shape to include
          any irregular map sheet extents that will be included or excluded in
          the diagram.

          * CLIP_AOI-The AOI feature will be clipped by the sheets to be
          displayed in the adjoining sheet diagram and may have an irregular
          shape. This is the default.

          * DONT_CLIP_AOI-The AOI feature will not be clipped and will retain
          its originally calculated rectangular shape. This may result in
          partial sheets being displayed in the adjoining sheets diagram."""
    ...

@gptooldoc('GenerateElevationGuideFeatures_topographic', None)
def GenerateElevationGuideFeatures(in_feature_dataset=..., area_of_interest=..., in_rasters=..., hydro_exclusion_features=..., spot_height_features=..., hydro_line_features=..., hydro_area_features=..., contour_interval=..., bands_minarea=..., smooth_tolerance=..., number_of_bands=..., height_field=..., search_distance=..., hydroline_minlength=..., hydroline_minspacing=..., hydroarea_minlength=..., hydroarea_minwidth=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateElevationGuideFeatures_topographic(in_feature_dataset, area_of_interest, in_rasters;in_rasters..., {hydro_exclusion_features}, {spot_height_features}, {hydro_line_features;hydro_line_features...}, {hydro_area_features;hydro_area_features...}, {contour_interval}, {bands_minarea}, {smooth_tolerance}, {number_of_bands}, {height_field}, {search_distance}, {hydroline_minlength}, {hydroline_minspacing}, {hydroarea_minlength}, {hydroarea_minwidth})

        Creates data required for an elevation guide diagram surround element
        as required by various supported map product specifications. This tool
        uses existing banding and thinning parameters to generate output
        elevation band features, spot height features, and hydrology features.

     INPUTS:
      in_feature_dataset (Feature Dataset):
          An existing feature dataset that will contain the EGB feature classes.
          Data created for the elevation guide box is maintained in these
          feature classes in this feature dataset.
      area_of_interest (Layer):
          A feature layer with a single selected feature that defines a
          processing extent for banding operations and a clipping extent for
          spot heights, and input hydrology areas and lines.
      in_rasters (Raster Layer / Mosaic Layer):
          One or more rasters used to create elevation bands and supply
          elevation values to the created features.
      hydro_exclusion_features {Feature Layer}:
          A feature layer that defines a large water body area to exclude from
          the elevation band area computation.
      spot_height_features {Feature Layer}:
          A feature layer or class that contains spot heights.
      hydro_line_features {Feature Layer}:
          Hydrology line features used to generate the output of a thinned
          hydrology dataset. Only the output features are generalized through
          this thinning process.
      hydro_area_features {Feature Layer}:
          Hydrology area features used to generate the thinned hydrology
          dataset. Only the output features are generalized through this
          thinning process.
      contour_interval {Long}:
          Specifies the contour interval that will be used to determine the
          closest available contour when calculating the elevation band area.
          Elevation bands are created with their limits aligned to the specified
          contour interval, except low and high values, which will represent
          their actual calculated values.

          * 10-A contour interval of 10 will be used.

          * 20-A contour interval of 20 will be used. This is the default.

          * 40-A contour interval of 40 will be used.

          * 80-A contour interval of 80 will be used.
      bands_minarea {Double}:
          The minimum area for output polygons. Features smaller than
          this value will be removed. The default is 0.00016 square decimal
          degrees. If you are creating an output dataset with a projected
          coordinate
          system, ensure that this value reflects the square units of that
          coordinate system-for example, square meters for a UTM dataset.
          Otherwise, the default value may result in an empty output dataset.
      smooth_tolerance {Linear Unit}:
          The tolerance used by the smoothing algorithm. The larger the value,
          the more generalized the output band features. The default is 0.002
          decimal degrees.
      number_of_bands {Long}:
          Specifies the number of elevation bands that will be generated.

          * 1-One elevation band will be generated.

          * 2-Two elevation bands will be generated.

          * 3-Three elevation bands will be generated.

          * 4-Four elevation bands will be generated.
      height_field {Field}:
          The field that identifies the elevation values of the spot height
          features. These values will be evaluated during the thinning process.
      search_distance {Linear Unit}:
          The minimum distance between spot heights. The default is 0 meters.
      hydroline_minlength {Linear Unit}:
          The minimum length used to eliminate hydrology features. The tool will
          thin hydrology features that have a length less than this value. This
          value is used when generalizing input hydro lines and areas.
      hydroline_minspacing {Linear Unit}:
          The shortest distance between hydrographic segments that will display
          at the output scale. If the spacing between two parallel trending
          features is smaller than this value, one of the features will be
          hidden. This parameter defines the density of the resulting thinned
          hydrography. It should correspond to the distance between two parallel
          trending features that is visually significant to include at the final
          scale. When the density of features is too high (that is, the features
          are too closely spaced), at least one feature will be hidden. This can
          result in important features or features longer than the
          hydroline_minlength value being hidden.
      hydroarea_minlength {Linear Unit}:
          The length used to split and classify hydrographic polygons as short
          or long. Polygons will be split at any location where the edge-to-edge
          distance is equal to the this value.
      hydroarea_minwidth {Linear Unit}:
          The width used to split and classify hydrographic polygons as narrow
          or wide. Polygons will be split at any location where the edge-to-edge
          distance is equal to this value."""
    ...

@gptooldoc('GenerateLocationDiagramFeatures_topographic', None)
def GenerateLocationDiagramFeatures(in_feature_dataset=..., area_of_interest=..., sheet_id_field=..., wac_features=..., onc_features=..., land_features=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateLocationDiagramFeatures_topographic(in_feature_dataset, area_of_interest, sheet_id_field, wac_features, onc_features, land_features)

        Generates location diagram features for a Joint Operations Graphic
        (JOG) map sheet. The location diagram must include JOG_Index features,
        WAC_Index features, ONC_Index features, or LandPoly features for the
        area surrounding the processed sheet.

     INPUTS:
      in_feature_dataset (Feature Dataset):
          The feature dataset that will contain the location diagram feature
          classes. The tool will create these features classes if they do not
          exist.
      area_of_interest (Layer):
          A polygon feature layer with a single selected feature that will be
          used to identify the center and surrounding AOIs.
      sheet_id_field (Field):
          An attribute field that will be used to identify the generated sheet
          features. You can use the JOG_SHEET field as the value for this
          parameter if the field is present in the layer specified by the
          area_of_interest parameter value.
      wac_features (Feature Layer):
          The World Aeronautical Chart (WAC) features that will be used to
          generate the location diagram feature classes in the input
          geodatabase. The default path is specified for this parameter if the
          Defense Mapping product files are installed.
      onc_features (Feature Layer):
          The Operational Navigation Charts (ONC) features that will be used to
          generate the location diagram feature classes in the input
          geodatabase. The default path is specified for this parameter if the
          Defense Mapping product files are installed.
      land_features (Feature Layer):
          The land features that will be used to generate the location diagram
          feature classes in the input geodatabase. The default path is
          specified for this parameter if the Defense Mapping product files are
          installed."""
    ...

@gptooldoc('GenerateSpotHeights_topographic', None)
def GenerateSpotHeights(in_contour_features=..., in_raster=..., target_spot_features=..., contour_height_field=..., spot_height_field=..., spot_height_subtype=..., area_of_interest=..., scale=..., z_factor=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateSpotHeights_topographic(in_contour_features, in_raster;in_raster..., target_spot_features, contour_height_field, spot_height_field, {spot_height_subtype}, {area_of_interest}, {scale}, {z_factor})

        Creates elevation point features based on contour tops and
        depressions. Elevation points are created in each top and depression.
        Point height values are populated based on a digital elevation model.

     INPUTS:
      in_contour_features (Feature Layer):
          The contours from which spot heights will be computed.
      in_raster (Raster Layer / Mosaic Layer):
          The rasters used to derive the highest or lowest elevations in contour
          tops or depressions.
      target_spot_features (Feature Layer):
          An existing point feature layer or feature class in which spot heights
          will be created.
      contour_height_field (Field):
          The field in the input contours that contains elevation values. The
          field type must be numeric.
      spot_height_field (Field):
          The field in the output spot heights to which elevation values will be
          written.
      spot_height_subtype {String}:
          The spot height subtype value to be assigned to new spot height
          features.
      area_of_interest {Feature Layer}:
          The extent where spot heights will be created. The area of interest
          (AOI) is the outer extent of all selected polygons in the feature
          layer. If none are selected, the extent of the raster will be used.
          This parameter does not accept point layers as valid input.
      scale {String}:
          Specifies the scale that will be used to optimize spot heights (the
          scale of the cartographic product that will be printed). Setting a
          scale will set the default of the z_factor parameter to a value that
          is appropriate for the scale value.

          * 1:5,000-The 1:5,000 cartographic product scale will be used.

          * 1:10,000-The 1:10,000 cartographic product scale will be used.

          * 1:12,500-The 1:12,500 cartographic product scale will be used.

          * 1:25,000-The 1:25,000 cartographic product scale will be used.

          * 1:50,000-The 1:50,000 cartographic product scale will be used. This
          is the default.

          * 1:100,000-The 1:100,000 cartographic product scale will be used.

          * 1:250,000-The 1:250,000 cartographic product scale will be used.

          * 1:500,000-The 1:500,000 cartographic product scale will be used.

          * 1:1,000,000-The 1:1,000,000 cartographic product scale will be used.
      z_factor {Double}:
          The unit conversion factor that will be used when generating spot
          heights. The default is 1.The spot heights are generated based on the
          z-values in the input
          raster, which are often measured in units of meters or feet. With the
          default value of 1, the spot heights will be in the same units as the
          z-values of the input raster. To create spot heights in a unit other
          than that of the z-values, set an appropriate value for the z-factor.
          It is not necessary that the ground x,y and surface z-units be
          consistent for this tool.For example, if the elevation values in the
          input raster are in feet,
          but you want the spot heights to be generated in meters, set the
          z-factor to 0.3048 (1 foot = 0.3048 meters)."""
    ...

@gptooldoc('GenerateTopographicContours_topographic', None)
def GenerateTopographicContours(in_rasters=..., area_of_interest=..., contour_features=..., elevation_field=..., contour_subtype=..., scale=..., resample_raster=..., contour_interval=..., base_contour=..., z_factor=..., zero_contour=..., code_field=..., index_interval=..., index_code=..., intermediate_code=..., depression_code=..., depression_intermediate_code=..., raster_smooth_tolerance=..., minimum_length=..., contour_smooth_tolerance=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateTopographicContours_topographic(in_rasters;in_rasters..., area_of_interest, contour_features, elevation_field, {contour_subtype}, {scale}, {resample_raster}, {contour_interval}, {base_contour}, {z_factor}, {zero_contour}, {code_field}, {index_interval}, {index_code}, {intermediate_code}, {depression_code}, {depression_intermediate_code}, {raster_smooth_tolerance}, {minimum_length}, {contour_smooth_tolerance})

        Creates and smooths contours from an input raster.

     INPUTS:
      in_rasters (Raster Layer / Mosaic Layer):
          The input raster layers that will be used to derive the contour lines.
      area_of_interest (Feature Layer):
          A feature layer that will be used to clip the input raster before
          processing. A buffer is created before clipping the raster, which
          results in larger output contours that extend beyond the selected AOI.
          The feature layer must have only one selected feature.
      contour_features (Feature Layer):
          An existing line feature class or feature layer. Contours will be
          appended to this feature class.
      elevation_field (Field):
          The field from the input contours that will store the contour
          elevation value. This field defaults to ZV2 or ZVH if a field with
          either of those names exists in the contour feature class.
      contour_subtype {String}:
          The subtype to which contours will be written if the input contours
          have subtypes.
      scale {String}:
          Specifies the scale that will be used to optimize contours. This is
          the scale of the cartographic product that will be printed. Specifying
          the scale will set the defaults of other parameters to values that are
          appropriate for the output scale. The default is the 1:50,000
          cartographic product scale.

          * 1:5,000-The 1:5,000 cartographic product scale will be used.

          * 1:10,000-The 1:10,000 cartographic product scale will be used.

          * 1:12,500-The 1:12,500 cartographic product scale will be used.

          * 1:25,000-The 1:25,000 cartographic product scale will be used.

          * 1:50,000-The 1:50,000 cartographic product scale will be used. This
          is the default.

          * 1:100,000-The 1:100,000 cartographic product scale will be used.

          * 1:250,000-The 1:250,000 cartographic product scale will be used.

          * 1:500,000-The 1:500,000 cartographic product scale will be used.

          * 1:1,000,000-The 1:1,000,000 cartographic product scale will be used.
      resample_raster {Boolean}:
          Specifies whether the input raster will be resampled before creating
          contours.

          * RESAMPLE_RASTER-The input raster will be resampled before creating
          contours.

          * NO_RESAMPLE_RASTER-The input raster will not be resampled when
          creating contours. This is the default.
      contour_interval {Double}:
          The interval, or distance, between contour lines. This can be any
          positive number. The default is set by the scale value. If this
          parameter is left blank, the default scale value will be used.
      base_contour {Double}:
          The value that contours will be generated above and below to cover the
          entire value range of the input raster. The default is 0.
      z_factor {Double}:
          The unit conversion factor that will be used when generating contours.
          The default is 1.The contour lines are generated based on the z-values
          in the input
          raster, which are often measured in units of meters or feet. With the
          default value of 1, the contours will be in the same units as the
          z-values of the input raster. To create contours in a unit other than
          that of the z-values, set an appropriate value for the z-factor. It is
          not necessary that the ground x,y and surface z-units be consistent
          for this tool.For example, if the elevation values in the input raster
          are in
          meters, but you want the contours to be generated in feet, set the
          z-factor to 3.28084 (1 meter = 3.28084 feet).
      zero_contour {Boolean}:
          Specifies whether a zero contour will be created. A zero contour
          represents sea level. Zero contours, when generated along a coastline,
          can be created inside a water body. Specify ZERO_CONTOUR if you want
          contours generated on land areas that are at or below sea level.

          * ZERO_CONTOUR-A zero contour will be created.

          * NO_ZERO_CONTOUR-A zero contour will not be created. This is the
          default.
      code_field {Field}:
          The field from the input contour feature class where the appropriate
          code will be stored. The field defaults to the HQC field if it exists
          in the input contour feature class.
      index_interval {Long}:
          The interval, or distance, between index contour lines. For example,
          if the contour interval is 20 meters and you want index contours every
          100 meters, specify 100. The default is set by the scale value.
      index_code {String}:
          The code value that will be stored in the code_field parameter value
          when an index contour is identified. The default code will be 1 if the
          HQC field exists in the input contour feature class.
      intermediate_code {String}:
          The code value that will be stored in the code_field parameter value
          when an intermediate contour is identified. The default code will be 2
          if the HQC field exists in the input contour feature class.
      depression_code {String}:
          The code value that will be stored in the code_field parameter value
          when a depression contour is identified. The default code will be 5 if
          the HQC field exists in the input contour feature class.
      depression_intermediate_code {String}:
          The code value that will be stored in the code_field parameter value
          when a depression intermediate contour is identified. The default code
          will be 6 if the HQC field exists in the input contour feature class.
      raster_smooth_tolerance {Double}:
          The amount of smoothing that will be applied to the input raster
          before creating the contour lines.
      minimum_length {Linear Unit}:
          The minimum length that will be used for an individual contour line.
          The default is set by the scale value. If the value is set to 0 or
          left blank, no contours will be deleted from the output contours based
          on their short length.
      contour_smooth_tolerance {Linear Unit}:
          The amount of smoothing that will be applied to the contour lines. The
          larger the value, the more generalized the contours. The default is
          set by the scale value. If this parameter is set to 0 or left blank,
          no smoothing will be applied to the output contours."""
    ...

@gptooldoc('IdentifyContours_topographic', None)
def IdentifyContours(in_contour_features=..., in_rasters=..., contour_height_field=..., contour_code_field=..., contour_index_interval=..., index_code=..., intermediate_code=..., depression_code=..., depression_intermediate_code=..., depression_contours_count=..., area_of_interest=..., z_factor=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """IdentifyContours_topographic(in_contour_features, in_rasters;in_rasters..., contour_height_field, contour_code_field, {contour_index_interval}, {index_code}, {intermediate_code}, {depression_code}, {depression_intermediate_code}, {depression_contours_count}, {area_of_interest}, {z_factor})

        Identifies types of contours and applies hypsographic codes to input
        features.

     INPUTS:
      in_contour_features (Feature Layer):
          The input contours that will be updated with the specified contour
          codes.
      in_rasters (Raster Layer / Mosaic Layer):
          The rasters that will be used to derive elevations of points inside
          contours to correctly identify the types of contours.
      contour_height_field (Field):
          The field in the input contour feature class that contains elevation
          values. This field type must be numeric.
      contour_code_field (Field):
          The field in the input contour feature class that will be updated with
          the appropriate domain code.
      contour_index_interval {Long}:
          The interval or distance between index contour lines. The default is
          100.
      index_code {String}:
          The value that will be used to populate the contour_code_field
          parameter value when index contours are identified. The default is 1.
      intermediate_code {String}:
          The value that will be used to populate the contour_code_field
          parameter value when intermediate contours are identified. The default
          is 2.
      depression_code {String}:
          The value that will be used to populate the contour_code_field
          parameter value when depression contours are identified. The default
          is 5.
      depression_intermediate_code {String}:
          The value that will be used to populate the contour_code_field
          parameter value when depression intermediate contours are identified.
          The default is 6.
      depression_contours_count {Long}:
          The number of contours in a depression that will be coded as
          depressions. The value provided must be greater than zero. If no value
          is provided, all of the contours in the depression will be coded as
          depressions.
      area_of_interest {Layer}:
          The layer that defines the processing extent. The layer must have only
          one selected feature.
      z_factor {Double}:
          The conversion factor that will be used to convert the contour
          elevation value unit of measurement to match the raster's unit of
          measurement. The default is 1.For example, if the elevation values in
          the input raster are in meters
          but the contours are in feet, set the z-factor to 3.28084 (1 meter =
          3.28084 feet)."""
    ...

@gptooldoc('ValidateSpotHeights_topographic', None)
def ValidateSpotHeights(in_contour_features=..., contour_height_field=..., contour_interval=..., in_rasters=..., in_spot_features=..., spot_height_field=..., area_of_interest=..., z_factor=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ValidateSpotHeights_topographic(in_contour_features, contour_height_field, contour_interval, in_rasters;in_rasters..., in_spot_features, spot_height_field, {area_of_interest}, {z_factor})

        Validates that spot heights are higher than or equal to their
        respective contour top, and based on the contour interval, that a
        contour top is not missing a contour line between it and a spot
        height.

     INPUTS:
      in_contour_features (Feature Layer):
          The contour features that will be used to validate the spot heights.
      contour_height_field (Field):
          The field that contains elevation values for the in_contour_features
          parameter value. The type for this field must be numeric.
      contour_interval (Long):
          The interval, or distance, between contour lines. The value can be any
          positive number.
      in_rasters (Raster Layer / Mosaic Layer):
          The rasters that will be used to derive elevations of points inside
          contours.
      in_spot_features (Feature Layer):
          An existing point feature layer that contains spot heights that will
          be validated.
      spot_height_field (Field):
          The field that contains elevation values for the in_spot_features
          parameter value.
      area_of_interest {Layer}:
          The extent that contains the spot heights that will be validated. This
          parameter does not accept point layers as valid input and must have
          only one selected feature.
      z_factor {Double}:
          The unit conversion factor that will be used when validating spot
          heights to convert the contour elevation value unit of measurement to
          match the raster's unit of measurement. The default is 1.For example,
          if the elevation values in the input raster are in meters
          but the contours are in feet, set the z-factor to 3.28084 (1 meter =
          3.28084 feet)."""
    ...

@gptooldoc('GenerateProductLayout_topographic', None)
def GenerateProductLayout(geodatabase=..., aoi_layer=..., product=..., version=..., output_location=..., rasters=..., template=..., output_type=..., export_file=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateProductLayout_topographic(geodatabase, aoi_layer, product, version, output_location, {rasters;rasters...}, {template}, {output_type}, {export_file})

        Automates the process of producing a layout or map based on a standard
        specification.

     INPUTS:
      geodatabase (Workspace):
          The input geodatabase that contains the features for the final map
          product. The schema of the workspace must match the schema of the
          product selected.
      aoi_layer (Feature Layer):
          A polygon feature layer that describes the processing extent. The
          feature layer must have only one feature selected or must be a feature
          class with only one feature.
      product (String):
          Specifies the supported map product that will be used.

          * MTM50-An MGCP Topographic Map at 1:50,000 cartographic product scale
          will be used.

          * MTM100-A MGCP Topographic Map at 1:100,000 cartographic product
          scale will be used.

          * TM25-A Topographic Map at 1:25,000 cartographic product scale will
          be used.

          * TM50-A Topographic Map at 1:50,000 cartographic product scale will
          be used.

          * TM100-A Topographic Map at 1:100,000 cartographic product scale will
          be used.

          * JOGA-A Joint Operations Graphic at 1:250,000 cartographic product
          scale will be used.

          * CTM50-A Civilian Topographic map at 1:50,000 cartographic product
          scale will be used.
      version (String):
          The supported versions of the selected product.
      output_location (Folder):
          The folder path to which the output file will be written.
      rasters {Raster Layer / Mosaic Layer}:
          The input rasters used if the product requires an elevation guide
          surround element to calculate the elevation bands and spot height
          features. If you specify more than one raster, the rasters must have
          the same cell size, band number, and pixel type. If no raster is
          specified, the elevation guide data frame will not be processed and a
          warning will appear.
      template {Layout}:
          The layout template to be used. If no layout template is specified,
          the default layout template for the product will be used.
      output_type {String}:
          Specifies the type of output.

          * PAGX-A layout file will be created. This is the default.

          * APRX-An ArcGIS Pro project file will be created.

          * PDF-A .pdf file will be created.

          * TIFF-A .tiff file will be created.
      export_file {File}:
          A file that defines a set of parameter values for the specified
          output_type parameter value."""
    ...

@gptooldoc('MakeGridsAndGraticulesLayer_topographic', None)
def MakeGridsAndGraticulesLayer(in_grid_xml=..., area_of_interest=..., target_feature_dataset=..., out_layer_name=..., grid_name=..., configure_layout=..., layout=..., map_frame=..., reference_scale=..., rotation=..., mask_size=..., xy_tolerance=..., primary_coordinate_system=..., ancillary_coordinate_system_1=..., ancillary_coordinate_system_2=..., ancillary_coordinate_system_3=..., ancillary_coordinate_system_4=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """MakeGridsAndGraticulesLayer_topographic(in_grid_xml, area_of_interest, target_feature_dataset, out_layer_name, {grid_name}, {configure_layout}, {layout}, {map_frame}, {reference_scale}, {rotation}, {mask_size}, {xy_tolerance}, {primary_coordinate_system}, {ancillary_coordinate_system_1}, {ancillary_coordinate_system_2}, {ancillary_coordinate_system_3}, {ancillary_coordinate_system_4})

        Creates a grouped layer of feature classes depicting grid, graticule,
        and border features using predefined cartographic specifications. Grid
        layers are ideal for advanced grid definitions that are scale and
        extent specific.

     INPUTS:
      in_grid_xml (File):
          The XML grid definition template that stores the specification's
          graphic properties for each grid layer. In addition to the graphic
          properties, which cannot be altered before execution, the definition
          has specific default values, exposed as parameters, that can be
          modified before execution.
      area_of_interest (Feature Layer / Extent):
          The polygon feature layer or geographic extent used to determine the
          area over which the grid features are created.
      target_feature_dataset (Feature Dataset):
          The feature dataset that will store the grid features. Grid-specific
          feature classes will be created if they do not already exist. If they
          already exist, and a grid with the same name and type as the one being
          created also exists, it will be overwritten.
      grid_name {String / Field}:
          The name used to uniquely identify the grid. You can use a unique name
          for the grid or choose a field from the input area of interest feature
          layer.
      configure_layout {Boolean}:
          Adjusts the map, map frame, and layout settings to ensure they match
          the grid layer. The map's coordinate system as well as the map frame's
          scale, rotation, size, and extent can be altered to enforce
          consistency. This setting requires that a map frame is chosen from the
          map_frame parameter.

          * CONFIGURE_LAYOUT-The data frame and layout are configured using grid
          settings.

          * NO_CONFIGURE_LAYOUT-The data frame and layout are not configured.
          This is the default.
      layout {Layout}:
          The layout that contains the map frame to which the grid will be added
          when the configure_layout parameter is enabled. The layout can be in
          the active project or from an existing layout file.
      map_frame {String}:
          The map frame that will be updated. The map associated with the map
          frame can also be updated.
      reference_scale {Double}:
          The scale at which the grid is created and should be viewed.
          When the reference scale from the XML grid definition file is defined
          as Use Environment, the reference scale is derived in the following
          order:

          * The geoprocessing Reference Scale environment setting

          * The active data frame's reference scale

          * The active data frame's scale

          * The value from the XML grid definition file
      rotation {Double}:
          The rotation angle for the grid components. Rotation is used
          to create annotation features that are aligned with the page. Unless
          otherwise specified, rotation is calculated using the area of interest
          feature. When the rotation type from the XML grid definition file is
          defined as Use Environment, the rotation is derived in the following
          order:

          * The active data frame's rotation

          * The value from the XML grid definition file
      mask_size {Linear Unit}:
          The mask is a polygon feature that forms an outer ring around the
          extent of the neatline and is used to mask data that falls in the area
          reserved for coordinate labels. Mask size defines the width of the
          polygon mask feature in map or page units. The data frame may need to
          be resized to fit around the edge of the mask while including the
          coordinate labels.
      xy_tolerance {Linear Unit}:
          The minimum distance between geodatabase features, expressed in linear
          units. This value defaults to the value set in the grid XML. You can
          set higher values for data with less coordinate accuracy and lower
          values for data with extremely high accuracy. Features that fall
          within the set x,y tolerance will be considered coincident.
      primary_coordinate_system {Spatial Reference}:
          The primary coordinate system used to create grid features. The final
          product or data frame should use the same coordinate system. This
          coordinate system must be a projected coordinate system. When
          the primary coordinate system in the XML grid definition
          file is defined as Use Environment, the default primary coordinate
          system is derived in the following order:

          * The geoprocessing Cartographic Coordinate System environment setting

          * The active data frame's coordinate system if it is a projected
          coordinate system

          * The Fixed value from the XML grid definition file
      ancillary_coordinate_system_1 {Spatial Reference}:
          The first of up to four ancillary coordinate systems used to create
          grid features. The grid template XML file specifies the number of
          ancillary grids.
      ancillary_coordinate_system_2 {Spatial Reference}:
          The second of up to four ancillary coordinate systems used to create
          grid features. The grid template XML file specifies the number of
          ancillary grids.
      ancillary_coordinate_system_3 {Spatial Reference}:
          The third of up to four ancillary coordinate systems used to create
          grid features. The grid template XML file specifies the number of
          ancillary grids.
      ancillary_coordinate_system_4 {Spatial Reference}:
          The fourth of up to four ancillary coordinate systems used to create
          grid features. The grid template XML file specifies the number of
          ancillary grids.

     OUTPUTS:
      out_layer_name (Group Layer):
          The name of the group layer that will be created to contain
          the symbolized grid and graticule feature classes. The group layer can
          be composed of the following layers for grid elements:

          * Mask (polygon)

          * Clip (polygon)

          * Segments (line)

          * Gridlines (line)

          * Ticks (line)

          * Endpoints (point)

          * Points (point)

          * Annotation
          This is a temporary layer that you must save in the project or as a
          layer file."""
    ...

@gptooldoc('PopulateMapSheetInfo_topographic', None)
def PopulateMapSheetInfo(in_layout=..., area_of_interest=..., lookup_table=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """PopulateMapSheetInfo_topographic(in_layout, area_of_interest, lookup_table)

        Populates text in graphic elements on a map layout.

     INPUTS:
      in_layout (Layout):
          The input layout that contains graphic elements with tagged text
          strings to be updated.
      area_of_interest (Feature Layer):
          A feature layer with a selection set containing one AOI feature. This
          parameter only accepts only polygon features. The tool writes
          attribute values from this feature to tagged text strings in defense-
          specific graphic elements.
      lookup_table (Table View):
          An input table that contains the Field_Name and DM_Tag fields."""
    ...

@gptooldoc('ApplyFeatureLevelMetadata_topographic', None)
def ApplyFeatureLevelMetadata(in_features=..., in_metadata_table=..., metadata_favorite=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ApplyFeatureLevelMetadata_topographic(in_features;in_features..., in_metadata_table, metadata_favorite)

        Applies values from a metadata record in the FeatureLevelMetadata
        table to selected features that have matching attribute fields.

     INPUTS:
      in_features (Feature Layer):
          The inputs to which the metadata_favorite parameter value will be
          applied.
      in_metadata_table (Table View):
          The path to the metadata table containing the records that will be
          used to populate attributes.
      metadata_favorite (String):
          The record that will be used to populate attributes. The available
          options depend on the records available in the metadata table."""
    ...

@gptooldoc('CalculateDefaultValues_topographic', None)
def CalculateDefaultValues(in_datasets=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CalculateDefaultValues_topographic(in_datasets;in_datasets...)

        Replaces null values in a feature class or table with the default
        values from the geodatabase feature class.

     INPUTS:
      in_datasets (Table View / Feature Layer / Dataset):
          The feature classes and/or tables whose null values will be replaced
          with the default values from the data model."""
    ...

@gptooldoc('CalculateMetrics_topographic', None)
def CalculateMetrics(in_features=..., in_metric_types=..., in_length_attributes=..., in_width_attributes=..., in_area_attributes=..., in_angle_attributes=..., in_elevation_attributes=..., in_precision=..., mgrs_attributes=..., mgrs_precision=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CalculateMetrics_topographic(in_features;in_features..., in_metric_types;in_metric_types..., {in_length_attributes}, {in_width_attributes}, {in_area_attributes}, {in_angle_attributes}, {in_elevation_attributes}, {in_precision}, {mgrs_attributes}, {mgrs_precision})

        Populates metrics for features in a geodatabase. Metrics include
        length, width, area, and elevation attributes.

     INPUTS:
      in_features (Feature Layer):
          The features for which metrics will be calculated.
      in_metric_types (String):
          Specifies the types of metrics that will be calculated.

          * ANGLE_OF_ORIENTATION-Angle of orientation metrics will be calculated

          * AREA-Area metrics will be calculated.

          * ELEVATION-Elevation metrics will be calculated.

          * LENGTH-Length metrics will be calculated.

          * MGRS-Military Grid Reference System coordinates will be calculated.

          * WIDTH-Width metrics will be calculated.
      in_length_attributes {String}:
          A comma-delimited string of field names from which the length metrics
          will be calculated. The default is LEG,LEN,LEN_,LGN,LZN. You can add
          the names of other length metric fields; if the fields exist in the
          in_features value, they will be computed.
      in_width_attributes {String}:
          A comma-delimited string of field names from which the width metrics
          will be calculated. The default is WID,WID_,WGP. You can add the names
          of other width metric fields; if the fields exist in the in_features
          value, they will be computed.
      in_area_attributes {String}:
          A comma-delimited string of field names from which the area metrics
          will be calculated. The default is ARA,ARE,ARE_. You can add the names
          of other area metric fields; if the fields exist in the in_features
          value, they will be computed.
      in_angle_attributes {String}:
          A comma-delimited string of field names from which the angle of
          orientation metrics will be calculated. The default is AOO,DOF,FEO.
          You can add the names of other angle of orientation metric fields; if
          the fields exist in the in_features value, they will be computed.
      in_elevation_attributes {String}:
          A comma-delimited string of field names from which the elevation
          metrics will be calculated. The default is ZV2,ZVH. You can add the
          names of other elevation metric fields; if the fields exist in the
          in_features value, they will be computed.
      in_precision {Long}:
          The precision of the metrics written to the target attributes.
      mgrs_attributes {String}:
          A comma-delimited string of field names from which the MGRS
          coordinates will be calculated. The default is MGRSValue,MGRS. You can
          add the names of other MGRS fields; if the fields exist in the
          in_features value, they will be computed. The fields must have a
          String field type and a field length greater than the largest possible
          MGRS coordinate value.
      mgrs_precision {String}:
          Specifies the precision of the coordinates that will be calculated for
          the target attributes.

          * 6x8 (4Q)-The precision will be calculated at grid-level precision,
          typically the polygon formed by a 6-degree wide UTM zone and 8-degree
          high latitude bands.

          * 100km (4QFJ)-The precision will be calculated at 100,000 meters
          squared.

          * 10km (4QFJ16)-The precision will be calculated at 10,000 meters
          squared.

          * 1km (4QFJ1267)-The precision will be calculated at 1,000 meters
          squared.

          * 100m (4QFJ123678)-The precision will be calculated at 100 meters
          squared.

          * 10m (4QFJ12346789)-The precision will be calculated at 10 meters
          squared.

          * 1m (4QFJ1234567890)-The precision will be calculated at 1 meter
          squared.

          * Image City Map (1234)-The precision will be calculated at the level
          of an Image City Map (ICM). This is the default."""
    ...

@gptooldoc('MergeLinesByPseudoNode_topographic', None)
def MergeLinesByPseudoNode(input_features=..., merge_fields=..., aggregate_operations=..., merge_feature_rule=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """MergeLinesByPseudoNode_topographic(input_features, {merge_fields;merge_fields...}, {aggregate_operations;aggregate_operations...}, {merge_feature_rule})

        Dissolves features where pseudo nodes occur.

     INPUTS:
      input_features (Feature Layer):
          The line features from which pseudo nodes will be removed.
      merge_fields {Field}:
          The field or fields on which features will be merged.
      aggregate_operations {Value Table}:
          Specifies the fields that will be used to calculate the specified
          statistic. Multiple statistic and field combinations can be specified.
          Null values are excluded from all statistical calculations.Text
          attribute fields can be summarized using first and last
          statistics. Numeric attribute fields can be summarized using any
          statistic.Available statistic types are as follows:

          * SUM-The total value for the specified field will be calculated.

          * MEAN-The average for the specified field will be calculated.

          * MIN-The smallest value for all records of the specified field will
          be found.

          * MAX-The largest value for all records of the specified field will be
          found.

          * RANGE-The range of values (maximum minus minimum) for the specified
          field will be calculated.

          * STD-The standard deviation of values in the specified field will be
          calculated.

          * COUNT-The number of values included in statistical calculations will
          be found. Each value will be counted except null values. To determine
          the number of null values in a field, create a count on the field in
          question, create a count on a different field that does not contain
          null values (for example, the OID if present), and subtract the two
          values.

          * FIRST-The value of the first record in the input will be used.

          * LAST-The value of the last record in the input will be used.

          * MEDIAN-The median for all records of the specified field will be
          calculated.

          * VARIANCE-The variance for all records of the specified field will be
          calculated.

          * UNIQUE-The number of unique values of the specified field will be
          counted.
      merge_feature_rule {String}:
          Specifies which feature's attributes will be maintained when two
          features are merged at a pseudo node.

          * FIRST-The feature with the lowest ObjectID and its attributes will
          be maintained while merging. The value for the fields with a specified
          aggregation operation will be updated with the calculated value.

          * LAST-The feature with the highest ObjectID and its attributes will
          be maintained while merging. The value for the fields with a specified
          aggregation operation will be updated with the calculated value.

          * BY_LENGTH-The feature with the longest length and its attributes
          will be maintained while merging. The value for the fields with a
          specified aggregation operation will be updated with the calculated
          value.

          * USE_DEFAULTS-The feature with the lowest ObjectID will be maintained
          while merging. The value for the fields with a specified aggregation
          operation will be updated with the calculated value. The value for
          fields that are not merge fields or calculated with an aggregation
          operation will have the value assigned with the default value from the
          field or subtype when applicable."""
    ...

@gptooldoc('RemoveCutbackVertices_topographic', None)
def RemoveCutbackVertices(in_features=..., minimum_angle=..., removal_method=..., skip_coincident_vertices=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """RemoveCutbackVertices_topographic(in_features, minimum_angle, {removal_method}, {skip_coincident_vertices})

        Removes unwanted cutbacks from polyline and polygon features.

     INPUTS:
      in_features (Feature Layer):
          The polyline or polygon feature class from which cutback vertices will
          be removed. This feature class (or layer) will be modified.
      minimum_angle (Double):
          The minimum angle threshold value in degrees. The angle value should
          be within the range of 0-180. If the angle formed by a vertex and its
          two neighboring points is smaller than the specified minimum angle,
          the vertex is a candidate for cutback removal.
      removal_method {String}:
          Specifies whether cutbacks will be removed sequentially (individually)
          or all at once.

          * SEQUENTIAL-Cutbacks will be removed sequentially for a feature.
          After a cutback is removed, the change in geometry is considered when
          determining cutbacks to the remaining vertices of a feature. This is
          the default.

          * ALL-Cutbacks will be removed for all vertices at once.
      skip_coincident_vertices {Boolean}:
          Specifies whether cutback vertices will be removed when the vertex is
          snapped to another feature in the same feature class.

          * SKIP_COINCIDENT-Cutback vertices with angles less than the
          minimum_angle value will not be removed from the feature geometry if
          they are snapped to other features.

          * REMOVE_COINCIDENT-Cutback vertices will be removed without
          considering whether they are snapped to other features. This is the
          default."""
    ...

@gptooldoc('RepairSelfIntersection_topographic', None)
def RepairSelfIntersection(in_features=..., repair_type=..., max_length=..., repair_at_end_point=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """RepairSelfIntersection_topographic(in_features, repair_type, {max_length}, {repair_at_end_point})

        Repairs self-intersecting line or polygon features. The portion
        between the feature and the intersection points are either deleted or
        split into a new feature.

     INPUTS:
      in_features (Feature Layer):
          The polyline or polygon feature class with the self-intersections that
          will be repaired.
      repair_type (String):
          Specifies whether self-intersections will be deleted or split.

          * DELETE-Self-intersections will be deleted. This is the default.

          * SPLIT-Self-intersections will be split at the intersection point and
          retained.
      max_length {Linear Unit}:
          The maximum length of the segment between the points of self-
          intersection. Only segments shorter than the specified maximum length
          will be removed.
      repair_at_end_point {Boolean}:
          Specifies whether self-intersections with an end point that snaps to
          itself will be removed.

          * REPAIR_ENDS-Self-intersections with an end point that snaps to
          itself will be removed.

          * IGNORE_ENDS-Self-intersections with an end point that snaps to
          itself (such as a cul-de-sac) will not be removed. This is the
          default."""
    ...

@gptooldoc('SplitFeatures_topographic', None)
def SplitFeatures(cutting_features=..., target_features=..., use_target_z=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """SplitFeatures_topographic(cutting_features, target_features;target_features..., use_target_z)

        Splits features on input feature classes for any number of polyline or
        polygon target feature classes using the cutting features and inserts
        points on the cutting feature.

     INPUTS:
      cutting_features (Feature Layer):
          The cutting features used to split the target features where they
          intersect the target feature class geometries.
      target_features (Feature Layer):
          The features that will be divided by the cutting features.
      use_target_z (Boolean):
          Specifies whether the z-value from the source or target will be used.

          * USE_TARGET_Z-The z-value from the source or target will be used.

          * DONT_USE_TARGET_Z-The z-value from the source or target will not be
          used. This is the default."""
    ...

@gptooldoc('UpdateGeoNames_topographic', None)
def UpdateGeoNames(in_features=..., in_geonames_features=..., in_geonames_table=..., named_feature_id_field=..., name_id_field=..., name_field=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """UpdateGeoNames_topographic(in_features;in_features..., in_geonames_features, in_geonames_table, named_feature_id_field, name_id_field, name_field)

        Updates the name field on input features based on the information from
        GeoNames_FeaturesP and GEONAMES_TABLE.

     INPUTS:
      in_features (Feature Layer):
          The input features that will be updated. Each in_features value should
          have field names matching the values specified for the
          named_feature_id_field, name_id_field, and name_field parameters.
      in_geonames_features (Feature Layer):
          The input GeoNames features that identify unique named feature
          locations.
      in_geonames_table (Table View):
          A table containing name records related to the input GeoNames
          features.
      named_feature_id_field (Field):
          The field storing GeoNames named feature identifier values. These
          values should not be null or empty on the input features.
      name_id_field (Field):
          The field to store GeoNames name identifier values.
      name_field (Field):
          The field to store GeoNames name values."""
    ...

@gptooldoc('EliminatePolygon_topographic', None)
def EliminatePolygon(in_features=..., surrounding_features=..., min_area=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """EliminatePolygon_topographic(in_features, surrounding_features;surrounding_features..., {min_area})

        Eliminates a polygon by merging it with the polygon from the
        surrounding features that it shares the longest boundary with.

     INPUTS:
      in_features (Feature Layer):
          The feature layers that contain the polygons to be deleted.
      surrounding_features (Feature Layer):
          The polygon features that the Input Features are compared against. If
          the feature is smaller than the Minimum Area, it becomes part of the
          input features.
      min_area {Areal Unit}:
          Polygons smaller than the Minimum Area will be deleted. If the Minimum
          Area is left blank, all features or a selection set from the Input
          Features will be considered for elimination."""
    ...

@gptooldoc('ExportGeneralizedData_topographic', None)
def ExportGeneralizedData(input_geodatabase=..., target_geodatabase=..., rule_file=..., data_theme=..., export_visible_features=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ExportGeneralizedData_topographic(input_geodatabase, target_geodatabase, rule_file, data_theme, {export_visible_features})

        Exports data generalized by the ArcGIS Production Mapping theme-based
        generalization models into a production schema using generalization
        rules defined in a Microsoft Excel spreadsheet.

     INPUTS:
      input_geodatabase (Workspace):
          The geodatabase containing data in the generalization schema.
      target_geodatabase (Workspace):
          The geodatabase where the generalized data will be loaded.
      rule_file (File):
          The Excel file containing the generalization rules. This file defines
          features participating in the generalization process and determines
          the data that will be loaded and how it is organized. An example rule
          file is provided in the product file downloads for Defense Mapping and
          Production Mapping.
      data_theme (String):
          A theme that specifies the type of data to be generalized.
          Available themes are automatically populated from the Generalization
          Rule File parameter. The values provided in the example rule file are
          as follows:

          * TRANS-A data theme that groups features in a transportation network
          such as roads and railways.

          * STRUCTURE-A data theme that groups structural features such as
          buildings.

          * HYDRO-A data theme that groups water features such as lakes and
          rivers.

          * SOE-A skin of the earth data theme that groups polygon features that
          cover the entire surface of the earth with no holes or gaps. It can
          consist of water, vegetation, land, and artificial features.

          * GENERAL-A data theme that groups features other than those defined
          by another theme.
      export_visible_features {Boolean}:
          Specifies whether features with a value of 1 in the visibility field
          will be exported to the target database.

          * EXPORT_VISIBLE-Features with the visibility field set to 1 will not
          be exported.

          * EXPORT_ALL-All features will be exported, regardless of the value in
          the visibility field. This is the default."""
    ...

@gptooldoc('FillGaps_topographic', None)
def FillGaps(input_features=..., max_gap_area=..., fill_option=..., fill_unenclosed_gaps=..., max_gap_distance=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """FillGaps_topographic(input_features;input_features..., max_gap_area, {fill_option}, {fill_unenclosed_gaps}, {max_gap_distance})

        Fills gaps between polygon features that participate in a topology
        where the coincident boundaries are evident.

     INPUTS:
      input_features (Feature Layer):
          A list of input polygon feature classes or layers to be analyzed for
          gaps.
      max_gap_area (Areal Unit):
          The maximum area that can be considered a gap. Areas larger than this
          threshold are not filled.
      fill_option {String}:
          Specifies how enclosed and unenclosed gaps are filled.

          * FILL_BY_LENGTH-Gaps are filled by adding a gap's geometry to the
          polygon with the longest shared edge. This is the default.

          * FILL_BY_ORDER-Gaps are filled sequentially according to the order of
          the input polygon features list.
      fill_unenclosed_gaps {Boolean}:
          Specifies whether the tool fills unenclosed gaps.

          * SKIP_UNENCLOSED_GAPS-Only enclosed gaps are filled. Unenclosed gap
          are skipped. This is the default.

          * FILL_ALL-Both enclosed and unenclosed gaps are filled.
      max_gap_distance {Linear Unit}:
          The maximum distance between features in which a gap can be filled.
          This parameter is used only when the fill_unenclosed_gaps parameter is
          set to FILL_ALL."""
    ...

@gptooldoc('IdentifyNarrowPolygons_topographic', None)
def IdentifyNarrowPolygons(in_features=..., out_feature_class=..., min_width=..., min_length=..., taper_length=..., connecting_features=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """IdentifyNarrowPolygons_topographic(in_features, out_feature_class, min_width, min_length, {taper_length}, {connecting_features;connecting_features...})

        Splits a polygon based on its width and classifies each portion as
        narrow or wide based on its width and length.

     INPUTS:
      in_features (Feature Layer):
          The features to be split.
      min_width (Linear Unit):
          The width used to split and classify polygons as narrow or wide.
          Polygons will be split at any location where the edge-to-edge distance
          is equal to the Minimum Width.
      min_length (Linear Unit):
          The length used to classify the split polygons as short or long.
      taper_length {Linear Unit}:
          The distance the end of the split feature will extend to provide a
          more natural break.
      connecting_features {Feature Layer}:
          The features that will be used to refine the tapering of wide areas.
          The polygons will be tapered toward the touch point or the shared
          boundary of a connecting feature.

     OUTPUTS:
      out_feature_class (Feature Class):
          The output feature class containing the results."""
    ...

@gptooldoc('ImportGeneralizationData_topographic', None)
def ImportGeneralizationData(input_geodatabase=..., target_geodatabase=..., rule_file=..., data_theme=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ImportGeneralizationData_topographic(input_geodatabase, target_geodatabase, rule_file, data_theme)

        Imports data from a production schema to a themed generalization
        database using generalization rules defined in a Microsoft Excel
        spreadsheet.

     INPUTS:
      input_geodatabase (Workspace):
          The geodatabase containing data in a production schema.
      target_geodatabase (Workspace):
          The target geodatabase where the data optimized for generalization
          will be loaded.
      rule_file (File):
          The Excel file containing the generalization rules. This file defines
          features participating in the generalization process and determines
          the data that will be loaded and how it is organized. An example rule
          file is provided in the product file downloads for Defense Mapping and
          Production Mapping.
      data_theme (String):
          A theme that specifies the type of data to be generalized.
          Available themes are automatically populated from the Generalization
          Rule File parameter. The values provided in the example rule file are
          as follows:

          * TRANS-A data theme that groups features in a transportation network
          such as roads and railways.

          * STRUCTURE-A data theme that groups structural features such as
          buildings.

          * HYDRO-A data theme that groups water features such as lakes and
          rivers.

          * SOE-A skin of the earth data theme that groups polygon features that
          cover the entire surface of the earth with no holes or gaps. It can
          consist of water, vegetation, land, and artificial features.

          * GENERAL-A data theme that groups features other than those defined
          by another theme."""
    ...

@gptooldoc('PolygonToCenterline_topographic', None)
def PolygonToCenterline(in_features=..., out_feature_class=..., connecting_features=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """PolygonToCenterline_topographic(in_features, out_feature_class, {connecting_features;connecting_features...})

        Creates centerlines from polygon features. This tool is useful for
        creating centerlines from hydrographic polygons for use at smaller
        scales.

     INPUTS:
      in_features (Feature Layer):
          The polygon features that will be used to create the centerline.
      connecting_features {Feature Layer}:
          The features to be used to ensure connectivity of the centerline with
          other features in a network. The centerline will link to the point or
          the shared boundary wherever a feature from a connecting feature class
          touches the input feature.

     OUTPUTS:
      out_feature_class (Feature Class):
          The output feature class for the centerlines."""
    ...

@gptooldoc('RemoveSmallLines_topographic', None)
def RemoveSmallLines(in_features=..., minimum_length=..., maximum_angle=..., in_intersecting_features=..., recursive=..., split_input_lines=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """RemoveSmallLines_topographic(in_features, minimum_length, {maximum_angle}, {in_intersecting_features;in_intersecting_features...}, {recursive}, {split_input_lines})

        Removes lines that are shorter than a specified minimum length and do
        not connect to other features on one end.

     INPUTS:
      in_features (Feature Layer):
          The features that will have small lines removed.
      minimum_length (Linear Unit):
          The minimum length for input lines. Features shorter than this
          distance will be removed.
      maximum_angle {Long}:
          Any line below the minimum length that is within the defined angle of
          a consecutive line segment will be kept.
      in_intersecting_features {Feature Layer}:
          Additional intersecting features that the input features can be
          compared to when determining whether the feature is a small line.
      recursive {Boolean}:
          Specifies whether small lines on the line features will be removed.

          * NON_RECURSIVE-All the small lines on lines will be removed. The
          remaining lines will not be analyzed to determine whether they are
          small lines. This is the default.

          * RECURSIVE-The small lines will be removed from the lines and the
          remaining lines will be analyzed to determine whether they are
          considered small lines. If they do not meet the minimum_length value,
          they will be considered small lines and removed.
      split_input_lines {Boolean}:
          Specifies whether the input line features will be split at all
          intersections before determining the small lines to remove.

          * SPLIT-All lines in the input feature class will be split at
          intersections to ensure topological integrity. The length of the split
          features, not the original feature geometries, will be considered when
          applying the minimum length value to determine small lines. This is
          the default.

          * NO_SPLIT-The lines will not be split before determining the lines to
          remove. The length of the input feature geometries will be used when
          applying the minimum length value to determine small lines."""
    ...

@gptooldoc('ThinHydrologyLines_topographic', None)
def ThinHydrologyLines(in_features=..., invisibility_field=..., min_length=..., min_spacing=..., hierarchy_field=..., intersecting_features=..., unsplit_lines=..., use_angles=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ThinHydrologyLines_topographic(in_features, invisibility_field, min_length, {min_spacing}, {hierarchy_field}, {intersecting_features;intersecting_features...}, {unsplit_lines}, {use_angles})

        Generates a simplified hydrographic line network for display at a
        smaller scale. The resulting hydrographic network maintains the main
        arteries while thinning less significant features based on hierarchy,
        length, and spacing between features.

     INPUTS:
      in_features (Feature Layer):
          The hydrography line feature to be thinned.
      invisibility_field (Field):
          Features that participate in the thinned hydrography collection will
          have a value of 0. Those that are extraneous have a value of 1. A
          layer definition query can be used to display the results.
      min_length (Linear Unit):
          An indication of the shortest hydrographic segment that is sensible to
          display at the output scale. It defines a sense of the resolution or
          granularity of the resulting thinned hydrography. It should correspond
          to a length that is visually significant to include at the final
          scale. The results of this tool are a balanced compromise between the
          requirements posed by hierarchy, minimum length, minimum spacing,
          angle of connecting features, and directionality of the hydro
          geometry. Therefore, the minimum length value cannot necessarily be
          measured directly in the resulting feature set.
      min_spacing {Linear Unit}:
          An indication of the shortest distance between a hydrographic segment
          that is sensible to display at the output scale. If the spacing
          between two parallel trending features is smaller than this value, one
          of the features will be set as invisible. It defines a sense of the
          density of the resulting thinned hydrography. It should correspond to
          the distance between two parallel trending features that is visually
          significant to include at the final scale. When the density of
          features is too high (that is, the features are too closely spaced),
          at least one feature will be hidden. This can result in important
          features or features longer than the min_length being hidden.An
          indication of the shortest distance between a hydrographic segment
          that is sensible to display at the output scale. If the spacing
          between two parallel trending features is smaller than this value, one
          of the features will be set as invisible. It defines a sense of the
          density of the resulting thinned hydrography. It should correspond to
          the distance between two parallel trending features that is visually
          significant to include at the final scale. When the density of
          features is too high (that is, the features are too closely spaced),
          at least one feature will be hidden. This can result in important
          features or features longer than the Minimum Length being hidden.
      hierarchy_field {Field}:
          This field contains the hierarchical ranking of feature importance,
          where 1 is very important, and larger integers reflect decreasing
          importance. A value of 0 forces the feature to remain visible in the
          final results. It identifies the relative importance of features to
          help establish which features are significant. For optimal results,
          use no more than five levels of hierarchy. Input features with
          Hierarchy = 0 are considered locked and will remain visible, along
          with adjacent features necessary for connectivity.
      intersecting_features {Feature Layer}:
          If a segment is snapped to features in the provided layers, it will
          not be removed. An example would be a small river segment snapped to a
          lake. Even if the segment is under the min_length, it would need to
          remain to ensure that it remains connected to the water body into
          which it flows.
      unsplit_lines {Boolean}:
          This will merge any split features in the in_features to help ensure
          that the main waterway is preserved. If set to NO_UNSPLIT_LINES, the
          ends of the waterway may be removed due to them being under the
          min_length.

          * UNSPLIT_LINES-Features that are closed on both end points will be
          merged before thinning to preserve main hydrographic arteries that
          traverse a long distance. This is the default.

          * NO_UNSPLIT_LINES-Features will remain split before the thinning
          process.
      use_angles {Boolean}:
          If set to USE_ANGLES, the angles between waterway branches will be
          used to help determine the main waterway; the highest angle will be
          used. If disabled, the longest branch will be considered part of the
          main waterway.

          * USE_ANGLES-In junctions with 3 or more waterways, features that are
          closer together in angle will be kept.

          * NO_USE_ANGLES-In junctions with 3 or more waterways, features that
          are longer will be kept. This is the default."""
    ...

@gptooldoc('CreateCrossReferenceGeodatabase_topographic', None)
def CreateCrossReferenceGeodatabase(source_workspace=..., target_database=..., out_database=..., mapping_file=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CreateCrossReferenceGeodatabase_topographic(source_workspace, target_database, out_database, {mapping_file})

        Creates a cross-reference geodatabase that the Load Data tool uses to
        map source data to target data when loading batch data.

     INPUTS:
      source_workspace (LocalDatabase|RemoteDatabase|FileSystem):
          The workspace, either a geodatabase or shapefile directory, that
          contains the schema of data that will be mapped to the target
          workspace.
      target_database (Workspace):
          The geodatabase that contains the schema of the database to which the
          source will be mapped.
      mapping_file {File}:
          An Excel spreadsheet that contains information on how the source
          features, fields, and attribute value will be mapped to the
          target_database parameter value.

     OUTPUTS:
      out_database (Workspace):
          The file geodatabase that will be created containing the mapping from
          the source_workspace parameter value to the target_database parameter
          value."""
    ...

@gptooldoc('ExportMetadata_topographic', None)
def ExportMetadata(in_cell_features=..., export_location=..., metadata_type=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ExportMetadata_topographic(in_cell_features, export_location, {metadata_type})

        Exports a Multinational Geospatial Co-production Program (MGCP) or
        MGCP Urban Vector Data (MUVD) metadata dataset (Cell or Resource,
        Subregion, and Source feature classes) to an .xml file.

     INPUTS:
      in_cell_features (Feature Layer):
          The MGCP Cell or Resource feature layer that will be exported.
      export_location (Folder):
          The directory where the metadata .xml files will be created.
      metadata_type {String}:
          Specifies the type of metadata that will be exported.

          * MGCP-Multinational Geospatial Co-production Program metadata will be
          exported. This is the default.

          * MUVD-MGCP Urban Vector Data metadata will be exported."""
    ...

@gptooldoc('ExtractDataByFeature_topographic', None)
def ExtractDataByFeature(in_datasets=..., target_gdb=..., reuse_schema=..., filter_feature=..., filter_type=..., checkout_replica=..., replica_name=..., expand_feature_classes_and_tables=..., get_related_data=..., excluded_rel_classes=..., where_clause=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ExtractDataByFeature_topographic(in_datasets;in_datasets..., target_gdb, {reuse_schema}, {filter_feature}, {filter_type}, {checkout_replica}, {replica_name}, {expand_feature_classes_and_tables}, {get_related_data}, {excluded_rel_classes;excluded_rel_classes...}, {where_clause})

        Extracts features from multiple input feature classes into a target
        database.

     INPUTS:
      in_datasets (Value Table):
          A value table of rows that contain a dataset to extract and a filter
          option for that dataset. Specifying a filter option allows you to
          control how rows are replicated in each dataset. The following are
          filter options:

          * Dataset-The schema of the dataset will be extracted to the child
          workspace

          * Rows Option-Specifies whether all rows, only the schema, or
          features that match filter criteria will be extracted.

          * All Rows-All rows of the dataset will be extracted to the child
          workspace.

          * Schema Only-Only the schema of the dataset will be extracted to the
          child workspace.

          * Use Filters-If a feature layer is specified for the Filter Feature
          Layer parameter, features that either intersect or are contained by
          features in the Filter Feature Layer parameter will be extracted.
      target_gdb (Workspace / GeoDataServer):
          The workspace into which data will be extracted.
      reuse_schema {Boolean}:
          Specifies whether a geodatabase that contains the schema of the data
          to extract will be reused. This reduces the amount of time required to
          extract the data. This option is only supported for file geodatabases.

          * REUSE-The schema will be reused.

          * DO_NOT_REUSE-The schema will not be reused. This is the default.
      filter_feature {Layer}:
          A feature layer with one selected feature used to limit the extent of
          the data that will be extracted.
      filter_type {String}:
          Specifies the spatial relationship between the Filter Feature Layer
          and Input Datasets parameter values and how that relationship will be
          filtered. The spatial relationship is applied to data in an extent
          defined by the area of interest (AOI) specified in the Filter Feature
          Layer parameter.

          * INTERSECTS-Features in the Input Datasets parameter that intersect
          features in the Filter Feature Layer parameter will be extracted.

          * CONTAINS-Features in the Input Datasets parameter that are contained
          by the selected feature in the Filter Feature Layer parameter will be
          extracted.

          * CLIP-Features in the Input Datasets parameter that intersect
          features in the Filter Feature Layer parameter will be extracted, and
          the features will be split at the AOI boundary and only those within
          the AOI will be kept.
      checkout_replica {Boolean}:
          Specifies whether the data will be checked out, replicated, edited,
          and checked back in one time.

          * CHECKOUT_REPLICA-The replica will be checked out.

          * DO_NOT_CHECKOUT_REPLICA-The replica will not be checked out. This is
          the default.
      replica_name {String}:
          The name of the replica to check out.
      expand_feature_classes_and_tables {String}:
          Specifies whether expanded feature classes and tables-such as those in
          networks, topologies, or relationship classes-will be added.

          * USE_DEFAULTS-The expanded feature classes and tables related to the
          feature classes and tables in the replica will be added. The default
          for feature classes is to replicate all features intersecting the
          spatial filter. If no spatial filter has been provided, all features
          are included. The default for tables is to replicate only the schema.

          * ADD_WITH_SCHEMA_ONLY-Only the schema for the expanded feature
          classes and tables will be added.

          * ALL_ROWS-All rows for expanded feature classes and tables will be
          added.

          * DO_NOT_ADD-No expanded feature classes and tables will be added.
          This is the default.
      get_related_data {Boolean}:
          Specifies whether rows related to existing rows in the replica will be
          replicated. For example, consider a feature (f1) inside the
          replication filter and a related feature (f2) from another class
          outside the filter. Feature f2 is included in the replica if you
          choose to get related data.

          * DO_NOT_GET_RELATED-Related data will not be replicated. This is the
          default.

          * GET_RELATED-Related data will be replicated.
      excluded_rel_classes {Relationship Class}:
          The relationship classes with the relationships to exclude from
          extraction. The relationship classes will still be included if both
          datasets that participate are present but the related objects are not
          extracted.
      where_clause {SQL Expression}:
          An SQL expression that is used to further refine results from the AOI
          extraction."""
    ...

@gptooldoc('GenerateExcelFromGeodatabase_topographic', None)
def GenerateExcelFromGeodatabase(in_geodatabase=..., out_excel_file=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateExcelFromGeodatabase_topographic(in_geodatabase, out_excel_file)

        Creates a Microsoft Excel file (.xls or .xlsx) from the contents of a
        geodatabase.

     INPUTS:
      in_geodatabase (Workspace):
          The geodatabase that will be used to create the Excel spreadsheet.

     OUTPUTS:
      out_excel_file (File):
          The Excel file that will be created from the geodatabase."""
    ...

@gptooldoc('GenerateGeodatabaseFromExcel_topographic', None)
def GenerateGeodatabaseFromExcel(in_excel_file=..., out_geodatabase=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GenerateGeodatabaseFromExcel_topographic(in_excel_file, out_geodatabase)

        Creates a geodatabase from the contents of a Microsoft Excel file
        (.xls or .xlsx).

     INPUTS:
      in_excel_file (File):
          The Excel file that will be used to generate the geodatabase.
      out_geodatabase (Workspace):
          The geodatabase that will be generated from the Excel file."""
    ...

@gptooldoc('GeoNamesToGeodatabase_topographic', None)
def GeoNamesToGeodatabase(in_source=..., in_feature_class=..., in_allow_duplicates=..., in_table=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GeoNamesToGeodatabase_topographic(in_source, in_feature_class, in_allow_duplicates, in_table)

        Loads GeoNames data into a feature class and table. The feature class
        is composed of point features, and the table contains fields with
        information concerning the naming conventions used for the features.
        The feature class contains the Unique Feature Identifier (UFI) and
        Unique Name Identifier (UNI), which match the same fields in the
        GeoNames table.

     INPUTS:
      in_source (Text File / Shapefile):
          Path to the source file containing GeoNames information. This needs to
          be a properly formatted GeoNames file.
      in_feature_class (Feature Class):
          The GeoNames feature class; this feature class should be in the
          working database.
      in_allow_duplicates (Boolean):
          Allows duplicate features in the GeoNames feature class.

          * ALLOW_DUPLICATES-Allows the tool to import features even if there is
          already an entry in the GeoNames feature class and table.

          * DON'T_ALLOW_DUPLICATES-Prevents the tool from importing features if
          there is another feature with the same geometry and attributes in the
          GeoNames feature class or GeoNames table. This is the default.
      in_table (Table):
          The GeoNames table. This table should be in the working database."""
    ...

@gptooldoc('GeodatabaseToShape_topographic', None)
def GeodatabaseToShape(in_features=..., output_folder=..., coded_value_domain_export_mode=..., conversion_method=..., create_empties=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GeodatabaseToShape_topographic(in_features;in_features..., output_folder, coded_value_domain_export_mode, conversion_method, create_empties)

        Exports one or more feature classes in a geodatabase to shapefiles
        using one of three modes: defense, generic, and Multinational
        Geospatial Co-Production Program (MGCP).

     INPUTS:
      in_features (Feature Layer):
          The features used to create the shapefiles.
      output_folder (Folder):
          The folder that will contain the output shapefiles.
      coded_value_domain_export_mode (String):
          Specifies the method that will be used to export coded domain values.

          * DESCRIPTIONS-Coded domain values will be exported using their
          descriptions rather than raw values.

          * VALUES-Coded domain values will be exported as raw values. This is
          the default.

          * VALUES_AND_DESCRIPTIONS-Coded domain values will be exported as raw
          values and string descriptions
      conversion_method (String):
          Specifies the conversion method that will be applied.

          * DEFENSE_BY_FEATURECLASS-A shapefile will be created based on the
          feature class name and trailing underscores will be removed from
          fields.

          * DEFENSE_BY_SUBTYPE-A shapefile will be created based on the subtype
          name, attributes applicable to that subtype will be exported, and
          trailing underscores will be removed from fields. This is the default.

          * GENERIC_BY_FEATURECLASS-A shapefile will be created for each feature
          class selected. The shapefile name must match the feature class name.

          * GENERIC_BY_SUBTYPE-A shapefile will be created for each subtype of
          the feature class selected. The shapefile name must match the subtype
          name.

          * MGCP-A shapefile will be created based on the feature class subtype.
          The exported shapefile will be named using the geometry type prefix,
          for example, S for surface features, L for line features, P for point
          features, and the feature code. For example, the river subtype BH140
          in the WatrcrsL feature class would be exported to a shapefile named
          LBH140.

          * MUVD-A shapefile will be created based on the feature class subtype.
          The exported shapefile will be named using the geometry type prefix,
          for example, S for surface features, C for curve features, P for point
          features, and the feature code. For example, the river subtype BH140
          in the WatercrsL feature class would be exported to a shapefile named
          CBH140.
      create_empties (Boolean):
          Specifies whether empty shapefiles will be created if the input
          feature classes are empty.

          * CREATE_EMPTIES-Empty shapefiles will be created if the corresponding
          input feature classes are empty.

          * NO_CREATE_EMPTIES-Empty shapefiles will not be created if the
          corresponding input feature classes are empty. This is the default."""
    ...

@gptooldoc('ImportMetadata_topographic', None)
def ImportMetadata(files=..., in_cell_features=..., metadata_type=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ImportMetadata_topographic(files;files..., in_cell_features, {metadata_type})

        Imports Multinational Geospatial Co-production Program (MGCP) or MGCP
        Urban Vector Data (MUVD) metadata to an MGCP or MUVD database.

     INPUTS:
      files (File):
          The .xml files that contain the metadata that will be imported.
      in_cell_features (Feature Layer):
          The Cell or Resource feature class where the metadata will be
          imported.
      metadata_type {String}:
          Specifies the type of metadata that will be imported.

          * MGCP-Multinational Geospatial Co-production Program metadata will be
          imported. This is the default.

          * MUVD-MGCP Urban Vector Data metadata will be imported."""
    ...

@gptooldoc('LoadData_topographic', None)
def LoadData(in_cross_reference=..., in_sources=..., in_target=..., in_dataset_map_defs=..., row_level_errors=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """LoadData_topographic(in_cross_reference, in_sources;in_sources..., in_target, {in_dataset_map_defs;in_dataset_map_defs...}, {row_level_errors})

        Moves features from one schema to another by loading data from a
        source to a target workspace. Data mapping rules described in a
        cross-reference database are applied during loading.

     INPUTS:
      in_cross_reference (Workspace):
          The path to a cross-reference database.
      in_sources (Workspace):
          A list of workspaces that contain the source features to load into the
          target workspace.
      in_target (Workspace):
          The target workspace that contains the schema referenced in the cross-
          reference database. Source features are loaded into this workspace.
      in_dataset_map_defs {String}:
          The source to target feature class mapping list. The format of this
          string is id | SourceDataset | TargetDataset | WhereClause | Subtype.
      row_level_errors {Boolean}:
          Specifies whether the tool will log errors that occur while inserting
          new rows into feature classes and tables in the in_target parameter.

          * ROW_LEVEL_ERROR_LOGGING-Errors that occur during individual row-
          level inserts will be logged. This is the default.

          * NO_ROW_LEVEL_ERROR_LOGGING-Errors that occur during individual row-
          level inserts will not be logged."""
    ...

@gptooldoc('UnzipCellAndImport_topographic', None)
def UnzipCellAndImport(Root_Folder=..., Target_Geodatabase=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """UnzipCellAndImport_topographic(Root_Folder, Target_Geodatabase)

        Unzips and imports compressed Multinational Geospatial Co-production
        Program (MGCP) 1-degree-by-1-degree cell packages (*.zip) into a
        target geodatabase.

     INPUTS:
      Root_Folder (Folder):
          The root folder that contains one or more compressed shapefile cell
          packages in a .zip file.
      Target_Geodatabase (Workspace):
          The geodatabase where the unzipped shapefiles will be imported."""
    ...

@gptooldoc('ExportTopology_topographic', None)
def ExportTopology(topology=..., location=..., file_name=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ExportTopology_topographic(topology, location, file_name)

        Exports a topology from a geodatabase to an .xml file.

     INPUTS:
      topology (Topology / Topology Layer):
          An existing topology in a geodatabase. All feature classes that
          participate in this topology will be listed in the output .xml file.
      location (Folder):
          The folder in which the .xml file will be written.
      file_name (String):
          The name of the topology .xml file that will be created by the tool."""
    ...

@gptooldoc('ImportTopology_topographic', None)
def ImportTopology(in_feature_dataset=..., topology_definition_file=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """ImportTopology_topographic(in_feature_dataset, topology_definition_file)

        Creates a geodatabase topology from a definition .xml file generated
        by the Export Topology tool in the Topographic Production toolbox.

     INPUTS:
      in_feature_dataset (Feature Dataset):
          The feature dataset in which the topology will be created. The feature
          dataset must contain the feature classes listed in the
          topology_definition_file.
      topology_definition_file (File):
          The .xml file that contains the topology definition."""
    ...

@gptooldoc('GAIT_topographic', None)
def GAIT(in_features=..., gait_exe=..., folder=..., schema=..., project=..., format=..., metadata=..., silent=..., reviewer_workspace=..., specfile=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GAIT_topographic(in_features;in_features..., gait_exe, folder, schema, project, format, metadata, silent, {reviewer_workspace}, {specfile})

        Validates data using the Geospatial Analysis Integrity Tool (GAIT),
        checking geometry, feature codes, attribute values and domains, and
        metadata.

     INPUTS:
      in_features (Table View / Feature Layer):
          The features to validate.
      gait_exe (File):
          The path to the GAIT executable file.
      folder (Folder):
          The shapefile export directory.
      schema (String):
          The data model that corresponds to the data displayed in the input
          feature layer.
      project (String):
          The name of the project. The project contains validation information,
          such as the checks run on the data and the results.
      format (String):
          The set of checks to run on the data. This is specific to the data
          model listed in the attribution schema.
      metadata (String):
          The metadata mapping table that corresponds to the data model of the
          input feature layer and the attribution schema.

          * META_ESRI-Esri metadata

          * META_INGR-Intergraph metadata

          * META_MGCPNGA-MGCP NGA metadata
      silent (Boolean):
          Indicates the amount of output messages to return from GAIT.exe.

          * SILENT-Limit messaging from GAIT.exe. This is the default.

          * VERBOSE-Run GAIT.exe in verbose mode.
      reviewer_workspace {Workspace}:
          The workspace to write the output features. Each shapefile result
          record is written to the reviewer table in this workspace.
      specfile {File}:
          A file that defines custom checks."""
    ...

@gptooldoc('CopyJobFiles_topographic', None)
def CopyJobFiles(job_id=..., source_path=..., target_path=..., archive_source=..., delete_source=..., create_job_folder=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CopyJobFiles_topographic(job_id, source_path, target_path, {archive_source}, {delete_source}, {create_job_folder}, {database_path})

        Copies Workflow Manager (Classic) job files to and from a local
        machine and a shared directory for processing.

     INPUTS:
      job_id (Long):
          The Job ID of the Workflow Manager (Classic) job that will be updated.
      source_path (Folder):
          The path to the folder containing the files to be copied.
      target_path (Folder):
          The path to the location where the files will be copied.
      archive_source {Boolean}:
          Specifies whether the files in the source path will be zipped before
          copying to the target location.

          * ARCHIVE-A .zip file with the contents of the source directory will
          be created and copied to the target location.

          * NO_ARCHIVE-The contents of the source directory will be copied
          directly to the target location. This is the default.
      delete_source {Boolean}:
          Specifies whether the files in the source path will be deleted after
          the files are copied to the target location.

          * DELETE_SOURCE-The source directory and all its contents will be
          deleted after the files are copied.

          * NO_DELETE_SOURCE-The source directory will not be deleted after the
          files are copied. This is the default.
      create_job_folder {Boolean}:
          Specifies whether a folder will be created in the target path for
          containing the copied files.

          * CREATE_JOB_FOLDER-A folder will be created in the target path with
          the name of the chosen job. Files are copied from the source path to
          this new folder.

          * NO_CREATE_JOB_FOLDER-A folder will not be created, and files from
          the source path will be copied directly to the target path. This is
          the default.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('CreateTaskGroupJobs_topographic', None)
def CreateTaskGroupJobs(job_id=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CreateTaskGroupJobs_topographic(job_id, {database_path})

        Creates new Task Group jobs based on the properties of an existing
        job.

     INPUTS:
      job_id (Long):
          The job ID of the ArcGIS Workflow Manager (Classic) job that will have
          dependencies set.
      database_path {File}:
          The Workflow Manager (Classic) database connection file that contains
          the job information. If no connection file is specified, the current
          default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('GetFeaturesByJobAOI_topographic', None)
def GetFeaturesByJobAOI(job_id=..., source_database=..., target_database=..., extract_operation=..., filter_feature=..., filter_type=..., replica_type=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """GetFeaturesByJobAOI_topographic(job_id, source_database, target_database, extract_operation, {filter_feature}, {filter_type}, {replica_type}, {database_path})

        Extracts features from a source geodatabase to a target geodatabase
        based on the Filter Feature Layer parameter value (or job AOI).

     INPUTS:
      job_id (Long):
          The job ID of the Workflow Manager (Classic) job that will be updated.
          The default area over which features will be extracted or replicated
          is also determined.
      source_database (Workspace):
          The path to the source database containing features to extract.
      target_database (Workspace):
          The database from which features will be extracted.
      extract_operation (String):
          Specifies whether the data will be copied to the target database or
          replicated to the target database.

          * EXTRACT_DATA-A copy of the features will be extracted to the target
          database. This is the default.

          * REPLICATE_DATA-The features will be extracted as a replica.
      filter_feature {Feature Layer}:
          A feature layer with one selected feature that will be used to limit
          the extent of the data that will be extracted. If no filter feature is
          specified, the job AOI will be used.
      filter_type {String}:
          Specifies the spatial relationship between source_database and
          filter_feature. This parameter is only used if the extract_operation
          parameter is set to EXTRACT_DATA.

          * INTERSECTS-Features from the source_database parameter that
          intersect features in the filter_feature parameter will be extracted.
          This is the default.

          * CONTAINS-Features from the source_database parameter that are
          contained in the selected feature in the filter_feature parameter will
          be extracted.

          * CLIP-Features from the source_database parameter that intersect
          features in the filter_feature parameter will be extracted. Features
          are then split at the AOI boundary and only those in the AOI boundary
          will be kept.
      replica_type {String}:
          Specifies the type of replica that will be created. This parameter is
          only used if the extract_operation parameter is set to REPLICATE_DATA.

          * TWO_WAY_REPLICA-Changes can be sent between child and parent
          replicas in both directions.

          * ONE_WAY_REPLICA-Changes will be sent from the parent replica to the
          child replica only.

          * CHECK_OUT-Data will be replicated, edited, and checked back in one
          time. This is the default.

          * ONE_WAY_CHILD_TO_PARENT_REPLICA-Changes will be sent from the child
          replica to the parent replica only.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('SetTaskGroupDependencies_topographic', None)
def SetTaskGroupDependencies(job_id=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """SetTaskGroupDependencies_topographic(job_id, {database_path})

        Creates dependencies between a job and other existing Task Group jobs
        based on the criteria defined in the extended properties.

     INPUTS:
      job_id (Long):
          The job ID of the Workflow Manager (Classic) job that will have
          dependencies set.
      database_path {File}:
          The Workflow Manager (Classic) database connection file that contains
          the job information. If no connection file is specified, the current
          default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('UpdateTaskGroupMetrics_topographic', None)
def UpdateTaskGroupMetrics(job_id=..., status_layer=..., status_field=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """UpdateTaskGroupMetrics_topographic(job_id, {status_layer}, {status_field}, {database_path})

        Updates and summarizes task group metrics that are part of the
        standard Topographic Workflow deployment of Workflow Manager
        (Classic).

     INPUTS:
      job_id (Long):
          The job ID of the job that will be updated.
      status_layer {Feature Layer}:
          The feature class containing status polygons that keep track of the
          last time work occurred over an extent. Only use this parameter to
          update a polygon feature class that is not the standard status
          polygons created by the Topographic Workflow.
      status_field {Field}:
          The text or date field in which the last modified date will be stored.
          The parameter is only enable, if a Status Layer value is defined.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('CopyExtendedProperties_topographic', None)
def CopyExtendedProperties(source_job_id=..., target_job_id=..., property_table_name=..., property_fields=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CopyExtendedProperties_topographic(source_job_id, target_job_id, property_table_name, property_fields;property_fields..., {database_path})

        Copies extended property values from one job to another job in the
        same Workflow Manager (Classic) repository.

     INPUTS:
      source_job_id (Long):
          The Job ID of the Workflow Manager (Classic) job that contains the
          properties to copy.
      target_job_id (Long):
          The Job ID of the target job that will have its properties updated.
      property_table_name (String):
          The name of the extended properties table that will be updated.
      property_fields (String):
          The properties to be copied from the source job to the target job.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('SetDataWorkspace_topographic', None)
def SetDataWorkspace(job_id=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """SetDataWorkspace_topographic(job_id, {database_path})

        Sets the data workspace for the chosen job to the appropriate database
        based on the production type of the job.

     INPUTS:
      job_id (Long):
          The job ID of the Workflow Manager (Classic) job that will be updated.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('SetProductionProperties_topographic', None)
def SetProductionProperties(job_id=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """SetProductionProperties_topographic(job_id, {database_path})

        Updates the production properties extended properties table of a
        Workflow Manager (Classic) job based on its production type to ensure
        that the job and any associated tasks use the correct data and maps.

     INPUTS:
      job_id (Long):
          The ID of the Workflow Manager (Classic) job that will be updated.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('UpdateExtendedProperty_topographic', None)
def UpdateExtendedProperty(job_id=..., properties_table_name=..., property_field=..., value=..., increment_value=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """UpdateExtendedProperty_topographic(job_id, properties_table_name, property_field, value, {increment_value}, {database_path})

        Updates an extended property in the identified properties table for
        the chosen job.

     INPUTS:
      job_id (Long):
          The Job ID of the Workflow Manager (Classic) job that will be updated.
      properties_table_name (String):
          The name of the extended properties table that will be updated.
      property_field (String):
          The property to be updated in the extended properties table.
      value (String):
          The value that will be set for the extended property.
      increment_value {Boolean}:
          If a value already exists for the chosen property, this parameter
          specifies whether the increment value will be added to the current
          value or will replace the current value.

          * INCREMENT-The specified value will be added to any existing value
          for the property.

          * REPLACE-The specified value will replace the existing value for the
          property.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('UpdatePropertyCount_topographic', None)
def UpdatePropertyCount(job_id=..., properties_table_name=..., property_field=..., update_value=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """UpdatePropertyCount_topographic(job_id, properties_table_name, property_field, update_value, {database_path})

        Increases the value in an extended property by the update value each
        time the tool is run so that metrics are recorded.

     INPUTS:
      job_id (Long):
          The ID of the Workflow Manager (Classic) job that will be updated.
      properties_table_name (String):
          The name of the extended properties table that will be updated.
      property_field (String):
          The property to be updated in the selected extended properties table.
      update_value (Long):
          The value by which the selected extended property will be increased.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('CancelRemainingTasks_topographic', None)
def CancelRemainingTasks(job_id=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CancelRemainingTasks_topographic(job_id, {database_path})

        Prevents the remaining tasks in a job from starting or being created.
        The active task and its task group job will still complete.

     INPUTS:
      job_id (Long):
          The job ID of the parent ArcGIS Workflow Manager (Classic) task group
          job that contains the task list derived from the Set Task List tool.
      database_path {File}:
          The ArcGIS Workflow Manager (Classic) database connection file that
          contains the job information. If a connection is not specified, the
          current default ArcGIS Workflow Manager (Classic) database will be
          used."""
    ...

@gptooldoc('CreateJobForTask_topographic', None)
def CreateJobForTask(job_id=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """CreateJobForTask_topographic(job_id, {database_path})

        Automatically creates a Workflow Manager (Classic) job for a task.

     INPUTS:
      job_id (Long):
          The job ID of the Workflow Manager (Classic) job that will be the
          parent to the newly created child job. The Current Task extended
          property value for this job will be used to determine the type of task
          job that will be created.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('InsertTaskGroup_topographic', None)
def InsertTaskGroup(job_id=..., task_group_id=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """InsertTaskGroup_topographic(job_id, task_group_id, {database_path})

        Adds tasks from the chosen task group to a job when required by
        workflow execution.

     INPUTS:
      job_id (Long):
          The ID of the Workflow Manager (Classic) job that will be updated.
          This is the ID for the parent task group job, not the task job.
      task_group_id (Long):
          The ID of the task group that defines the tasks that will be inserted
          into the selected job's task list.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('SetNextTask_topographic', None)
def SetNextTask(job_id=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """SetNextTask_topographic(job_id, {database_path})

        Sets the next task in a workflow from the task list.

     INPUTS:
      job_id (Long):
          The ID of the Workflow Manager (Classic) job that will be updated.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('SetTaskList_topographic', None)
def SetTaskList(job_id=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """SetTaskList_topographic(job_id, {database_path})

        Populates the list of expected tasks for a job based on the selected
        task group.

     INPUTS:
      job_id (Long):
          The ID of the Workflow Manager (Classic) job that will be updated.
      database_path {File}:
          The Workflow Manager (Classic) database connection file (.jtc) that
          contains the job information. If no connection file is specified, the
          current default Workflow Manager (Classic) database will be used."""
    ...

@gptooldoc('SetTaskStatus_topographic', None)
def SetTaskStatus(job_id=..., parent_id=..., status=..., database_path=...): # -> conversion | int | float | complex | basestring | list[Unknown] | tuple[Unknown, ...] | dict[Unknown, Unknown]:
    """SetTaskStatus_topographic(job_id, parent_id, status, {database_path})

        Updates the status of a task based on the state of the Workflow
        Manager (Classic) job created for the task.

     INPUTS:
      job_id (Long):
          The job ID of the task job that has a change in status.
      parent_id (Long):
          The job ID of the task group job that is the parent to the task job.
      status (String):
          Specifies the status of the selected task.

          * WORKING-Work has begun for the task.

          * COMPLETE-Work has been completed for the task.

          * RESTART-Work will be restarted by creating a new job of the same
          type.
      database_path {File}:
          The Workflow Manager (Classic) database connection file that contains
          the job information. If no connection file is specified, the current
          default Workflow Manager (Classic) database will be used."""
    ...

